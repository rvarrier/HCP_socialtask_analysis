{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting trait-fMRI correlations\n",
    "\n",
    "(older filename: 2A_trait_fMRI_correl_analyses_nooutputs_Figure7d.ipynb)\n",
    " Rekha Varrier, 2022"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting default fontsizes for plots\n",
    "\n",
    "s=20 # CHANGE FONTSIZE HERE\n",
    "\n",
    "plt.rc('font', size=s) #controls default text size\n",
    "plt.rc('axes', titlesize=s) #fontsize of the title\n",
    "plt.rc('axes', labelsize=s) #fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=s) #fontsize of the x tick labels\n",
    "plt.rc('ytick', labelsize=s) #fontsize of the y tick labels\n",
    "plt.rc('legend', fontsize=s) #fontsize of the legend\n",
    "#import matplotlib as mpl\n",
    "#mpl.rcParams['font.weight']= 'normal'\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "res_behav_data = pd.read_csv('../data/RESTRICTED_esfinn_11_21_2021_19_19_35.csv')\n",
    "res_behav_data.set_index(\"Subject\", inplace=True)\n",
    "res_behav_data.index = res_behav_data.index.map(str)\n",
    "print(res_behav_data.shape)\n",
    "res_behav_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read in unrestricted behavioral data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "unres_behav_data = pd.read_csv('../data/unrestricted_esfinn_11_21_2021_19_19_13.csv')\n",
    "unres_behav_data.set_index(\"Subject\", inplace=True)\n",
    "unres_behav_data.index = unres_behav_data.index.map(str)\n",
    "print(unres_behav_data.shape)\n",
    "unres_behav_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "behav_data = pd.concat([res_behav_data, unres_behav_data], axis=1)\n",
    "print(behav_data.shape)\n",
    "behav_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read in FMRI data, join into single dataframe, then join this with the larger dataframe:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#suff= ''\n",
    "suff = '_corrected'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_file_loc = '/Users/f0053cz/Dropbox (Dartmouth College)/postdoc_Dartmouth/HCP/fMRIScipts/data'\n",
    "sub_id_all = np.load(os.path.join(data_file_loc,f'sub_ID_all{suff}.npy'))\n",
    "sub_id_all = [str(i) for i in sub_id_all]\n",
    "print(len(sub_id_all),sub_id_all[:5])\n",
    "\n",
    "# load behavioral responses too - to identify missed/invalid trials later - 1 for \"social\", 0 for \"nonsocial\" and 9 for \"unsure\", nan for missed response\n",
    "responses = np.load(os.path.join(data_file_loc,f'responses{suff}.npy'))\n",
    "responses.shape # subs *movies"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = np.load('/Users/f0053cz/Dropbox (Dartmouth College)/postdoc_Dartmouth/HCP/fMRIScipts/data/sub_ID_all_corrected.npy')\n",
    "x,x.shape, responses.shape # if not 1049,10 - check that the right file is imported"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "shen268_lbl = pd.read_csv(os.path.join(data_file_loc,\"shen_dictionary.csv\"))\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "shen268_lbl.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for comparison with the other main figure if needed\n",
    "nodes_coaxbill_rand_all = np.load(os.path.join(data_file_loc,'nodes_coaxbill_rand_all.npy')) # sig nodes hihglighted in the first S>NS GLM\n",
    "len(np.where(nodes_coaxbill_rand_all)[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from multipy.fdr import lsu\n",
    "from corrstats import independent_corr\n",
    "vidnames = [\"COAXING-B\", \"BILLIARD-A\", \"DRIFTING-A\", \"Fishing\", \"Random mechanical\",\"Scaring\", \"SEDUCING-B\", \"STAR-A\", \"SURPRISING-B\", \"TENNIS-A\"]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Traits vs. fmri unmodulated by responses"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from nltools.data import Brain_Data\n",
    "from nltools.mask import expand_mask, roi_to_brain\n",
    "from nilearn.plotting import plot_glass_brain, plot_surf_roi,plot_stat_map,plot_img,plot_surf_contours\n",
    "from nilearn import datasets\n",
    "from nilearn.surface import vol_to_surf\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "from nilearn.datasets import fetch_surf_fsaverage\n",
    "fsaverage = fetch_surf_fsaverage()\n",
    "\n",
    "#coords = [10*int(i) for i in np.linspace(-4,7,6)]\n",
    "bg_img = datasets.load_mni152_template()\n",
    "\n",
    "mask = Brain_Data('https://neurovault.org/media/images/8423/shen_2mm_268_parcellation.nii.gz')\n",
    "mask_x = expand_mask(mask)\n",
    "\n",
    "\n",
    "def color_rois(values):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function assumes you are passing a vector \"values\" with the same length as the number of nodes in the atlas.\n",
    "    \"\"\"\n",
    "    shen268 = nib.load(os.path.join(data_file_loc,\"shen_2mm_268_parcellation.nii.gz\"))\n",
    "    shen268_data = shen268.get_fdata()\n",
    "    img = np.zeros(shen268_data.shape)\n",
    "    #print(shen268_data.shape)\n",
    "    for roi in range(len(values)):\n",
    "        itemindex = np.where(shen268_data==roi+1) # find voxels in this node (add 1 to account for zero-indexing)\n",
    "        #print(len(itemindex[0]))\n",
    "        img[itemindex] = values[roi] # color them by the desired value \n",
    "\n",
    "    affine = shen268.affine\n",
    "    img_nii = nib.Nifti1Image(img, affine)\n",
    "    \n",
    "    return img_nii\n",
    "\n",
    "fig_save_loc = os.path.join('/Users/f0053cz/Dropbox (Dartmouth College)/postdoc_Dartmouth/HCP/paper_prep/figures/fig2_2_traits/fmri_results')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def explore_correlation(x, y, data,corrtype='Spearman'):\n",
    "    \"\"\"\n",
    "    Calculates and plots correlation between x and y variables in dataframe `data`, plus distribution of x and y \n",
    "    \"\"\"\n",
    "    sns.set_style(\"white\")\n",
    "    \n",
    "    inds = ~np.isnan(data[x]) & ~np.isnan(data[y]) # find rows where neither x or y is NaN\n",
    "\n",
    "    g = sns.jointplot(x=x, y=y, data=data, kind='reg', color='gray')\n",
    "\n",
    "    # Calculate and print correlations\n",
    "    if corrtype == 'Pearson':\n",
    "        rp, pp = stats.pearsonr(data[x][inds], data[y][inds])\n",
    "        g.ax_joint.annotate(f'r_p = {rp:.2f} (p={pp:.1g})', xy=(.05,.95), xycoords='axes fraction')\n",
    "    elif corrtype == 'Spearman':\n",
    "        rs, ps = stats.spearmanr(data[x][inds], data[y][inds])\n",
    "        g.ax_joint.annotate(f'r_s = {rs:.2f} (p={ps:.1g})', xy=(.05,.95), xycoords='axes fraction')\n",
    "    \n",
    "    return g"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ALL MOVIES"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# first of all, best to remove subjects with < 10 responses for power in general\n",
    "count_resp = np.zeros((responses.shape[0],))\n",
    "for i in range(responses.shape[0]):\n",
    "    count_resp[i] = len(np.where(~np.isnan(responses[i,:]))[0])\n",
    "subs_10resp = np.where(count_resp == 10)[0]\n",
    "len(subs_10resp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# creating a 3D array of beta coeffs across movies from individual movie files\n",
    "all_coefs_run = np.zeros((1049,268,10))\n",
    "#all_coefs_trial = np.zeros((1049,268,10))\n",
    "\n",
    "vidnames = [\"COAXING-B\", \"BILLIARD-A\", \"DRIFTING-A\", \"Fishing\", \"Random mechanical\",\"Scaring\", \"SEDUCING-B\", \"STAR-A\", \"SURPRISING-B\", \"TENNIS-A\"]\n",
    "for m in range(10):\n",
    "    fileName =  os.path.join(data_file_loc,'coefs_run_norm','slope_reg',f'coef_slopereg_runnorm_{vidnames[m]}{suff}.npy')\n",
    "    #fileName =  os.path.join(data_file_loc,'coefs_trial_norm','slope_reg',f'coef_slopereg_trialnorm_{vidnames[m]}{suff}.npy')\n",
    "    all_coefs_run[:,:,m] = np.load(fileName)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pymer4.models import Lmer # ,Lm # for LME\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = pd.DataFrame({})#columns = ['Subject','coef','response','movie'])\n",
    "n=0\n",
    "nresp = [len(np.where(~np.isnan(responses[i,:]))[0]) for i in range(responses.shape[0])]\n",
    "for m in range(10):\n",
    "    #fMRI_data = pd.DataFrame({'coefs': all_coefs[subs_10resp,n,m],'response':responses[subs_10resp,m], 'subID':sub_id_all[subs_10resp], 'movie':np.repeat(m,len(subs_10resp))})\n",
    "    fMRI_data = pd.DataFrame({'Subject':sub_id_all,'slopeReg_node': all_coefs_run[:,n,m], 'response': responses[:,m],\n",
    "    'nresp':nresp, 'movie': np.repeat(m,1049)})\n",
    "    #fMRI_data = fMRI_data.loc[fMRI_data['nresp']==10,:]\n",
    "    fMRI_data.set_index(\"Subject\", inplace=True)\n",
    "    data_temp = fMRI_data.join(behav_data.loc[:,['ASR_Intn_T','Age_in_Yrs','Gender']], how='inner') # join betas and trait info\n",
    "    data = data.append(data_temp)#,ignore_index=True)\n",
    "data.reset_index(inplace=True)\n",
    "\n",
    "inds = ~np.isnan(data['slopeReg_node']) # find rows with missing fMRI data\n",
    "data = data.loc[inds,:]\n",
    "data.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Demographics for the paper"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "unique_subs = data.drop_duplicates(subset=['Subject'])\n",
    "unique_subs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "unique_subs.groupby(['Gender']).count(),unique_subs['Age_in_Yrs'].describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ALL MOVIES - LME - run norm slope betas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ALL MOVIES - LME - run norm slope betas\n",
    "coef_nodes_all_lme_run,   pval_nodes_all_lme_run   =  [np.empty((268,)) for _ in range(2)] # nodes * responses (non-social, social) - LME\n",
    "coef_nodes_all_lme_run[:],pval_nodes_all_lme_run[:] = [np.nan] *2\n",
    "\n",
    "nsubs_node_all = []\n",
    "nresp = [len(np.where(~np.isnan(responses[i,:]))[0]) for i in range(responses.shape[0])]\n",
    "start_time = time.time()\n",
    "for n in range(268): \n",
    "    if n% 50 ==0:\n",
    "        print('node',n, ', time taken=',time.time()-start_time)\n",
    "\n",
    "    data = pd.DataFrame({})#columns = ['Subject','coef','response','movie'])\n",
    "    for m in range(10):\n",
    "        fMRI_data = pd.DataFrame({'Subject': sub_id_all,'slopeReg_node': all_coefs_run[:,n,m], \n",
    "        'response': responses[:,m],'nresp':nresp, 'movie': np.repeat(m,1049)})\n",
    "        fMRI_data.set_index(\"Subject\", inplace=True)\n",
    "        data_temp = fMRI_data.join(behav_data['ASR_Intn_T'], how='inner') # join betas and trait info\n",
    "        data = data.append(data_temp)#,ignore_index=True)\n",
    "    data.reset_index(inplace=True)\n",
    "\n",
    "    inds = ~np.isnan(data['slopeReg_node']) & ~np.isnan(data['ASR_Intn_T']) # find rows where neither x or y is NaN\n",
    "    data = data.loc[inds,:]\n",
    "    nsubs_node_all.append(len(np.where(np.unique(data['Subject']))[0]))\n",
    "    # Calculate and print correlations\n",
    "    \n",
    "    model2 = Lmer('slopeReg_node ~  ASR_Intn_T + (1|movie)', data=data) # ff: mean response, rf:subjID\n",
    "    model2.fit(summary = False, verbose = False, no_warnings = True)\n",
    "\n",
    "    if (len(model2.warnings) == 0):\n",
    "        coef_nodes_all_lme_run[n] = model2.coefs['Estimate'][1]\n",
    "        pval_nodes_all_lme_run[n] = model2.coefs['P-val'][1]\n",
    "   \n",
    "#pval_nodes_fdr_all_lr_run = lsu(pval_nodes_all_lr_run,q=.05)\n",
    "pval_nodes_all_lme_run_unc = pval_nodes_all_lme_run < .05\n",
    "pval_nodes_fdr_all_lme_run = lsu(pval_nodes_all_lme_run,q=.05)\n",
    "np.where(pval_nodes_fdr_all_lme_run)#, np.where(pval_nodes_fdr_all_lr_run)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# (only subs with all 10 responses) ALL MOVIES - LME - run norm slope betas \n",
    "coef_nodes_all_lme_run_10resp,   pval_nodes_all_lme_run_10resp   =  [np.empty((268,)) for _ in range(2)] # nodes * responses (non-social, social) - LME\n",
    "coef_nodes_all_lme_run_10resp[:],pval_nodes_all_lme_run_10resp[:] = [np.nan] *2\n",
    "\n",
    "nsubs_node_all10 = []\n",
    "nresp = [len(np.where(~np.isnan(responses[i,:]))[0]) for i in range(responses.shape[0])]\n",
    "start_time = time.time()\n",
    "for n in range(268): \n",
    "    if n% 50 ==0:\n",
    "        print('node',n, ', time taken=',time.time()-start_time)\n",
    "\n",
    "    data1 = pd.DataFrame({})#columns = ['Subject','coef','response','movie'])\n",
    "    for m in range(10):\n",
    "        fMRI_data = pd.DataFrame({'Subject':np.array(sub_id_all)[subs_10resp], 'slopeReg_node': all_coefs_run[subs_10resp,n,m],\n",
    "        'response':responses[subs_10resp,m], 'nresp':np.array(nresp)[subs_10resp], 'movie':np.repeat(m,len(subs_10resp))})\n",
    "        fMRI_data.set_index(\"Subject\", inplace=True)\n",
    "        data_temp = fMRI_data.join(behav_data['ASR_Intn_T'], how='inner') # join betas and trait info\n",
    "        data1 = data1.append(data_temp)#,ignore_index=True)\n",
    "    data1.reset_index(inplace=True)\n",
    "\n",
    "    inds = ~np.isnan(data1['slopeReg_node']) & ~np.isnan(data1['ASR_Intn_T']) # find rows where neither x or y is NaN\n",
    "    data1 = data1.loc[inds,:]\n",
    "    # Calculate and print correlations\n",
    "    nsubs_node_all10.append(len(np.where(np.unique(data1['Subject']))[0]))\n",
    "    \n",
    "    model2 = Lmer('slopeReg_node ~  ASR_Intn_T + (1|movie)', data=data1) # ff: mean response, rf:subjID\n",
    "    model2.fit(summary = False, verbose = False, no_warnings = True)\n",
    "\n",
    "    if (len(model2.warnings) == 0):\n",
    "        coef_nodes_all_lme_run_10resp[n] = model2.coefs['Estimate'][1]\n",
    "        pval_nodes_all_lme_run_10resp[n] = model2.coefs['P-val'][1]\n",
    "   \n",
    "#pval_nodes_fdr_all_lr_run = lsu(pval_nodes_all_lr_run,q=.05)\n",
    "pval_nodes_all_lme_run_unc_10resp = pval_nodes_all_lme_run_10resp < .05\n",
    "pval_nodes_fdr_all_lme_run_10resp = lsu(pval_nodes_all_lme_run_10resp,q=.05)\n",
    "np.where(pval_nodes_fdr_all_lme_run_10resp)#, np.where(pval_nodes_fdr_all_lr_run)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# nr of sig. nodes, FDR-corrected and uncorrected\n",
    "print('nsubs=', data.shape, len(np.where(pval_nodes_fdr_all_lme_run)[0]), len(np.where(pval_nodes_all_lme_run<.05)[0]))\n",
    "\n",
    "# ALL 10 RESP; nr of sig. nodes, FDR-corrected and uncorrected\n",
    "print('nsubs=', data1.shape, len(np.where(pval_nodes_fdr_all_lme_run_10resp)[0]), len(np.where(pval_nodes_all_lme_run_10resp<.05)[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "coef_nodes_all_lme_run[pval_nodes_all_lme_run_unc].shape, len(np.where(coef_nodes_all_lme_run[pval_nodes_all_lme_run_unc]>0)[0])\\\n",
    "    , len(np.where(coef_nodes_all_lme_run[pval_nodes_all_lme_run_unc]<0)[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Characterizing correlations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('nr of nodes whose reg coeffts (q<.05 are sig):', coef_nodes_all_lme_run[pval_nodes_fdr_all_lme_run].shape)\n",
    "print('nr of sig (q<.05) nodes whose reg coeffts (i.e., trait-beta_activity) are: ')\n",
    "print('> 0:',len(np.where(coef_nodes_all_lme_run[pval_nodes_fdr_all_lme_run]>0)[0]))\n",
    "print('< 0:',len(np.where(coef_nodes_all_lme_run[pval_nodes_fdr_all_lme_run]<0)[0]))\n",
    "\n",
    "print('only subs with all 10 responses:')\n",
    "print('nr of nodes whose reg coeffts (q<.05 are sig):', coef_nodes_all_lme_run_10resp[pval_nodes_fdr_all_lme_run_10resp].shape)\n",
    "print('nr of sig (q<.05) nodes whose reg coeffts (i.e., trait-beta_activity) are: ')\n",
    "print('> 0:',len(np.where(coef_nodes_all_lme_run_10resp[pval_nodes_fdr_all_lme_run_10resp]>0)[0]))\n",
    "print('< 0:',len(np.where(coef_nodes_all_lme_run_10resp[pval_nodes_fdr_all_lme_run_10resp]<0)[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in np.where(coef_nodes_all_lme_run[pval_nodes_fdr_all_lme_run]>0)[0]:\n",
    "    n = np.where(pval_nodes_fdr_all_lme_run)[0][i]\n",
    "    x = all_coefs_run[:,n,:].flatten()\n",
    "    print(f'Node_ind {n}: {np.nanmean(x):.2f}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How many nodes show activation and how many deactivation here?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## All subs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "df = pd.DataFrame({'Node': [n+1 for n in np.where(pval_nodes_fdr_all_lme_run)[0]], 'reg_coefft':coef_nodes_all_lme_run[pval_nodes_fdr_all_lme_run], \n",
    "'slope_beta': [np.nanmean(all_coefs_run[:,n,:].flatten()) for n in np.where(pval_nodes_fdr_all_lme_run)[0]],\n",
    "'pval':pval_nodes_all_lme_run[pval_nodes_fdr_all_lme_run], \n",
    "'ROI name':[eval(shen268_lbl[str(n+1)][0])['name'] for n in np.where(pval_nodes_fdr_all_lme_run)[0]]}).sort_values(by=['reg_coefft'],ascending = True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## only all 10 subs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df10 = pd.DataFrame({'Node': [n+1 for n in np.where(pval_nodes_fdr_all_lme_run_10resp)[0]], 'reg_coefft':coef_nodes_all_lme_run_10resp[pval_nodes_fdr_all_lme_run_10resp], \n",
    "'slope_beta': [np.nanmean(all_coefs_run[subs_10resp,n,:].flatten()) for n in np.where(pval_nodes_fdr_all_lme_run_10resp)[0]],\n",
    "'pval':pval_nodes_all_lme_run_10resp[pval_nodes_fdr_all_lme_run_10resp], \n",
    "'ROI name':[eval(shen268_lbl[str(n+1)][0])['name'] for n in np.where(pval_nodes_fdr_all_lme_run_10resp)[0]]}).sort_values(by=['reg_coefft'],ascending = True)\n",
    "df10.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Intersection with GLM nodes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('GLM nodes (q<.05 across conditions; black contours in figs:', np.where(nodes_coaxbill_rand_all))\n",
    "print('\\nall subs:')\n",
    "print('all nodes showing trait-dependence (q<.05):', np.where(pval_nodes_fdr_all_lme_run))\n",
    "\n",
    "print('\\nonly subs with all 10 responses:')\n",
    "print('all nodes showing trait-dependence (q<.05):', np.where(pval_nodes_fdr_all_lme_run_10resp))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "GLM_trait_nodes =  np.where(nodes_coaxbill_rand_all& pval_nodes_fdr_all_lme_run)[0]\n",
    "GLM_trait_nodes_unc = np.where(nodes_coaxbill_rand_all& pval_nodes_all_lme_run_unc)[0]\n",
    "print('GLM intersection nodes that also show trait-dependence (FDR):', GLM_trait_nodes, len(GLM_trait_nodes))\n",
    "print('GLM intersection nodes that also show trait-dependence (unc.):', GLM_trait_nodes_unc, len(GLM_trait_nodes_unc))\n",
    "\n",
    "GLM_trait_nodes_10resp =  np.where(nodes_coaxbill_rand_all& pval_nodes_fdr_all_lme_run_10resp)[0]\n",
    "GLM_trait_nodes_unc_10resp = np.where(nodes_coaxbill_rand_all& pval_nodes_all_lme_run_unc_10resp)[0]\n",
    "print('\\n\\nGLM intersection nodes that also show trait-dependence (FDR, ONLY 10 RESP SUBJECTS):', GLM_trait_nodes_10resp, len(GLM_trait_nodes_10resp))\n",
    "print('GLM intersection nodes that also show trait-dependence (unc., ONLY 10 RESP SUBJECTS):', GLM_trait_nodes_unc_10resp, len(GLM_trait_nodes_unc_10resp))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# non-glm nodes showing trait-dependence\n",
    "NoGLM_trait_nodes =  np.where(~nodes_coaxbill_rand_all& pval_nodes_fdr_all_lme_run)[0]\n",
    "print('% of GLM nodes showing trait-dependence:', 100*len(GLM_trait_nodes)/(len(GLM_trait_nodes) + len(NoGLM_trait_nodes)))\n",
    "\n",
    "NoGLM_trait_nodes_10resp =  np.where(~nodes_coaxbill_rand_all& pval_nodes_fdr_all_lme_run_10resp)[0]\n",
    "print('% of GLM nodes showing trait-dependence:', 100*len(GLM_trait_nodes_10resp)/(len(GLM_trait_nodes_10resp) + len(NoGLM_trait_nodes_10resp)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame({'Node': [n+1 for n in GLM_trait_nodes_10resp], 'reg coefft':coef_nodes_all_lme_run[GLM_trait_nodes_10resp],\n",
    "'pval':pval_nodes_all_lme_run[GLM_trait_nodes_10resp], \n",
    "'ROI name':[eval(shen268_lbl[str(n+1)][0])['name'] for n in GLM_trait_nodes_10resp]}).sort_values(by=['reg coefft'],ascending = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nrows = 2 #5\n",
    "ncols= 8\n",
    "fig, axs = plt.subplots(nrows = nrows, ncols= ncols, figsize=(25,20*.4))#(25,20))\n",
    "#for ind, n in enumerate(GLM_trait_nodes):    # all subs\n",
    "for ind, n in enumerate(GLM_trait_nodes_10resp):    # only subs with all 10 responses\n",
    "    row = int(np.floor(ind/ncols))\n",
    "    col = int(ind%ncols)\n",
    "    x = all_coefs_run[:,n,:].flatten()\n",
    "    x = x[~np.isnan(x)]\n",
    "    axs[row,col].boxplot(x, widths = 1)\n",
    "    xmin,xmax = 0,2\n",
    "    plt.xlim(xmin,xmax)\n",
    "    axs[row,col].hlines(0,xmin,xmax, color = 'grey', ls = ':')\n",
    "    plt.ylim(-4,4)\n",
    "    stat_results =  stats.ttest_1samp(x,0)\n",
    "    if stat_results[1] < .001:\n",
    "        suff = '***'\n",
    "    elif stat_results[1] < .01:\n",
    "        suff = '**'\n",
    "    elif stat_results[1] < .05:\n",
    "        suff = '*'\n",
    "    elif stat_results[1] < .1:\n",
    "        suff = '+'\n",
    "    else:\n",
    "        suff = ''\n",
    "\n",
    "    if  stat_results[1] < .05:\n",
    "        if np.nanmean(x) > 0:\n",
    "            axs[row,col].set_title(f'N_ind {n},\\nM={np.nanmean(x):.2f}{suff}', color = 'red')\n",
    "        elif np.nanmean(x) < 0:\n",
    "            axs[row,col].set_title(f'N_ind {n},\\nM={np.nanmean(x):.2f}{suff}', color = 'blue')\n",
    "    else:\n",
    "        axs[row,col].set_title(f'N_ind {n},\\nM={np.nanmean(x):.2f}{suff}')\n",
    "\n",
    "\n",
    "if ncols > 1:\n",
    "     #for ind in range(len(GLM_trait_nodes), int(nrows*ncols)):\n",
    "     for ind in range(len(GLM_trait_nodes_10resp), int(nrows*ncols)):\n",
    "        row = int(np.floor(ind/ncols))\n",
    "        col = int(ind%ncols)\n",
    "        axs[row,col].axis('off')\n",
    "          \n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nrows = 5\n",
    "ncols= 8\n",
    "fig, axs = plt.subplots(nrows = nrows, ncols= ncols, figsize=(25,20))\n",
    "#for ind, n in enumerate(NoGLM_trait_nodes):\n",
    "for ind, n in enumerate(NoGLM_trait_nodes_10resp):    # only subs with all 10 responses\n",
    "    row = int(np.floor(ind/ncols))\n",
    "    col = int(ind%ncols)\n",
    "    x = all_coefs_run[:,n,:].flatten()\n",
    "    x = x[~np.isnan(x)]\n",
    "    axs[row,col].boxplot(x, widths = 1)\n",
    "    xmin,xmax = 0,2\n",
    "    plt.xlim(xmin,xmax)\n",
    "    axs[row,col].hlines(0,xmin,xmax, color = 'grey', ls = ':')\n",
    "    plt.ylim(-4,4)\n",
    "    stat_results =  stats.ttest_1samp(x,0)\n",
    "    if stat_results[1] < .001:\n",
    "        suff = '***'\n",
    "    elif stat_results[1] < .01:\n",
    "        suff = '**'\n",
    "    elif stat_results[1] < .05:\n",
    "        suff = '*'\n",
    "    elif stat_results[1] < .1:\n",
    "        suff = '+'\n",
    "    else:\n",
    "        suff = ''\n",
    "\n",
    "    if  stat_results[1] < .05:\n",
    "        if np.nanmean(x) > 0:\n",
    "            axs[row,col].set_title(f'N_ind {n},\\nM={np.nanmean(x):.2f}{suff}', color = 'red')\n",
    "        elif np.nanmean(x) < 0:\n",
    "            axs[row,col].set_title(f'N_ind {n},\\nM={np.nanmean(x):.2f}{suff}', color = 'blue')\n",
    "    else:\n",
    "        axs[row,col].set_title(f'N_ind {n},\\nM={np.nanmean(x):.2f}{suff}')\n",
    "\n",
    "if ncols > 1:\n",
    "     for ind in range(len(NoGLM_trait_nodes_10resp), int(nrows*ncols)):\n",
    "        row = int(np.floor(ind/ncols))\n",
    "        col = int(ind%ncols)\n",
    "        axs[row,col].axis('off')\n",
    "          \n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Uncorrected overla\n",
    "x = np.where((coef_nodes_all_lme_run>0) & (pval_nodes_all_lme_run_unc))[0]\n",
    "print('Unc:\\n', [[n,eval(shen268_lbl[str(n+1)][0])['name']] for n in x])\n",
    "\n",
    "x =  np.where((coef_nodes_all_lme_run>0) & (pval_nodes_fdr_all_lme_run))[0] #np.where(coef_nodes_all_lme_run[pval_nodes_fdr_all_lme_run]>0)[0]\n",
    "print('\\nFDR-corr:\\n', [[n,eval(shen268_lbl[str(n+1)][0])['name']] for n in x])\n",
    "\n",
    "x = np.where((coef_nodes_all_lme_run_10resp>0) & (pval_nodes_all_lme_run_unc_10resp))[0]\n",
    "print('\\nUnc:\\n', [[n,eval(shen268_lbl[str(n+1)][0])['name']] for n in x])\n",
    "\n",
    "x =  np.where((coef_nodes_all_lme_run_10resp>0) & (pval_nodes_fdr_all_lme_run_10resp))[0] #np.where(coef_nodes_all_lme_run[pval_nodes_fdr_all_lme_run]>0)[0]\n",
    "print('\\nFDR-corr:\\n', [[n,eval(shen268_lbl[str(n+1)][0])['name']] for n in x])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n = 121\n",
    "data = pd.DataFrame({})#columns = ['Subject','coef','response','movie'])\n",
    "for m in range(10):\n",
    "    fMRI_data = pd.DataFrame({'Subject':np.array(sub_id_all)[subs_10resp],'slopeReg_node': all_coefs_run[subs_10resp,n,m], \n",
    "    'response': responses[subs_10resp,m],'nresp':np.array(nresp)[subs_10resp], 'movie': np.repeat(m,subs_10resp.shape[0])})\n",
    "    fMRI_data.set_index(\"Subject\", inplace=True)\n",
    "    data_temp = fMRI_data.join(behav_data['ASR_Intn_T'], how='inner') # join betas and trait info\n",
    "    data = data.append(data_temp)#,ignore_index=True)\n",
    "data.reset_index(inplace=True)     \n",
    "inds = ~np.isnan(data['slopeReg_node']) & ~np.isnan(data['ASR_Intn_T']) # find rows where neither x or y is NaN\n",
    "data = data.loc[inds,:]\n",
    "\n",
    "avg, sem = data[['slopeReg_node','ASR_Intn_T','Subject']].groupby(['Subject']).mean(), data[['slopeReg_node','ASR_Intn_T','Subject']].groupby(['Subject']).sem()\n",
    "explore_correlation(x='ASR_Intn_T',y='slopeReg_node', data = avg)\n",
    "\n",
    "model2 = Lmer('slopeReg_node ~  ASR_Intn_T + (1|movie)', data=data) # ff: mean response, rf:subjID\n",
    "model2.fit()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_result_brainmaps(nodes,  contours_mat, intersection_, params,text_x,suff):\n",
    "    cmap = 'RdBu_r'\n",
    "\n",
    "    #levels,labels,colors,coods = params['levels'],params['labels'],params['colors'],params['coords']\n",
    "    colors, coods, vmin, vmax, txt , title_txt = \\\n",
    "        params['color'], params['coords'], params['vmin'], params['vmax'], params['txt'], params['title_txt']\n",
    "\n",
    "    img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "    ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords = coords,cmap = cmap, bg_img = bg_img,\n",
    "    colorbar= False,threshold = .0001)\n",
    "    ax_plot.add_contours(color_rois((intersection_)),linewidths=.5, colors=[colors[0]],linestyles='solid') # GLM nodes\n",
    "    plt.savefig(os.path.join(fig_save_loc,f'ALL/axial{suff}.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "\n",
    "    fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "    \n",
    "    #LH (left hemisphere)\n",
    "    ax1 = ax[0,0] # left lateral\n",
    "    texture = vol_to_surf(color_rois(nodes), fsaverage.pial_left,interpolation='nearest',radius =1, n_samples=1)\n",
    "    surf_plot1=plot_surf_roi(fsaverage.infl_left, texture, hemi='left',cmap = cmap, colorbar=False, symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                                bg_map=fsaverage.sulc_left,axes=ax1)#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "     \n",
    "    texture_contour = vol_to_surf(color_rois(contours_mat), fsaverage.pial_left,interpolation='nearest',radius =1, n_samples=1)\n",
    "    plot_surf_contours(fsaverage.infl_left, texture_contour, axes = ax1, figure=surf_plot1, legend=False, levels = [1], colors=colors)\n",
    "\n",
    "    ax1 = ax[1,0] # left medial\n",
    "    surf_plot2=plot_surf_roi(fsaverage.infl_left, texture, hemi='left',cmap = cmap, colorbar=False, symmetric_cmap=True, vmin = vmin,\\\n",
    "         vmax = vmax, bg_map=fsaverage.sulc_left, view = 'medial',axes=ax1)#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "    plot_surf_contours(fsaverage.infl_left, texture_contour, axes = ax1, figure=surf_plot2, legend=True, levels = [1],colors=colors)\n",
    "\n",
    "    #RH (right hemisphere)\n",
    "    ax1 = ax[0,1] # right lateral\n",
    "    texture = vol_to_surf(color_rois(nodes), fsaverage.pial_right,interpolation='nearest',radius =1, n_samples=1)\n",
    "    surf_plot3=plot_surf_roi(fsaverage.infl_right, texture, hemi='right',cmap = cmap, colorbar=True,symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                                bg_map=fsaverage.sulc_right,axes=ax1)#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "    texture_contour = vol_to_surf(color_rois(contours_mat), fsaverage.pial_right,interpolation='nearest',radius = 1, n_samples=1)\n",
    "    plot_surf_contours(fsaverage.infl_right, texture_contour, axes = ax1, figure=surf_plot3, legend=False,levels = [1],colors=colors)\n",
    "    \n",
    "    box = surf_plot3.axes[4].get_position()\n",
    "    surf_plot3.axes[4].set_position([box.x0*.93, box.y0-.3, box.width, box.height*2])  # move a bit the bar to the right, need to divide by number of columns (to move relative to last figure only, not to overall row, else will get too far away)\n",
    "    \n",
    "    ax1 = ax[1,1] # right medial\n",
    "    surf_plot4=plot_surf_roi(fsaverage.infl_right, texture, hemi='right',cmap = cmap, colorbar=False,symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                                bg_map=fsaverage.sulc_right, view ='medial',axes=ax1)#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "    plot_surf_contours(fsaverage.infl_right, texture_contour, axes = ax1, figure=surf_plot4, levels = [1], colors=colors)\n",
    "    \n",
    "    ax[0,0].dist = 7 # change viewing distance to \"zoom in\" to surface plots\n",
    "    ax[0,1].dist = 7\n",
    "    ax[1,0].dist = 7\n",
    "    ax[1,1].dist = 7\n",
    "    \n",
    "    plt.subplots_adjust(left=0,\n",
    "                        bottom=0, \n",
    "                        right=.8, \n",
    "                        top=1, \n",
    "                        wspace=0.0, \n",
    "                        hspace=-.1)\n",
    "    plt.savefig(os.path.join(fig_save_loc,f'ALL/surf_all4{suff}.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# only subs with all 10 responses\n",
    "coords = [-44,-34,-24] # for the final version\n",
    "cmap = 'RdBu_r'\n",
    "   \n",
    "vmin,vmax = -.006,.006\n",
    "txt = 'LME\\nEstimate'\n",
    "\n",
    "nodes = np.zeros((268,))\n",
    "nodes[pval_nodes_fdr_all_lme_run_10resp] = coef_nodes_all_lme_run_10resp[pval_nodes_fdr_all_lme_run_10resp]\n",
    "\n",
    "title_txt = \"\" #title_txt = r\"    Trait-fMRI correlation, all animations\" # (nodes unc.)'\n",
    "\n",
    "contours_mat = np.zeros((268,))\n",
    "contours_mat[nodes_coaxbill_rand_all] = 1\n",
    "\n",
    "params = {'color': ['k'], 'coords': coords, 'vmin':vmin, 'vmax': vmax, 'txt': txt , 'title_txt': title_txt}\n",
    "text_x = 7\n",
    "suff = '_all_only10subs'\n",
    "plot_result_brainmaps(nodes, contours_mat, nodes_coaxbill_rand_all, params, text_x,suff)\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('py37': conda)"
  },
  "interpreter": {
   "hash": "30fd9c97283ec1278eec212a8f8afab06ad903f38228c32cacb469eba8e56f4f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}