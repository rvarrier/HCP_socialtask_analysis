{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "- Analyses comparing the interaction between traits, responses and fMRI beta slope regressors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read in restricted behavioral data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "res_behav_data = pd.read_csv('../data/RESTRICTED_esfinn_11_21_2021_19_19_35.csv')\n",
    "res_behav_data.set_index(\"Subject\", inplace=True)\n",
    "res_behav_data.index = res_behav_data.index.map(str)\n",
    "print(res_behav_data.shape)\n",
    "res_behav_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read in unrestricted behavioral data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "unres_behav_data = pd.read_csv('../data/unrestricted_esfinn_11_21_2021_19_19_13.csv')\n",
    "unres_behav_data.set_index(\"Subject\", inplace=True)\n",
    "unres_behav_data.index = unres_behav_data.index.map(str)\n",
    "print(unres_behav_data.shape)\n",
    "unres_behav_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Combine restricted and unrestricted behavioral data into a single dataframe:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "behav_data = pd.concat([res_behav_data, unres_behav_data], axis=1)\n",
    "print(behav_data.shape)\n",
    "behav_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read in FMRI data, join into single dataframe, then join this with the larger dataframe:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_file_loc = '/Users/f0053cz/Dropbox (Dartmouth College)/postdoc_Dartmouth/HCP/fMRIScipts/data'\n",
    "sub_id_all = np.load(os.path.join(data_file_loc,'sub_ID_all.npy'))\n",
    "sub_id_all = [str(i) for i in sub_id_all]\n",
    "print(len(sub_id_all),sub_id_all[:5])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load behavioral responses too - to identify missed/invalid trials later - 1 for \"social\", 0 for \"nonsocial\" and 9 for \"unsure\", nan for missed response\n",
    "responses = np.load(os.path.join(data_file_loc,'responses.npy'))\n",
    "responses.shape # subs *movies"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load slope regression coefficents for the fMRI data\n",
    "coef_slope_rand = np.load(os.path.join(data_file_loc,'coefs_run_norm','slope_reg','coef_slopereg_runnorm_Random mechanical.npy'))\n",
    "coef_slope_fish = np.load(os.path.join(data_file_loc,'coefs_run_norm','slope_reg','coef_slopereg_runnorm_Fishing.npy'))\n",
    "coef_slope_coax = np.load(os.path.join(data_file_loc,'coefs_trial_norm','slope_reg','coef_slopereg_trialnorm_COAXING-B.npy'))\n",
    "coef_slope_bill = np.load(os.path.join(data_file_loc,'coefs_trial_norm','slope_reg','coef_slopereg_trialnorm_BILLIARD-A.npy'))\n",
    "coef_slope_all  = np.load(os.path.join(data_file_loc,'coef_slopereg_all.npy'))\n",
    "\n",
    "print(coef_slope_rand.shape)\n",
    "coef_slope_all.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "shen268_lbl = pd.read_csv(os.path.join(data_file_loc,\"shen_dictionary.csv\"))\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "shen268_lbl.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for comparison with the other main figure if needed\n",
    "nodes_coaxbill_rand_all = np.load(os.path.join(data_file_loc,'nodes_coaxbill_rand_all.npy')) # sig nodes hihglighted in the first S>NS GLM\n",
    "len(np.where(nodes_coaxbill_rand_all)[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Directly compare \"Social\" and \"Non-social\" using a linear regression for RANDOM MECH (and maybe FISHING)\n",
    "\n",
    "\n",
    "Procedure:\n",
    "1. compare the models: bold = b0+b1*response, bold = b0 + b1*response + b2*traits + b3*traits*responses, and bold = b0 + b1*response + b2*traits + b3*traits*responses\n",
    "2. select nodes for which the second model (or third depending on what we're looking for) is better AIC-wise\n",
    "3. extract coeffts for these nodes alone (redo another LR just for these nodes), fdr-correct and check nodes for significance.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from multipy.fdr import lsu\n",
    "from pymer4.models import Lm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## RANDOM MECH\n",
    "# find out in which nodes AIC decreases with trait terms\n",
    "# model 1: factor: responses\n",
    "# model 2: factor: responses, traits (no interactions)\n",
    "# model 3: factors: traits, responses, their interaction\n",
    "\n",
    "coef_nodes_rand_lr_model1, pval_nodes_rand_lr_model1 = [np.empty((268, )) for _ in range(2)]\n",
    "coef_nodes_rand_lr_model2, pval_nodes_rand_lr_model2 = [np.empty((268,2)) for _ in range(2)]\n",
    "coef_nodes_rand_lr_model3, pval_nodes_rand_lr_model3 = [np.empty((268,3)) for _ in range(2)]\n",
    "coef_nodes_rand_lr_model1[:],pval_nodes_rand_lr_model1[:],coef_nodes_rand_lr_model2[:],pval_nodes_rand_lr_model2[:],coef_nodes_rand_lr_model3[:],pval_nodes_rand_lr_model3[:]  = [np.nan]*6\n",
    "\n",
    "aic_nodes_rand_lr = np.empty((268,3))\n",
    "aic_nodes_rand_lr[:] = np.nan\n",
    "\n",
    "for n in range(268): \n",
    "    if n% 50 ==0:\n",
    "        print('node',n)\n",
    "    fMRI_data = pd.DataFrame({'Subject':sub_id_all,'slopeReg_node':coef_slope_rand[:,n], 'responses':responses[:,4]})\n",
    "    fMRI_data.set_index(\"Subject\", inplace=True)\n",
    "    data = fMRI_data.join(behav_data, how='inner') # join betas and trait info\n",
    "    data.reset_index(inplace=True)\n",
    "    data = data.loc[:,['Subject','slopeReg_node','responses','ASR_Intn_T']]\n",
    "    \n",
    "    d = data.loc[(data['responses']==0)|(data['responses']==1),:]\n",
    "    ind = (~np.isnan(d['slopeReg_node'])) & (~np.isnan(d['ASR_Intn_T'])) & (~np.isnan(d['responses']))\n",
    "    d = d.loc[ind,:]\n",
    "    \n",
    "    model1 = Lm(\"slopeReg_node ~ responses\", data=d)\n",
    "    model1.fit(summary = False, verbose = False)\n",
    "    \n",
    "    model2 = Lm(\"slopeReg_node ~ responses + ASR_Intn_T\", data=d)\n",
    "    model2.fit(summary = False, verbose = False)\n",
    "\n",
    "    model3 = Lm(\"slopeReg_node ~ responses + ASR_Intn_T + responses*ASR_Intn_T\", data=d)\n",
    "    model3.fit(summary = False, verbose = False)\n",
    "    #model.fit(factors={\"response\":[\"Social\",\"Unsure\"]},summary = False, verbose = False) # Unsure > Social\n",
    "   \n",
    "    if n == 0:\n",
    "        print(model1.fit())#factors={\"response\":[\"Social\",\"Unsure\"]}))\n",
    "        print(model2.fit())\n",
    "        print(model3.fit())\n",
    "\n",
    "    if (len(model1.warnings) == 0):\n",
    "        coef_nodes_rand_lr_model1[n] = model1.coefs['Estimate'][1]\n",
    "        pval_nodes_rand_lr_model1[n] = model1.coefs['P-val'][1]\n",
    "        aic_nodes_rand_lr[n,0] = model1.AIC\n",
    "\n",
    "    if (len(model2.warnings) == 0):\n",
    "        for ind in range(2):\n",
    "            coef_nodes_rand_lr_model2[n,ind] = model2.coefs['Estimate'][ind+1]\n",
    "            pval_nodes_rand_lr_model2[n,ind] = model2.coefs['P-val'][ind+1]\n",
    "        aic_nodes_rand_lr[n,1] = model2.AIC\n",
    "\n",
    "    if (len(model3.warnings) == 0):\n",
    "        for ind in range(3):\n",
    "            coef_nodes_rand_lr_model3[n,ind] = model3.coefs['Estimate'][ind+1]\n",
    "            pval_nodes_rand_lr_model3[n,ind] = model3.coefs['P-val'][ind+1]\n",
    "        aic_nodes_rand_lr[n,2] = model3.AIC\n",
    "\n",
    "pval_nodes_fdr_rand_lr_model1 = lsu(pval_nodes_rand_lr_model1,q=.05)\n",
    "\n",
    "pval_nodes_fdr_rand_lr_model2 = np.empty_like(pval_nodes_rand_lr_model2)\n",
    "pval_nodes_fdr_rand_lr_model2[:]=np.nan\n",
    "for ind in range(2):\n",
    "    pval_nodes_fdr_rand_lr_model2[:,ind] = lsu(pval_nodes_rand_lr_model2[:,ind],q=.05)\n",
    "\n",
    "pval_nodes_fdr_rand_lr_model3 = np.empty_like(pval_nodes_rand_lr_model3)\n",
    "pval_nodes_fdr_rand_lr_model3[:]=np.nan\n",
    "for ind in range(3):\n",
    "    pval_nodes_fdr_rand_lr_model3[:,ind] = lsu(pval_nodes_rand_lr_model3[:,ind],q=.05)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "aic_nodes_rand_lr1 = np.empty_like(aic_nodes_rand_lr)\n",
    "for i in [2,1,0]:\n",
    "    aic_nodes_rand_lr1[:,i] = aic_nodes_rand_lr[:,i]- aic_nodes_rand_lr[:,0]\n",
    "    #aic_nodes_corr_fish_lr[:,i] = aic_nodes_corr_fish_lr[:,i]- aic_nodes_corr_fish_lr[:,0]\n",
    "\n",
    "plt.figure(1,figsize=(5,10))\n",
    "plt.plot(aic_nodes_rand_lr1.T)\n",
    "plt.xticks(range(3),['only response','response+\\ntraits','response+\\ntraits+\\ninteraxn'])\n",
    "plt.hlines(-2,0,2,'grey',ls='dotted')\n",
    "plt.ylabel('AIC - \\nAIC(reponse-only model)')\n",
    "plt.xlabel('models (simple to complex -->)')\n",
    "plt.title('RANDOM MECH')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rand_nodes_add_traits = np.where((aic_nodes_rand_lr1[:,1]<-2))[0] #  response only v. trait main\n",
    "print(len(nodes_traits),rand_nodes_add_traits)\n",
    "\n",
    "rand_nodes_add_traits_interaxn = np.where(aic_nodes_rand_lr1[:,2]<-2)[0] #  trait main v. trait main+int\n",
    "print(len(nodes_traits),rand_nodes_add_traits_interaxn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# response only v. responses+ traits\n",
    "\n",
    "def get_sig_nodes(pval,nodes):\n",
    "    try:\n",
    "        terms =  pval.shape[1]\n",
    "    except:\n",
    "        terms = 1\n",
    "        pval = pval[:,np.newaxis]\n",
    "    #print(terms)\n",
    "    all_nodes =  np.empty((268,terms))\n",
    "    all_nodes[:] = np.nan\n",
    "    for i in range(terms):\n",
    "        all_nodes[nodes,i] = pval[nodes,i]\n",
    "    return [['term '+str(i+1),np.where(all_nodes[:,i]==1)[0]] for i in range(terms)]\n",
    "\n",
    "print('FDR-corr. response-only vs. responses+traits')\n",
    "print('response only:')\n",
    "print(get_sig_nodes(pval_nodes_fdr_rand_lr_model1, rand_nodes_add_traits))\n",
    "print('\\nresponse + traits:')\n",
    "print(get_sig_nodes(pval_nodes_fdr_rand_lr_model2, rand_nodes_add_traits))\n",
    "\n",
    "# response only v. responses+ traits + interaction\n",
    "'''print('\\n\\nFDR-corr. response-only vs. responses+traits+interaction')\n",
    "print('response only:')\n",
    "print(get_sig_nodes(pval_nodes_fdr_rand_lr_model1,rand_nodes_add_traits_interaxn))\n",
    "print('\\nresponse + traits + interactionn:')\n",
    "get_sig_nodes(pval_nodes_fdr_rand_lr_model3,rand_nodes_add_traits_interaxn)'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- So no significat term for 'traits' at the corrected level, and we get one additional sig. term for  'responses' - prob because it improves the model fit \n",
    "- How about at the uncorrected thresholds?\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#response only v. responses+ traits\n",
    "print('Unc. response-only vs. responses+traits')\n",
    "print('response only:')\n",
    "print(get_sig_nodes(pval_nodes_rand_lr_model1<.05,rand_nodes_add_traits))\n",
    "print('\\nresponse + traits:')\n",
    "print(get_sig_nodes(pval_nodes_rand_lr_model2<.05,rand_nodes_add_traits))\n",
    "\n",
    "# response only v. responses+ traits + interaction\n",
    "'''print('\\n\\nUnc. response-only vs. responses+traits+interaction')\n",
    "print('response only:')\n",
    "print(get_sig_nodes(pval_nodes_rand_lr_model1<.05,rand_nodes_add_traits_interaxn))\n",
    "print('\\nresponse + traits + interactionn:')\n",
    "get_sig_nodes(pval_nodes_rand_lr_model3<.05,rand_nodes_add_traits_interaxn)'''\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- There are several nodes showing a significant 'traits' term but at the unc. threshold"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# unc. threshold so don't take to heart. what are these regions though?\n",
    "for n in rand_nodes_add_traits:\n",
    "    print(n+1,eval(shen268_lbl[str(n+1)][0])['name'])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- mostly brainstem regions. Maybe more power with ALL MOVIES?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ALL MOVIES : Directly compare \"Social\" and \"Non-social\" using lr for ALL MOVIES\n",
    "\n",
    "\n",
    "Procedure:\n",
    "1. compare the models: bold = b0+b1*response, bold = b0 + b1*response + b2*traits + b3*traits*responses, and bold = b0 + b1*response + b2*traits + b3*traits*responses - subject as random factor in all models\n",
    "2. select nodes for which the second model (or third depending on what we're looking for) is better AIC-wise\n",
    "3. extract coeffts for these nodes alone (redo another LR just for these nodes), fdr-correct and check nodes for significance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# first of all, best to remove subjects with < 10 responses for power in general\n",
    "count_resp = np.zeros((responses.shape[0],))\n",
    "for i in range(responses.shape[0]):\n",
    "    count_resp[i] = len(np.where(~np.isnan(responses[i,:]))[0])\n",
    "subs_10resp = np.where(count_resp == 10)[0]\n",
    "len(subs_10resp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# creating a 3D array of beta coeffs across movies from individual movie files\n",
    "all_coefs = np.zeros((1048,268,10))\n",
    "\n",
    "vidnames = [\"COAXING-B\", \"BILLIARD-A\", \"DRIFTING-A\", \"Fishing\", \"Random mechanical\",\"Scaring\", \"SEDUCING-B\", \"STAR-A\", \"SURPRISING-B\", \"TENNIS-A\"]\n",
    "for m in range(10):\n",
    "    fileName =  os.path.join(data_file_loc,'coefs_run_norm','slope_reg',f'coef_slopereg_runnorm_{vidnames[m]}.npy')\n",
    "    all_coefs[:,:,m] = np.load(fileName)\n",
    "    #print(dat.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pymer4.models import Lm\n",
    "from multipy.fdr import lsu\n",
    "#from pymer4.models import Lmer\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# same analysis as above, all nodes\n",
    "# ALL MOVIES\n",
    "\n",
    "coef_nodes_all_model1,   pval_nodes_all_model1    = [np.empty((268,)) for _ in range(2)]\n",
    "coef_nodes_all_model1[:],pval_nodes_all_model1[:] = [np.nan] *2\n",
    "\n",
    "coef_nodes_all_model2,   pval_nodes_all_model2    = [np.empty((268,2)) for _ in range(2)]\n",
    "coef_nodes_all_model2[:],pval_nodes_all_model2[:] = [np.nan] *2\n",
    "\n",
    "coef_nodes_all_model3,   pval_nodes_all_model3    = [np.empty((268,3)) for _ in range(2)]\n",
    "coef_nodes_all_model3[:],pval_nodes_all_model3[:] = [np.nan] *2\n",
    "\n",
    "aic_nodes_all_lme = np.empty((268,3))\n",
    "aic_nodes_all_lme[:] = np.nan\n",
    "\n",
    "pval_nodes_fdr_all_model1 = np.empty_like(pval_nodes_all_model1)\n",
    "pval_nodes_fdr_all_model1[:] = np.nan\n",
    "\n",
    "pval_nodes_fdr_all_model2 = np.empty_like(pval_nodes_all_model2)\n",
    "pval_nodes_fdr_all_model2[:] = np.nan\n",
    "\n",
    "pval_nodes_fdr_all_model3 = np.empty_like(pval_nodes_all_model3)\n",
    "pval_nodes_fdr_all_model3[:] = np.nan\n",
    "\n",
    "nresp = [len(np.where(~np.isnan(responses[i,:]))[0]) for i in range(responses.shape[0])]\n",
    "start_time = time.time()\n",
    "for n in range(268):\n",
    "    if n% 50 ==0:\n",
    "        print(f'node_ind  {n}, time taken: {time.time()-start_time:.2f}')\n",
    "    \n",
    "    data = pd.DataFrame({})#columns = ['Subject','coef','response','movie'])\n",
    "    for m in range(10):\n",
    "        #fMRI_data = pd.DataFrame({'coefs': all_coefs[subs_10resp,n,m],'response':responses[subs_10resp,m], 'subID':sub_id_all[subs_10resp], 'movie':np.repeat(m,len(subs_10resp))})\n",
    "        fMRI_data = pd.DataFrame({'Subject':sub_id_all,'coef': all_coefs[:,n,m], 'response': responses[:,m],'nresp':nresp, 'movie': np.repeat(m,1048)})\n",
    "        fMRI_data = fMRI_data.loc[fMRI_data['nresp']==10,:]\n",
    "        fMRI_data.set_index(\"Subject\", inplace=True)\n",
    "        data_temp = fMRI_data.join(behav_data['ASR_Intn_T'], how='inner') # join betas and trait info\n",
    "        data = data.append(data_temp)#,ignore_index=True)\n",
    "    data.reset_index(inplace=True)\n",
    "    #if n == 0:\n",
    "    #    print(data.shape)\n",
    "    #    print(data.head())\n",
    "    \n",
    "    #d = data.loc[data['responses']==10,:]\n",
    "    inds = ~np.isnan(data['coef']) & ~np.isnan(data['ASR_Intn_T']) & (data['response']!=9) # find rows where neither x or y is NaN\n",
    "    data = data.loc[inds,:]\n",
    "    # Calculate and print correlations\n",
    "    \n",
    "    #model1 = Lmer('coef ~  response + (1|movie)', data=data) # ff: mean response, rf:subjID\n",
    "    model1 = Lm('coef ~  response', data=data) # ff: mean response, rf:subjID\n",
    "    model1.fit(summary = False, verbose = False, no_warnings = True)\n",
    "    #model.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "\n",
    "    #model2 = Lmer('coef ~  response + ASR_Intn_T + (1|movie)', data=data) # ff: mean response, rf:subjID\n",
    "    model2 = Lm('coef ~  response + ASR_Intn_T', data=data) # ff: mean response, rf:subjID\n",
    "    model2.fit(summary = False, verbose = False, no_warnings = True)\n",
    "\n",
    "    #model3 = Lmer('coef ~  response + ASR_Intn_T + response*ASR_Intn_T + (1|movie) ', data=data) # ff: mean response, rf:subjID\n",
    "    model3 = Lm('coef ~  response + ASR_Intn_T + response*ASR_Intn_T', data=data) # ff: mean response, rf:subjID\n",
    "    model3.fit(summary = False, verbose = False, no_warnings = True)\n",
    "\n",
    "    #model.fit(summary = False, verbose = False)\n",
    "    if (len(model1.warnings) == 0):\n",
    "        coef_nodes_all_model1[n] = model1.coefs['Estimate'][1]\n",
    "        pval_nodes_all_model1[n]= model1.coefs['P-val'][1]\n",
    "        aic_nodes_all_lme[n,0] = model1.AIC\n",
    "\n",
    "    if (len(model2.warnings) == 0):\n",
    "        for ind in range(2):\n",
    "            coef_nodes_all_model2[n,ind] = model2.coefs['Estimate'][ind+1]\n",
    "            pval_nodes_all_model2[n,ind] = model2.coefs['P-val'][ind+1]\n",
    "        aic_nodes_all_lme[n,1] = model2.AIC\n",
    "\n",
    "    if (len(model3.warnings) == 0):\n",
    "        for ind in range(3):\n",
    "            coef_nodes_all_model3[n,ind] = model3.coefs['Estimate'][ind+1]\n",
    "            pval_nodes_all_model3[n,ind] = model3.coefs['P-val'][ind+1]\n",
    "        aic_nodes_all_lme[n,2] = model3.AIC\n",
    "\n",
    "pval_nodes_fdr_all_model1 = lsu(pval_nodes_all_model1,q=.05)\n",
    "\n",
    "for ind in range(2):\n",
    "    pval_nodes_fdr_all_model2[:,ind] = lsu(pval_nodes_all_model2[:,ind],q=.05)\n",
    "\n",
    "for ind in range(3):\n",
    "    pval_nodes_fdr_all_model3[:,ind] = lsu(pval_nodes_all_model3[:,ind],q=.05)\n",
    " "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "aic_nodes_all_lme1 = np.empty((268,3))\n",
    "aic_nodes_all_lme1[:] = np.nan\n",
    "for i in [2,1,0]:\n",
    "    aic_nodes_all_lme1[:,i] = aic_nodes_all_lme[:,i]- aic_nodes_all_lme[:,0]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(1,figsize=(5,10))\n",
    "plt.plot(aic_nodes_all_lme1.T)\n",
    "plt.xticks(range(3),['only response','response+\\ntraits','response+\\ntraits+\\ninteraxn'])\n",
    "plt.hlines(-2,0,2,'grey',ls='dotted')\n",
    "plt.ylabel('AIC - \\nAIC(reponse-only model)')\n",
    "plt.xlabel('models (simple to complex -->)')\n",
    "plt.title('ALL MOVIES (linear regressions)')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "allmovies_nodes_add_traits = np.where((aic_nodes_all_lme1[:,1]<-2))[0] #  response only v. trait main\n",
    "print(len(nodes_traits),allmovies_nodes_add_traits)\n",
    "\n",
    "allmovies_nodes_add_traits_interaxn = np.where(aic_nodes_all_lme1[:,2]<-2)[0] #  trait main v. trait main+int\n",
    "print(len(nodes_traits),allmovies_nodes_add_traits_interaxn)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def intersection(lst1, lst2):\n",
    "    \n",
    "    if type(lst1) != 'list':\n",
    "        lst1 = list(lst1)\n",
    "    \n",
    "    if type(lst2) != 'list':\n",
    "        lst2 = list(lst2)\n",
    "    \n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3\n",
    "\n",
    "intersection (allmovies_nodes_add_traits, rand_nodes_add_traits)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('FDR-corr. response-only vs. responses+traits')\n",
    "print('response only:')\n",
    "print(get_sig_nodes(pval_nodes_fdr_all_model1, allmovies_nodes_add_traits))\n",
    "print('\\nresponse + traits:')\n",
    "print(get_sig_nodes(pval_nodes_fdr_all_model2, allmovies_nodes_add_traits))\n",
    "\n",
    "\n",
    "#response only v. responses+ traits\n",
    "print('\\n\\nUnc. response-only vs. responses+traits')\n",
    "print('response only:')\n",
    "print(get_sig_nodes(pval_nodes_all_model2<.05,allmovies_nodes_add_traits))\n",
    "print('\\nresponse + traits:')\n",
    "print(get_sig_nodes(pval_nodes_all_model2<.05,allmovies_nodes_add_traits))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## COAX-BILL"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- If coax-bill or all movies overlap with RANDOM MECH at least, what we did makes sense - too weak otherwise"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# same analysis as above, all nodes\n",
    "# COAX-BILL\n",
    "corrtype = 'Spearman' # 'Pearson'\n",
    "x = \"slopeReg_diff\"\n",
    "#y = \"Loneliness_Unadj\"\n",
    "y = \"ASR_Intn_T\"\n",
    "\n",
    "corr_nodes_coaxbill,   pval_nodes_coaxbill    =  [np.empty((268,)) for _ in range(2)]\n",
    "corr_nodes_coaxbill[:],pval_nodes_coaxbill[:] = [np.nan] *2\n",
    "\n",
    "pval_nodes_fdr_coaxbill = np.empty_like(pval_nodes_coaxbill)\n",
    "pval_nodes_fdr_coaxbill[:] = np.nan\n",
    "\n",
    "sig_nodes = np.where(nodes_coaxbill_rand_all)[0] # nodes sig in the main GLM analysis\n",
    "\n",
    "for n in sig_nodes:\n",
    "#for n in range(268): \n",
    "    #if n% 50 ==0:\n",
    "    print('node',n)\n",
    "\n",
    "    fMRI_data = pd.DataFrame({'Subject':sub_id_all,'slopeReg_diff':coef_slope_coax[:,n]-coef_slope_bill[:,n], 'responses':(responses[:,0]==1)&(responses[:,1]==0)})\n",
    "    fMRI_data.set_index(\"Subject\", inplace=True)\n",
    "    data = fMRI_data.join(behav_data, how='inner') # join betas and trait info\n",
    "    #if n == 0:\n",
    "    #    print(data.shape)\n",
    "    #    print(data.head())\n",
    "    \n",
    "    d = data.loc[data['responses']==True,:]\n",
    "    inds = ~np.isnan(d[x]) & ~np.isnan(d[y]) # find rows where neither x or y is NaN\n",
    "    \n",
    "    # Calculate and print correlations\n",
    "    if corrtype == 'Pearson':\n",
    "        corr_nodes_coaxbill[n], pval_nodes_coaxbill[n] = stats.pearsonr(d[x][inds], d[y][inds])\n",
    "    elif corrtype =='Spearman':\n",
    "        corr_nodes_coaxbill[n], pval_nodes_coaxbill[n] = stats.spearmanr(d[x][inds], d[y][inds])\n",
    "\n",
    "pval_nodes_fdr_coaxbill[sig_nodes] = lsu(pval_nodes_coaxbill[sig_nodes],q=.05)\n",
    "pval_ = lsu(pval_nodes_coaxbill[sig_nodes],q=.05)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Nodes sig. at the corrected threshold:', np.where(pval_nodes_fdr_coaxbill[sig_nodes]))\n",
    "print('Nodes sig. at the unc. threshold:',sig_nodes[pval_nodes_coaxbill[sig_nodes] <.05],',p-values:',pval_nodes_coaxbill[sig_nodes][pval_nodes_coaxbill[sig_nodes] <.05])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# intersection with the other analyses?\n",
    "\n",
    "print(intersection(sig_nodes[pval_nodes_coaxbill[sig_nodes] <.05],rand_nodes_add_traits))\n",
    "print(intersection(sig_nodes[pval_nodes_coaxbill[sig_nodes] <.05],rand_nodes_add_traits_interaxn))\n",
    "print(intersection(sig_nodes[pval_nodes_coaxbill[sig_nodes] <.05],allmovies_nodes_add_traits))\n",
    "print(intersection(sig_nodes[pval_nodes_coaxbill[sig_nodes] <.05],allmovies_nodes_add_traits_interaxn))\n",
    "\n",
    "[eval(shen268_lbl[str(n+1)][0])['name'] for n in [68,208]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('COAX-BILL')\n",
    "print('p corr. \"Social\"- \"Non-social\" responders',np.where(pval_nodes_corr_coaxbill))\n",
    "print('p unc. \"Social\" - \"Non-social\" responders',np.where(pval_nodes_coaxbill<.05))\n",
    "print('rand:',rand_sig_interaction_nodes[:,0])\n",
    "\n",
    "\n",
    "# Any overlap between RAND and COAX-BILL?\n",
    "print('\\nnodes where diff between correlation are sig in both COAX-BILL and RAND (linreg):',intersection(rand_sig_interaction_nodes[:,0],np.where(pval_nodes_coaxbill<.05)[0]))\n",
    "#print('nodes where diff between correlation are sig in both COAX-BILL and RAND:',np.where((pCorrs_rand<.05)          & (pval_nodes_coaxbill<.05))[0])\n",
    "#print('nodes where \"Social\" correlations are sig in both COAX-BILL and RAND:',   np.where((pval_nodes_rand[:,1]<.05) & (pval_nodes_coaxbill<.05))[0])\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "intersection(np.where(nodes_coaxbill_rand_all)[0],np.where(pval_nodes_coaxbill<.05)[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ALL MOVIES - run-wise estimates"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('ALL MOVIES')\n",
    "\n",
    "print('p corr. \"Social\"- \"Non-social\" responders',np.where(pval_nodes_corr_all))\n",
    "print('p unc. \"Social\" - \"Non-social\" responders',np.where(pval_nodes_all<.05))\n",
    "print('rand:',rand_sig_interaction_nodes[:,0])\n",
    "\n",
    "\n",
    "\n",
    "nmin,nmax = np.argmin(corr_nodes_coaxbill),np.argmax(corr_nodes_coaxbill)\n",
    "print(f'coaxbill, Node {nmin+1}, rSp={corr_nodes_coaxbill[nmin]:.2f}, pSp = {pval_nodes_coaxbill[nmin]:.2e}')\n",
    "print(f'coaxbill, Node {nmax+1}, rSp={corr_nodes_coaxbill[nmax]:.2f}, pSp = {pval_nodes_coaxbill[nmax]:.2e}')\n",
    "\n",
    "\n",
    "nmin,nmax = np.argmin(corr_nodes_all),np.argmax(corr_nodes_all)\n",
    "print(f'\\n\\nall movies, Node {nmin+1}, rSp={corr_nodes_coaxbill[nmin]:.2f}, pSp = {pval_nodes_coaxbill[nmin]:.2e}')\n",
    "print(f'all movies, Node {nmax+1}, rSp={corr_nodes_coaxbill[nmax]:.2f}, pSp = {pval_nodes_coaxbill[nmax]:.2e}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "tr0_ind = 3 # ind at which tr=0 starts\n",
    "[timepts_indiv_movie,vid_start_rel_tr] = np.load(os.path.join(data_file_loc,'Video_TRs.npy'),allow_pickle=True)\n",
    "print(vid_start_rel_tr)\n",
    "l_task = 28\n",
    "\n",
    "def remove_pretrial_TRs(tcs,vid_start_rel_tr,pretrial_TRs):\n",
    "\n",
    "    tcs1 = np.empty((tcs.shape[0],tcs.shape[1],28+pretrial_TRs,tcs.shape[3]))\n",
    "    tcs1[:] = np.nan\n",
    "\n",
    "    for vid_no in range(10):\n",
    "        tr0 = vid_start_rel_tr[vid_no]\n",
    "        tcs1[:,:,:,vid_no] = tcs[:,:,tr0-pretrial_TRs:tr0+28,vid_no] # 31 timepts\n",
    "    return tcs1\n",
    "\n",
    "\n",
    "print('\\ntrial-wise norm data.')\n",
    "fileName = os.path.join(data_file_loc,'timecourses_trial_norm','timecourse-all-movies_zscorenorm.npy')\n",
    "tcs_trial_z = np.load(fileName) # nsubs * nnodes * ntimepts *nmovies\n",
    "print('before:',tcs_trial_z.shape)\n",
    "tcs_trial_z = remove_pretrial_TRs(tcs_trial_z,vid_start_rel_tr,tr0_ind)\n",
    "print('after:',tcs_trial_z.shape)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "left_rois = pd.read_excel(os.path.join('/Users/f0053cz/Dropbox (Dartmouth College)/postdoc_Dartmouth/HCP/paper_prep/figures/fig5_timecourse/ROIs_left.xls'))\n",
    "left_rois"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "right_rois = pd.read_excel(os.path.join('/Users/f0053cz/Dropbox (Dartmouth College)/postdoc_Dartmouth/HCP/paper_prep/figures/fig5_timecourse/ROIs_right.xls'))\n",
    "right_rois"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lr_rois = pd.concat([left_rois,right_rois])\n",
    "lr_rois"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "TR = .72\n",
    "tr = [int(i) for i in lr_rois['Divergence\\n(sec)']/TR]\n",
    "tc_analysis_nodes = np.array([int(i) for i in lr_rois['Shen atlas node\\n(1-268)'].values - 1])\n",
    "tc_analysis_nodes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "traitdep_nodes_coaxbill = np.where(pval_nodes_coaxbill <.05)[0]\n",
    "print(traitdep_nodes_coaxbill)\n",
    "intersection_nodes_coaxbill = intersection(tc_analysis_nodes,traitdep_nodes_coaxbill )\n",
    "intersection_nodes_coaxbill"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparing activity at divergence pt"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def explore_correlation(x, y, data, str, ax, corrType = 'Spearman'):\n",
    "    \"\"\"\n",
    "    Calculates and plots correlation between x and y variables in dataframe `data`, plus distribution of x and y \n",
    "    \"\"\"\n",
    "    sns.set_style(\"white\")\n",
    "    \n",
    "    inds = ~np.isnan(data[x]) & ~np.isnan(data[y]) # find rows where neither x or y is NaN\n",
    "\n",
    "    #g = sns.jointplot(x=x, y=y, data=data, kind='reg', color='gray')\n",
    "    #g = sns.regplot(x=x, y=y, data=data, color='gray')\n",
    "    g = sns.regplot(x=x, y=y, data=data, color='gray')\n",
    "    \n",
    "    xmin,xmax = -3,3\n",
    "    plt.xlim(xmin,xmax)\n",
    "    ymin,ymax = 0,100\n",
    "    plt.ylim(ymin,ymax)\n",
    "        \n",
    "    # Calculate and print correlations\n",
    "    if corrType == 'Pearson':\n",
    "        rp, pp = stats.pearsonr(data[x][inds], data[y][inds])\n",
    "    else:\n",
    "        rs, ps = stats.spearmanr(data[x][inds], data[y][inds])\n",
    "    #g.ax_joint.annotate(f'{str},r_s = {rs:.2f} (p={ps:.1g})', xy=(.05,.95), xycoords='axes fraction')\n",
    "    g.annotate(f'{str},r_s = {rs:.2f} (p={ps:.1g})', xy=(.05,.95), xycoords='axes fraction')\n",
    "    \n",
    "    return g"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = \"bold_diff\"\n",
    "#y = \"Loneliness_Unadj\"\n",
    "y = \"ASR_Intn_T\"\n",
    "\n",
    "tr0_ind=3\n",
    "\n",
    "corr_nodes_coaxbill_divpt,pval_nodes_coaxbill_divpt = [np.empty((268,)) for _ in range(2)]\n",
    "corr_nodes_coaxbill_divpt[:],pval_nodes_coaxbill_divpt[:] = [np.nan] *2\n",
    "\n",
    "for n in intersection_nodes_coaxbill:\n",
    "    timept = tr0_ind +  tr[int(np.where(tc_analysis_nodes==n)[0])] #tr[tc_analysis_nodes==n]\n",
    "    bold_diff= tcs_trial_z[:,n,timept,0] - tcs_trial_z[:,n,timept,1]\n",
    "    fMRI_data = pd.DataFrame({'Subject':sub_id_all,'bold_diff':bold_diff, 'responses':(responses[:,0]==1)&(responses[:,1]==0)})\n",
    "    fMRI_data.set_index(\"Subject\", inplace=True)\n",
    "    data = fMRI_data.join(behav_data, how='inner') # join betas and trait info\n",
    "    #if n == 0:\n",
    "    #    print(data.shape)\n",
    "    #    print(data.head())\n",
    "    \n",
    "    d = data.loc[data['responses']==True,:]\n",
    "  \n",
    "    #if n == 0:\n",
    "    #    print(data.shape)\n",
    "    #    print(data.head())\n",
    "    \n",
    "    #inds = ~np.isnan(d[x]) & ~np.isnan(d[y]) # find rows where neither x or y is NaN\n",
    "    \n",
    "    explore_correlation(x,y,d,'Spearman')\n",
    "    plt.text(-2,100,f'Node{n+1}',fontweight='bold')\n",
    "    # Calculate and print correlations\n",
    "    '''if corrtype == 'Pearson':\n",
    "        corr_nodes_coaxbill_divpt[n], pval_nodes_coaxbill_divpt[n] = stats.pearsonr(d[x][inds], d[y][inds])\n",
    "    elif corrtype =='Spearman':\n",
    "        corr_nodes_coaxbill_divpt[n], pval_nodes_coaxbill_divpt[n] = stats.spearmanr(d[x][inds], d[y][inds])\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- the above (lack of) correlations show that the differences at the divergence pt does not directly depend on trait scores"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#tc_analysis_nodes = {'right': [65,68,69,75,80], 'left': [196,197,198,205,206,209,212,213]}\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot brain maps"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from nltools.data import Brain_Data\n",
    "from nltools.mask import expand_mask, roi_to_brain\n",
    "from nilearn.plotting import plot_glass_brain, plot_surf_roi,plot_stat_map,plot_img,plot_surf_contours\n",
    "from nilearn import datasets\n",
    "from nilearn.surface import vol_to_surf\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "from nilearn.datasets import fetch_surf_fsaverage\n",
    "fsaverage = fetch_surf_fsaverage()\n",
    "\n",
    "#coords = [10*int(i) for i in np.linspace(-4,7,6)]\n",
    "bg_img = datasets.load_mni152_template()\n",
    "\n",
    "mask = Brain_Data('https://neurovault.org/media/images/8423/shen_2mm_268_parcellation.nii.gz')\n",
    "mask_x = expand_mask(mask)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def color_rois(values):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function assumes you are passing a vector \"values\" with the same length as the number of nodes in the atlas.\n",
    "    \"\"\"\n",
    "    shen268 = nib.load(os.path.join(data_file_loc,\"shen_2mm_268_parcellation.nii.gz\"))\n",
    "    shen268_data = shen268.get_fdata()\n",
    "    img = np.zeros(shen268_data.shape)\n",
    "    #print(shen268_data.shape)\n",
    "    for roi in range(len(values)):\n",
    "        itemindex = np.where(shen268_data==roi+1) # find voxels in this node (add 1 to account for zero-indexing)\n",
    "        #print(len(itemindex[0]))\n",
    "        img[itemindex] = values[roi] # color them by the desired value \n",
    "\n",
    "    affine = shen268.affine\n",
    "    img_nii = nib.Nifti1Image(img, affine)\n",
    "    \n",
    "    return img_nii"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig_save_loc = os.path.join('/Users/f0053cz/Dropbox (Dartmouth College)/postdoc_Dartmouth/HCP/paper_prep/figures/fig2_2_traits/fmri_results')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# interaction plots\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "coords = [-50,-40,-25,-10,0,10,25,40] # initial exploration\n",
    "#coords = [-40,-30,-20] # for the final version\n",
    "cmap = 'RdBu_r'\n",
    "\n",
    "resp_lbl = [\"Nonsocial\",  \"Social\"]\n",
    "    \n",
    "vmin,vmax = -.03,.03\n",
    "\n",
    "#txt = r\"$\\overline{\\beta}(''Social''-''Non-social'')$\"\n",
    "txt = 'Interaction term\\n(trait_slope\"Social\"-\\ntrait_slope\"Non-social\")\\n,q<.05'\n",
    "\n",
    "nodes = np.zeros((268,))\n",
    "node_inds = [int(i) for i in rand_sig_interaction_nodes[:,0]]\n",
    "nodes[node_inds] = rand_sig_interaction_nodes[:,1]\n",
    "title_txt = f'RANDOM MECH \"Social\"-\"Non-social\"'\n",
    "\n",
    "fig,ax = plt.subplots(nrows=1,ncols=4,figsize = (20,5),subplot_kw={'projection': '3d'})\n",
    "\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img,colorbar= False,threshold = .0001)\n",
    "ax_plot.add_contours(color_rois((nodes_coaxbill_rand_all)),linewidths=1, colors=[[.3,.3,.3,1]],linestyles='solid')\n",
    "#ax_plot.add_contours(color_rois((pCorrs_rand<.05)),linewidths=2, colors=['g'],linestyles='solid')\n",
    "#ax_plot.title(title_txt,fontsize=24,bgcolor='k',color='w',fontweight='bold')\n",
    "#ax_plot._colorbar_ax.text(1,.8*vmax,txt,fontsize=20,fontdict = {'verticalalignment':'top','rotation':0})#get_legend()\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'RAND/{resp_lbl[resp]}/axial.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()\n",
    "\n",
    "#LH\n",
    "texture = vol_to_surf(color_rois(nodes), fsaverage.pial_left,interpolation='nearest',radius =1, n_samples=1)\n",
    "surf_plot1=plot_surf_roi(fsaverage.infl_left, texture, hemi='left',cmap = cmap, colorbar=False, symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                            bg_map=fsaverage.sulc_left,axes=ax[0])#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "\n",
    "#surf_plot1.axes[0].set_title(title_txt,fontsize=24,color='k',fontweight='bold')\n",
    "texture_contour1 = vol_to_surf(color_rois(nodes_coaxbill_rand_all), fsaverage.pial_left,interpolation='nearest',radius =1, n_samples=1)\n",
    "plot_surf_contours(fsaverage.infl_left, texture_contour1, axes = ax[0], figure=surf_plot1, legend=True,levels = [1], colors=[[.3,.3,.3,1]])\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'RAND/{resp_lbl[resp]}/left_lat.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')   \n",
    "#plt.clf()\n",
    "   \n",
    "\n",
    "surf_plot2=plot_surf_roi(fsaverage.infl_left, texture, hemi='left',cmap = cmap, colorbar=False, symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                            bg_map=fsaverage.sulc_left, view = 'medial',axes=ax[1])#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "plot_surf_contours(fsaverage.infl_left, texture_contour1, axes = ax[1], figure=surf_plot2, legend=True,levels = [1], colors=[[.3,.3,.3,1]])\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'RAND/{resp_lbl[resp]}/left_med.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()\n",
    "\n",
    "#RH\n",
    "texture = vol_to_surf(color_rois(nodes), fsaverage.pial_right,interpolation='nearest',radius =1, n_samples=1)\n",
    "surf_plot3=plot_surf_roi(fsaverage.infl_right, texture, hemi='right',cmap = cmap, colorbar=True,symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                            bg_map=fsaverage.sulc_right,axes=ax[3])#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "surf_plot3.axes[4].text(.4,.5*vmax,s=txt,fontsize=20, fontdict = {'verticalalignment':'top','horizontalalignment':'left','rotation':0})\n",
    "texture_contour1 = vol_to_surf(color_rois(nodes_coaxbill_rand_all), fsaverage.pial_right,interpolation='nearest',radius =1, n_samples=1)\n",
    "plot_surf_contours(fsaverage.infl_right, texture_contour1, axes = ax[3],figure=surf_plot3, legend=True,levels = [1], colors=[[.3,.3,.3,1]])\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'RAND/{resp_lbl[resp]}/right_lat.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()\n",
    "\n",
    "\n",
    "surf_plot4=plot_surf_roi(fsaverage.infl_right, texture, hemi='right',cmap = cmap, colorbar=False,symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                            bg_map=fsaverage.sulc_right, view ='medial',axes=ax[2])#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "plot_surf_contours(fsaverage.infl_right, texture_contour1, axes = ax[2], figure=surf_plot4, legend=True,levels = [1], colors=[[.3,.3,.3,1]])\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'RAND/{resp_lbl[resp]}/right_med.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from nilearn.plotting import plot_img_on_surf\n",
    "plot_img_on_surf(img.to_nifti(),threshold=.001,\n",
    "                          views=['lateral', 'medial'],\n",
    "                          hemispheres=['left', 'right'],\n",
    "                          colorbar=True,cmap= cmap)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "order = np.argsort(-rand_sig_interaction_nodes[:,1]) # in descending order of the interaction coefft\n",
    "node_inds = [int(i) for i in rand_sig_interaction_nodes[order,0]]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = \"coef_slope\"\n",
    "#y = \"Loneliness_Unadj\"\n",
    "y = \"ASR_Intn_T\"\n",
    "\n",
    "tr0_ind=3\n",
    "\n",
    "for i,n in enumerate(node_inds):\n",
    "    fig,ax = plt.subplots(figsize=(10,5),nrows=1,ncols=2)\n",
    "    hem = 'Left' if n >=134 else 'Right'\n",
    "    ind = order[i]\n",
    "    sl = np.round(1000*rand_sig_interaction_nodes[ind,1])/1000\n",
    "    plt.suptitle('Node ' + str(n+1) + '(' + hem + ') ' +  \"\\n\".join(eval(shen268_lbl[str(n+1)][0])[\"name\"].split(';')))\n",
    "       \n",
    "    for resp in range(2):        \n",
    "        respType = '\"Social\"' if resp == 1 else '\"Non-social\"'\n",
    "        rows = [int(i) for i in np.where(responses[:,4]==resp)[0]]\n",
    "        fMRI_data = pd.DataFrame({'Subject':np.array(sub_id_all)[rows],'coef_slope':coef_slope_rand[rows,n], 'responses':rows})\n",
    "        fMRI_data.set_index(\"Subject\", inplace=True)\n",
    "        data = fMRI_data.join(behav_data, how='inner') # join betas and trait info\n",
    "        \n",
    "        #explore_correlation(x,y,d,ax[i,resp],f'Node{n+1},{respType}','Spearman')\n",
    "        sns.regplot(data[x],data[y],ax=ax[resp],color = 'grey')\n",
    "        inds = (~np.isnan(data[x])) & (~np.isnan(data[y]))\n",
    "        r,p = stats.spearmanr(data.loc[inds,x],data.loc[inds,y])\n",
    "        ax[resp].set_title(respType)\n",
    "        if p>.05:\n",
    "            ax[resp].text(-4,70,f'r={r:.2f}\\n(p={p:.2f})')\n",
    "        else:\n",
    "            ax[resp].text(-4,70,f'r={r:.2f}\\n(p={p:.1e})')\n",
    "        ax[resp].set_xlim(-4,4)\n",
    "        ax[resp].set_ylim(30,80)\n",
    "        ax[resp].set_xticks([-3,-2,-1,0,1,2,3])\n",
    "        ax[resp].set_yticks([30,40,50,60,70,80])\n",
    "\n",
    "    plt.tight_layout()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Separate social/nonsocial plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "coords = [-50,-40,-25,-10,0,10,25,40] # initial exploration\n",
    "#coords = [-40,-30,-20] # for the final version\n",
    "cmap = 'RdBu_r'\n",
    "\n",
    "resp_lbl = [\"Nonsocial\",  \"Social\"]\n",
    "    \n",
    "vmin,vmax = -.32,.32\n",
    "for resp in [0,1]:\n",
    "    if resp == 1:\n",
    "        txt = f'  {corrtype} r\\n  (p<.05 unc.)\\n {y} vs  'r\"$\\overline{\\beta}(''Social'')$\"\n",
    "    else:\n",
    "        txt = f'  {corrtype} r\\n  (p<.05 unc.)\\n {y} vs  'r\"$\\overline{\\beta}(''Non-social'')$\"\n",
    "\n",
    "    nodes = np.zeros((268,))\n",
    "    nodes[pval_nodes_rand[:,resp]<.05] = corr_nodes_rand[pval_nodes_rand[:,resp]<.05,resp]\n",
    "\n",
    "    title_txt = f'RANDOM MECH \"{resp_lbl[resp]}\"'\n",
    "\n",
    "    img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "    ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img,colorbar= False,threshold = .0001)\n",
    "    ax_plot.add_contours(color_rois((nodes_coaxbill_rand_all)),linewidths=1, colors=[[.3,.3,.3,1]],linestyles='solid')\n",
    "    ax_plot.add_contours(color_rois((pCorrs_rand<.05)),linewidths=2, colors=['g'],linestyles='solid')\n",
    "    #ax_plot.title(title_txt,fontsize=24,bgcolor='k',color='w',fontweight='bold')\n",
    "    #ax_plot._colorbar_ax.text(1,.8*vmax,txt,fontsize=20,fontdict = {'verticalalignment':'top','rotation':0})#get_legend()\n",
    "    #plt.savefig(os.path.join(fig_save_loc,f'RAND/{resp_lbl[resp]}/axial.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "    #plt.clf()\n",
    "\n",
    "    fig,ax = plt.subplots(nrows=1,ncols=4,figsize = (20,5),subplot_kw={'projection': '3d'})\n",
    "\n",
    "    #LH\n",
    "    texture = vol_to_surf(color_rois(nodes), fsaverage.pial_left,interpolation='nearest',radius =1, n_samples=1)\n",
    "    surf_plot1=plot_surf_roi(fsaverage.infl_left, texture, hemi='left',cmap = cmap, colorbar=False, symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                                bg_map=fsaverage.sulc_left,axes=ax[0])#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "    #surf_plot1.axes[1].text(3,.8*vmax,s= txt,fontsize=20, fontdict = {'verticalalignment':'top','horizontalalignment':'left','rotation':0})\n",
    "    surf_plot1.axes[0].set_title(title_txt,fontsize=24,color='k',fontweight='bold')\n",
    "    texture_contour1 = vol_to_surf(color_rois(nodes_coaxbill_rand_all), fsaverage.pial_left,interpolation='nearest',radius =1, n_samples=1)\n",
    "    plot_surf_contours(fsaverage.infl_left, texture_contour1, figure=surf_plot1,axes=ax[0], legend=True,levels = [1], colors=[[.3,.3,.3,1]])\n",
    "    #plt.savefig(os.path.join(fig_save_loc,f'RAND/{resp_lbl[resp]}/left_lat.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')   \n",
    "    #plt.clf()\n",
    "\n",
    "    surf_plot2=plot_surf_roi(fsaverage.infl_left, texture, hemi='left',cmap = cmap, colorbar=False, symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                                bg_map=fsaverage.sulc_left, view = 'medial',axes=ax[1])#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "    #surf_plot2.axes[1].text(3,.8*vmax,s= txt,fontsize=20, fontdict = {'verticalalignment':'top','horizontalalignment':'left','rotation':0})\n",
    "    #surf_plot2.axes[0].set_title(title_txt,fontsize=24,color='k',fontweight='bold')\n",
    "    plot_surf_contours(fsaverage.infl_left, texture_contour1, figure=surf_plot2, legend=True,levels = [1], colors=[[.3,.3,.3,1]],axes=ax[1])\n",
    "    #plt.savefig(os.path.join(fig_save_loc,f'RAND/{resp_lbl[resp]}/left_med.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "    #plt.clf()\n",
    "\n",
    "    #RH\n",
    "    texture = vol_to_surf(color_rois(nodes), fsaverage.pial_right,interpolation='nearest',radius =1, n_samples=1)\n",
    "    surf_plot3=plot_surf_roi(fsaverage.infl_right, texture, hemi='right',cmap = cmap, colorbar=True,symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                                bg_map=fsaverage.sulc_right,axes=ax[3])#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "    surf_plot3.axes[1].text(3,.8*vmax,s=txt,fontsize=20, fontdict = {'verticalalignment':'top','horizontalalignment':'left','rotation':0})\n",
    "    texture_contour1 = vol_to_surf(color_rois(nodes_coaxbill_rand_all), fsaverage.pial_right,interpolation='nearest',radius =1, n_samples=1)\n",
    "    plot_surf_contours(fsaverage.infl_right, texture_contour1, figure=surf_plot3, axes=ax[3], legend=True,levels = [1], colors=[[.3,.3,.3,1]])\n",
    "    #plt.savefig(os.path.join(fig_save_loc,f'RAND/{resp_lbl[resp]}/right_lat.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "    #plt.clf()\n",
    "\n",
    "    surf_plot4=plot_surf_roi(fsaverage.infl_right, texture, hemi='right',cmap = cmap, colorbar=False,symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                                bg_map=fsaverage.sulc_right, view ='medial',axes=ax[2])#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "    plot_surf_contours(fsaverage.infl_right, texture_contour1, figure=surf_plot4, axes=ax[2], legend=True,levels = [1], colors=[[.3,.3,.3,1]])\n",
    "    #plt.savefig(os.path.join(fig_save_loc,f'RAND/{resp_lbl[resp]}/right_med.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "    #plt.clf()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# COAX-BILL\n",
    "coords = [-50,-40,-25,-10,0,10,25,40] # initial exploration\n",
    "#coords = [-40,-30,-20] # for the final version\n",
    "\n",
    "txt = f'  {corrtype} r\\n  (p<.05 unc.)\\n {y} vs  \\n  'r\"$\\overline{\\beta(''Social''-}$\" + '\\n  ' + r\"$\\overline{\\beta(''Non-social'')}$\"\n",
    "title_txt = 'COAX-BILL'\n",
    "\n",
    "nodes = np.zeros((268,))\n",
    "nodes[pval_nodes_coaxbill<.05] = corr_nodes_coaxbill[pval_nodes_coaxbill<.05]\n",
    "#vmin,vmax = -max(abs(nodes)),max(abs(nodes))\n",
    "vmin,vmax = -.32,.32\n",
    "\n",
    "cmap = 'RdBu_r'\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img,colorbar= False,threshold = .0001)\n",
    "ax_plot.add_contours(color_rois((nodes_coaxbill_rand_all)),linewidths=1, colors=[[.3,.3,.3,1]],linestyles='solid')\n",
    "\n",
    "fig,ax = plt.subplots(nrows=1,ncols=4,figsize = (20,5),subplot_kw={'projection': '3d'})\n",
    "\n",
    "#LH\n",
    "texture = vol_to_surf(color_rois(nodes), fsaverage.pial_left,interpolation='nearest',radius =1, n_samples=1)\n",
    "surf_plot1=plot_surf_roi(fsaverage.infl_left, texture, hemi='left',cmap = cmap, colorbar=False, symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                            bg_map=fsaverage.sulc_left,axes=ax[0])#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "#surf_plot1.axes[1].text(1,.8*vmax,s= txt,fontsize=20, fontdict = {'verticalalignment':'top','horizontalalignment':'left','rotation':0})\n",
    "surf_plot1.axes[0].set_title(title_txt,fontsize=24,color='k',fontweight='bold')\n",
    "texture_contour = vol_to_surf(color_rois(nodes_coaxbill_rand_all), fsaverage.pial_left,interpolation='nearest',radius =1, n_samples=1)\n",
    "plot_surf_contours(fsaverage.infl_left, texture_contour, figure=surf_plot1,axes=ax[0], legend=True,levels = [1], colors=[[.3,.3,.3,1]])\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'COAXBILL/left_lat.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()\n",
    "\n",
    "surf_plot2=plot_surf_roi(fsaverage.infl_left, texture, hemi='left',cmap = cmap, colorbar=False, symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                            bg_map=fsaverage.sulc_left, view = 'medial',axes=ax[1])#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "#surf_plot2.axes[1].text(3,.8*vmax,s= txt,fontsize=20, fontdict = {'verticalalignment':'top','horizontalalignment':'left','rotation':0})\n",
    "#surf_plot2.axes[0].set_title(title_txt,fontsize=24,color='k',fontweight='bold')\n",
    "plot_surf_contours(fsaverage.infl_left, texture_contour, figure=surf_plot2,axes=ax[1], legend=True,levels = [1], colors=[[.3,.3,.3,1]])\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'COAXBILL/left_med.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()\n",
    "\n",
    "#RH\n",
    "texture = vol_to_surf(color_rois(nodes), fsaverage.pial_right,interpolation='nearest',radius =1, n_samples=1)\n",
    "surf_plot3=plot_surf_roi(fsaverage.infl_right, texture, hemi='right',cmap = cmap, colorbar=True,symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                            bg_map=fsaverage.sulc_right,axes=ax[3])#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "surf_plot3.axes[4].text(3,.8*vmax,s=txt,fontsize=20, fontdict = {'verticalalignment':'top','horizontalalignment':'left','rotation':0})\n",
    "#surf_plot3.axes[0].set_title(title_txt,fontsize=24,color='k',fontweight='bold')\n",
    "texture_contour = vol_to_surf(color_rois(nodes_coaxbill_rand_all), fsaverage.pial_right,interpolation='nearest',radius =1, n_samples=1)\n",
    "plot_surf_contours(fsaverage.infl_right, texture_contour, figure=surf_plot3,axes=ax[3], legend=True,levels = [1], colors=[[.3,.3,.3,1]])\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'COAXBILL/right_lat.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()\n",
    "\n",
    "surf_plot4=plot_surf_roi(fsaverage.infl_right, texture, hemi='right',cmap = cmap, colorbar=False,symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                            bg_map=fsaverage.sulc_right, view ='medial',axes=ax[2])#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "#surf_plot4.axes[1].text(3,.8*vmax,s=txt,fontsize=20, fontdict = {'verticalalignment':'top','horizontalalignment':'left','rotation':0})\n",
    "#surf_plot4.axes[0].set_title(title_txt,fontsize=24,color='k',fontweight='bold')\n",
    "plot_surf_contours(fsaverage.infl_right, texture_contour, figure=surf_plot4,axes=ax[2], legend=True,levels = [1], colors=[[.3,.3,.3,1]])\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'COAXBILL/right_med.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot correlations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#\"Social\" alone\n",
    "nodes_ind = np.where( (pval_nodes_rand[:,1]<.05))[0]\n",
    "for n in nodes_ind:\n",
    "    lbl = eval(shen268_lbl[str(n+1)][0])['name']\n",
    "    print(n+1,lbl)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#\"Social\" alone\n",
    "nodes_ind = np.where( (pval_nodes_coaxbill<.05))[0]\n",
    "for n in nodes_ind:\n",
    "    lbl = eval(shen268_lbl[str(n+1)][0])['name']\n",
    "    print(n+1,np.round(corr_nodes_coaxbill[n],2),np.round(np.nanmean(coef_slope_coax[:,n]-coef_slope_bill[:,n]),2),lbl)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = \"slopeReg_diff\"\n",
    "\n",
    "#for n in range(268):\n",
    "n=138\n",
    "#n=191 # left MTG\n",
    "hemi_txt = 'Right hem' if n < 134 else 'Left hem'\n",
    "lbl  = '\\n'.join(eval(shen268_lbl[str(n+1)][0])['name'].split(';'))\n",
    "fMRI_data = pd.DataFrame({'Subject':sub_id_all,'slopeReg_diff':coef_slope_coax[:,n]-coef_slope_bill[:,n], 'responses':(responses[:,0]==1)&(responses[:,1]==0)})\n",
    "fMRI_data.set_index(\"Subject\", inplace=True)\n",
    "data = fMRI_data.join(behav_data, how='inner') # join betas and trait info\n",
    "\n",
    "\n",
    "d = data.loc[data['responses']==True,:]\n",
    "g = explore_correlation(x,y,d)\n",
    "plt.xlabel('Beta COAX-BILL')\n",
    "plt.text(plt.xlim()[0],100,f'\"{resp_lbl[resp]}\" (n={d.shape[0]}),\\n Node{n+1}',fontweight = 'bold')\n",
    "plt.xlim(min(data[x]),max(data[x]))\n",
    "plt.ylim(min(data[y]),max(data[y]))\n",
    "plt.text(plt.xlim()[0],120,f'\"{resp_lbl[resp]}\",{hemi_txt}\\n{lbl}',fontweight='bold')\n",
    "#g.savefig(f'../results/RandBeta{n+1}_vs_loneliness.png')\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.where(pval_nodes_fish[:,0]<.05)[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.where(pval_nodes_fish[:,1]<.05)[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.where(pval_nodes_rand[:,1]<.05)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nodes_ind =np.where((pval_nodes_rand[:,1]<.05) & (pval_nodes_fish[:,0]<.05))[0]\n",
    "for n in nodes_ind:\n",
    "    lbl = eval(shen268_lbl[str(n+1)][0])['name']\n",
    "    print(n+1,lbl)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.where((pval_nodes_rand[:,1]<.05) & (pval_nodes_fish[:,1]<.05))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = \"slopeReg_node\"\n",
    "\n",
    "#for n in range(268):\n",
    "n=84 \n",
    "hemi_txt = 'Right hem' if n < 134 else 'Left hem'\n",
    "lbl  = '\\n'.join(eval(shen268_lbl[str(n+1)][0])['name'].split())\n",
    "fMRI_data = pd.DataFrame({'Subject':sub_id_all,'slopeReg_node':coef_slope_rand[:,n], 'responses':responses[:,4]})\n",
    "fMRI_data.set_index(\"Subject\", inplace=True)\n",
    "data = fMRI_data.join(behav_data, how='inner') # join betas and trait info\n",
    "\n",
    "for resp in [0,1]:\n",
    "    d = data.loc[data['responses']==resp,:]\n",
    "    g = explore_correlation(x,y,d,'Spearman')\n",
    "    plt.xlabel('Beta RANDOM MECH\\n(<<< Deactivation   Activation >>>)')\n",
    "    plt.text(plt.xlim()[0],100,f'\"{resp_lbl[resp]}\" (n={d.shape[0]}),\\n Node{n+1}',fontweight = 'bold')\n",
    "    plt.xlim(min(data[x]),max(data[x]))\n",
    "    plt.ylim(min(data[y]),max(data[y]))\n",
    "    if resp ==0:\n",
    "        plt.text(plt.xlim()[0],120,f'\"{resp_lbl[resp]}\",{hemi_txt}\\n{lbl}',fontweight='bold')\n",
    "    else:\n",
    "        plt.text(plt.xlim()[0],120,f'\"{resp_lbl[resp]}\"',fontweight='bold')\n",
    "    #g.savefig(f'../results/RandBeta{n+1}_vs_loneliness.png')\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = \"slopeReg_node\"\n",
    "#for n in range(268):\n",
    "n=84\n",
    "hemi_txt = 'Right hem' if n < 134 else 'Left hem'\n",
    "lbl  = '\\n'.join(eval(shen268_lbl[str(n+1)][0])['name'].split())\n",
    "fMRI_data = pd.DataFrame({'Subject':sub_id_all,'slopeReg_node':coef_slope_fish[:,n], 'responses':responses[:,3]})\n",
    "fMRI_data.set_index(\"Subject\", inplace=True)\n",
    "data = fMRI_data.join(behav_data, how='inner') # join betas and trait info\n",
    "\n",
    "for resp in [0,1]:\n",
    "    d = data.loc[data['responses']==resp,:]\n",
    "    g = explore_correlation(x,y,d,'Spearman')\n",
    "    plt.xlabel('Beta FISHING\\n(<<< Deactivation   Activation >>>)')\n",
    "    plt.text(plt.xlim()[0],100,f'\"{resp_lbl[resp]}\" (n={d.shape[0]}),\\n Node{n+1}',fontweight = 'bold')\n",
    "    plt.xlim(min(data[x]),max(data[x]))\n",
    "    plt.ylim(min(data[y]),max(data[y]))\n",
    "    if resp ==0:\n",
    "        plt.text(plt.xlim()[0],120,f'\"{resp_lbl[resp]}\",{hemi_txt}\\n{lbl}',fontweight='bold')\n",
    "    else:\n",
    "        plt.text(plt.xlim()[0],120,f'\"{resp_lbl[resp]}\"',fontweight='bold')\n",
    "    #g.savefig(f'../results/RandBeta{n+1}_vs_loneliness.png')\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nodes = np.zeros((268,))\n",
    "nodes[n] = corr_nodes[n,1]\n",
    "cmap = 'RdBu_r'\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img,colorbar= True,threshold = .0001)\n",
    "ax_plot.title(title_txt,fontsize=24,bgcolor='k',color='w',fontweight='bold')\n",
    "ax_plot._colorbar_ax.text(1,.8*vmax,txt,fontsize=20,fontdict = {'verticalalignment':'top','rotation':0})#get_legend()\n",
    "\n",
    "#RH\n",
    "texture = vol_to_surf(color_rois(nodes), fsaverage.pial_right,interpolation='nearest',radius =1, n_samples=1)\n",
    "surf_plot3=plot_surf_roi(fsaverage.infl_right, texture, hemi='right',cmap = cmap, colorbar=True,symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                            bg_map=fsaverage.sulc_right)#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "surf_plot3.axes[1].text(3,.8*vmax,s=txt,fontsize=20, fontdict = {'verticalalignment':'top','horizontalalignment':'left','rotation':0})\n",
    "surf_plot3.axes[0].set_title(title_txt,fontsize=24,color='k',fontweight='bold')\n",
    "\n",
    "surf_plot4=plot_surf_roi(fsaverage.infl_right, texture, hemi='right',cmap = cmap, colorbar=True,symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                            bg_map=fsaverage.sulc_right,view='medial')#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "\n",
    "\n",
    "  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nodes = np.zeros((268,))\n",
    "nodes[pval_nodes[:,1]<.05] = corr_nodes[pval_nodes[:,1]<.05,1]\n",
    "    \n",
    "texture = vol_to_surf(color_rois(nodes), fsaverage.pial_right,interpolation='nearest',radius =1, n_samples=1)\n",
    "surf_plot3=plot_surf_roi(fsaverage.infl_right, texture, hemi='right',cmap = cmap, colorbar=True,symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                            bg_map=fsaverage.sulc_right)#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "surf_plot3.axes[1].text(3,.8*vmax,s=txt,fontsize=20, fontdict = {'verticalalignment':'top','horizontalalignment':'left','rotation':0})\n",
    "surf_plot3.axes[0].set_title(title_txt,fontsize=24,color='k',fontweight='bold')\n",
    "\n",
    "   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# plot timecourses"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_file_loc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tr0_ind = 3 # ind at which tr=0 starts\n",
    "[timepts_indiv_movie,vid_start_rel_tr] = np.load(os.path.join(data_file_loc,'Video_TRs.npy'),allow_pickle=True)\n",
    "print(vid_start_rel_tr)\n",
    "l_task = 28\n",
    "\n",
    "def remove_pretrial_TRs(tcs,vid_start_rel_tr,pretrial_TRs):\n",
    "\n",
    "    tcs1 = np.empty((tcs.shape[0],tcs.shape[1],28+pretrial_TRs,tcs.shape[3]))\n",
    "    tcs1[:] = np.nan\n",
    "\n",
    "    for vid_no in range(10):\n",
    "        tr0 = vid_start_rel_tr[vid_no]\n",
    "        tcs1[:,:,:,vid_no] = tcs[:,:,tr0-pretrial_TRs:tr0+28,vid_no] # 31 timepts\n",
    "    return tcs1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#select subs who responded \"social\" to the yes movie and nonsocial to the no movie\n",
    "\n",
    "print('\\ntrial-wise norm data.')\n",
    "fileName = os.path.join(data_file_loc,'timecourses_run_norm','timecourse-all-movies_zscorenorm.npy') # load fmri data\n",
    "tcs_run_z = np.load(fileName) # nsubs * nnodes * ntimepts *nmovies\n",
    "print('before:',tcs_run_z.shape)\n",
    "tcs_run_z = remove_pretrial_TRs(tcs_run_z,vid_start_rel_tr,tr0_ind)\n",
    "print('after:',tcs_run_z.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nodes = np.where(pval_nodes[:,1]<.05)[0]\n",
    "nodes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get the right red/blue shades\n",
    "#red_rgb = [103,0,31] # edges of RdBu\n",
    "#blue_rgb = [5,48,97] # edges of RdBu\n",
    "red_rgb =[188,61,62] # from Emily\n",
    "blue_rgb = [54,122,177] # from Emily\n",
    "red_rgb = np.array(red_rgb)/255\n",
    "blue_rgb = np.array(blue_rgb)/255\n",
    "alpha = .2 # transparency inside boxplots, for datapts etc."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fMRI_data = pd.DataFrame({'Subject':sub_id_all,'sub_ind':np.arange(0,1048),'slopeReg_node':coef_slope_rand[:,n], 'responses':responses[:,4]})\n",
    "fMRI_data.set_index(\"Subject\", inplace=True)\n",
    "data = fMRI_data.join(behav_data, how='inner') # join betas and trait info\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fMRI_data\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sorted_data = data.loc[data['responses']==1,['slopeReg_node','ASR_Intn_T','sub_ind','responses']]\n",
    "sorted_data = sorted_data.sort_values(by=['ASR_Intn_T'])\n",
    "sorted_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "movie_ind = 4\n",
    "ymin,ymax = -5,5\n",
    "n = 58\n",
    "subs = sorted_data['sub_ind'].values\n",
    "\n",
    "ncols = 15\n",
    "nrows= int(np.ceil(len(subs)/ncols))\n",
    "#fig, axes = plt.subplots(67,4, figsize=(15,150))\n",
    "xwidth = 30\n",
    "yheight = 20# .75*nrows*xwidth/ncols\n",
    "fig, ax = plt.subplots(nrows, ncols, sharex=True, sharey=True, figsize = (xwidth,yheight))\n",
    "fig.set_figwidth(xwidth)\n",
    "fig.set_figheight(yheight)\n",
    "\n",
    "TR=.72\n",
    "xlbls = [-2,0,5,10,15,20]\n",
    "x_ticks = [(i/TR)+tr0_ind for i in xlbls]\n",
    "xlbls = [str(i) for i in xlbls]\n",
    "lbls = [str(np.round((i-tr0_ind)*TR,1)) for i in x_ticks]\n",
    "\n",
    "plt.suptitle(f'Node {n+1},{eval(shen268_lbl[str(n+1)][0])[\"name\"]}',fontweight='bold')\n",
    "\n",
    "for i,s in enumerate(subs):\n",
    "\n",
    "    r = int(np.floor(i/ncols))\n",
    "    c = int(np.floor(i%ncols))\n",
    "\n",
    "    movieTC_yes = tcs_run_z[s,n,:,movie_ind] # nsubs * ntimepts\n",
    "    #movieTC_no  = tcs_run_z[responses[:,movie_ind]==0,n,:,movie_ind] # nsubs * ntimepts\n",
    "    #sig = np.where(~np.isnan(meanDiff_rand[n,:]))[0]    \n",
    "\n",
    "    ax[r,c].set_ylim(ymin,ymax)\n",
    "    ax[r,c].plot(range(movieTC_yes.shape[0]),movieTC_yes,color = 'k',linewidth=2,label ='\"Social\"')\n",
    "    #ax[r,c].errorbar(range(movieTC_yes.shape[1]),np.nanmean(movieTC_no,axis=0),stats.sem(movieTC_no,axis=0,nan_policy='omit'),color = blue_rgb,linewidth=2,label ='\"Non-social\"')\n",
    "    #if r==0:\n",
    "    if sorted_data[\"slopeReg_node\"][i] > 1:\n",
    "        ax[r,c].set_title(f'Sub {s},\\nasr={int(sorted_data[\"ASR_Intn_T\"][i])},b={sorted_data[\"slopeReg_node\"][i]:.2f}', color='r',fontsize = 16)\n",
    "    elif sorted_data[\"slopeReg_node\"][i] > .5:\n",
    "        ax[r,c].set_title(f'Sub {s},\\nasr={int(sorted_data[\"ASR_Intn_T\"][i])},b={sorted_data[\"slopeReg_node\"][i]:.2f}', color=[.5,.25,.25],fontsize = 16,)\n",
    "    elif sorted_data[\"slopeReg_node\"][i] < -1:\n",
    "        ax[r,c].set_title(f'Sub {s},\\nasr={int(sorted_data[\"ASR_Intn_T\"][i])},b={sorted_data[\"slopeReg_node\"][i]:.2f}', color='b',fontsize = 16)\n",
    "    elif sorted_data[\"slopeReg_node\"][i] < -.5:\n",
    "        ax[r,c].set_title(f'Sub {s},\\nasr={int(sorted_data[\"ASR_Intn_T\"][i])},b={sorted_data[\"slopeReg_node\"][i]:.2f}', color=[.25,.25,.5],fontsize = 16)\n",
    "    else:\n",
    "        ax[r,c].set_title(f'Sub {s},\\nasr={int(sorted_data[\"ASR_Intn_T\"][i])},b={sorted_data[\"slopeReg_node\"][i]:.2f}',fontsize = 16)\n",
    "    \n",
    "    ax[r,c].vlines(tr0_ind,-1,2,color=[.8,.8,.8])\n",
    "    ax[r,c].hlines(0,0,31,color=[.8,.8,.8])\n",
    "    ax[r,c].set_xticks(x_ticks)\n",
    "    ax[r,c].set_xticklabels(xlbls)\n",
    "\n",
    "ax[r,c+1].axis('off')\n",
    "ax[r,c+2].axis('off')\n",
    "\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sorted_data['ASR_Intn_T'][i]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = \"ASR_Extn_T\"\n",
    "g = explore_correlation(x, y)\n",
    "plt.xlabel('Beta Rand')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Determine whether the difference in correlation between `Soc-NonSoc_pc` and internalizing vs externalizing symptoms is statistically significant:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = \"Soc-NonSoc_pc\"\n",
    "y = \"ASR_Intn_T\"\n",
    "z = \"ASR_Extn_T\"\n",
    "\n",
    "inds = ~np.isnan(data[x]) & ~np.isnan(data[y]) & ~np.isnan(data[z])\n",
    "print(inds.sum())\n",
    "\n",
    "rs_xy = stats.spearmanr(data[x][inds], data[y][inds])[0]\n",
    "rs_xz = stats.spearmanr(data[x][inds], data[z][inds])[0]\n",
    "rs_yz = stats.spearmanr(data[y][inds], data[z][inds])[0]\n",
    "print(rs_xy)\n",
    "print(rs_xz)\n",
    "print(rs_yz)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following function was taken from here: https://github.com/psinger/CorrelationStats/blob/master/corrstats.py"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.stats import t, norm\n",
    "from math import atanh, pow\n",
    "from numpy import tanh\n",
    "\n",
    "def rz_ci(r, n, conf_level = 0.95):\n",
    "    zr_se = pow(1/(n - 3), .5)\n",
    "    moe = norm.ppf(1 - (1 - conf_level)/float(2)) * zr_se\n",
    "    zu = atanh(r) + moe\n",
    "    zl = atanh(r) - moe\n",
    "    return tanh((zl, zu))\n",
    "\n",
    "def rho_rxy_rxz(rxy, rxz, ryz):\n",
    "    num = (ryz-1/2.*rxy*rxz)*(1-pow(rxy,2)-pow(rxz,2)-pow(ryz,2))+pow(ryz,3)\n",
    "    den = (1 - pow(rxy,2)) * (1 - pow(rxz,2))\n",
    "    return num/float(den)\n",
    "\n",
    "def dependent_corr(xy, xz, yz, n, twotailed=True, conf_level=0.95, method='steiger'):\n",
    "    \"\"\"\n",
    "    Calculates the statistic significance between two dependent correlation coefficients\n",
    "    @param xy: correlation coefficient between x and y\n",
    "    @param xz: correlation coefficient between x and z\n",
    "    @param yz: correlation coefficient between y and z\n",
    "    @param n: number of elements in x, y and z\n",
    "    @param twotailed: whether to calculate a one or two tailed test, only works for 'steiger' method\n",
    "    @param conf_level: confidence level, only works for 'zou' method\n",
    "    @param method: defines the method uses, 'steiger' or 'zou'\n",
    "    @return: t and p-val\n",
    "    \"\"\"\n",
    "    if method == 'steiger':\n",
    "        d = xy - xz\n",
    "        determin = 1 - xy * xy - xz * xz - yz * yz + 2 * xy * xz * yz\n",
    "        av = (xy + xz)/2\n",
    "        cube = (1 - yz) * (1 - yz) * (1 - yz)\n",
    "\n",
    "        t2 = d * np.sqrt((n - 1) * (1 + yz)/(((2 * (n - 1)/(n - 3)) * determin + av * av * cube)))\n",
    "        p = 1 - t.cdf(abs(t2), n - 3)\n",
    "\n",
    "        if twotailed:\n",
    "            p *= 2\n",
    "\n",
    "        return t2, p\n",
    "    elif method == 'zou':\n",
    "        L1 = rz_ci(xy, n, conf_level=conf_level)[0]\n",
    "        U1 = rz_ci(xy, n, conf_level=conf_level)[1]\n",
    "        L2 = rz_ci(xz, n, conf_level=conf_level)[0]\n",
    "        U2 = rz_ci(xz, n, conf_level=conf_level)[1]\n",
    "        rho_r12_r13 = rho_rxy_rxz(xy, xz, yz)\n",
    "        lower = xy - xz - pow((pow((xy - L1), 2) + pow((U2 - xz), 2) - 2 * rho_r12_r13 * (xy - L1) * (U2 - xz)), 0.5)\n",
    "        upper = xy - xz + pow((pow((U1 - xy), 2) + pow((xz - L2), 2) - 2 * rho_r12_r13 * (U1 - xy) * (xz - L2)), 0.5)\n",
    "        return lower, upper\n",
    "    else:\n",
    "        raise Exception('Wrong method!')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n = inds.sum()\n",
    "\n",
    "xy = stats.spearmanr(data[x][inds], data[y][inds])[0]\n",
    "xz = stats.spearmanr(data[x][inds], data[z][inds])[0]\n",
    "yz = stats.spearmanr(data[y][inds], data[z][inds])[0]\n",
    "\n",
    "dependent_corr(xy, xz, yz, n, twotailed=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Look at responses on RANDMECH:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_trial_data = pd.read_csv('../data/hcp_social_826subs.csv')\n",
    "all_trial_data.set_index(\"subj_idx\", inplace=True)\n",
    "all_trial_data.index.rename(\"Subject\", inplace=True)\n",
    "all_trial_data.index = all_trial_data.index.map(str)\n",
    "all_trial_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = data.join(all_trial_data[all_trial_data[\"movie\"]==\"Random mechanical.AVI\"][\"response\"])\n",
    "data.rename(columns={\"response\": \"rand_mech_response\"}, inplace=True)\n",
    "data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#red_rgb = [103,0,31] # edges of RdBu\n",
    "#blue_rgb = [5,48,97] # edges of RdBu\n",
    "red_rgb =[188,61,62] # from Emily\n",
    "blue_rgb = [54,122,177] # from Emily\n",
    "red_rgb = np.array(red_rgb)/255\n",
    "blue_rgb = np.array(blue_rgb)/255\n",
    "alpha = .2 # transparency inside boxplots, for datapts etc."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#colors = [red_rgb,blue_rgb]\n",
    "# Set your custom color palette\n",
    "#myPalette = sns.set_palette(sns.color_palette(colors))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list(col[:2])+[alpha]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a new variable denoting subjects who responded either \"yes\" or \"unsure\"\n",
    "data[\"rand_mech_yesorunsure\"] = data[\"rand_mech_response\"] > 0\n",
    "\n",
    "y = \"ASR_Intn_T\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,10))\n",
    "\n",
    "#sns.set_palette([\"tab:blue\", \"tab:red\"])\n",
    "ax = sns.boxplot(x=\"rand_mech_yesorunsure\", y=y, data=data)\n",
    "ax.set_xlabel(\"RANDMECH response\")\n",
    "ax.set_xticklabels([\"\\\"Non-\\nsocial\\\"\", \"\\\"Social\\\" or \\n\\\"Unsure\\\"\"])\n",
    "\n",
    "'''for patch in ax.artists:\n",
    " r, g, b, a = patch.get_facecolor()\n",
    " patch.set_facecolor((r, g, b, alpha))\n",
    " patch.set_edgecolor((r, g, b, 1))'''\n",
    " \n",
    "for i,artist in enumerate(ax.artists):\n",
    "    if i == 0:\n",
    "        col = blue_rgb + [alpha]\n",
    "    else:\n",
    "        col = red_rgb + [alpha]\n",
    "        # Set the linecolor on the artist to the facecolor, and set the facecolor to None\n",
    "    #col = artist.get_facecolor()\n",
    "    artist.set_edgecolor(col)\n",
    "    #artist.set_edgecolor('None')\n",
    "    artist.set_facecolor(list(col[:3])+[alpha])\n",
    "    if np.round(col[0],2) ==  .75:\n",
    "        print(i)\n",
    "    # Each box has 6 associated Line2D objects (to make the whiskers, fliers, etc.)\n",
    "    # Loop over them here, and use the same colour as above\n",
    "    \n",
    "    for j in range(i*6,i*6+6):\n",
    "        line = ax.lines[j]\n",
    "        if j in [4,10]:\n",
    "            line.set_color('k')\n",
    "            line.set_linestyle('--')\n",
    "            line.set_linewidth(2)\n",
    "        else:\n",
    "            line.set_color(col)\n",
    "        line.set_mfc(col)\n",
    "        line.set_mec(col)\n",
    "        if j in [5,11]:\n",
    "            line.set_marker('o')\n",
    "plt.xlabel('')\n",
    "plt.title('RANDOM MECH', fontweight = 'bold')\n",
    "t, p = stats.ttest_ind(data[data[\"rand_mech_yesorunsure\"]==1][y], data[data[\"rand_mech_yesorunsure\"]==0][y], nan_policy='omit')\n",
    "ax.annotate(f't = {t:.2f},\\n(p = {p:.2g})', xy=(0.05, 0.85), xycoords='axes fraction')\n",
    "\n",
    "fig.savefig('../results/RANDMECHresp_vs_ASRIntnT.png')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def box_plot(data, edge_color, fill_color,pos,v):\n",
    "    # customize boxplots\n",
    "    alpha= .2\n",
    "    data = data[~np.isnan(data)]\n",
    "    bp = ax.boxplot(data, positions = [pos], patch_artist=True,widths=.6,vert=v,flierprops = dict(markeredgecolor=edge_color,\n",
    "    markerfacecolor=fill_color, alpha=alpha))\n",
    "    \n",
    "    for element in ['boxes', 'whiskers', 'fliers', 'means', 'caps']:\n",
    "        plt.setp(bp[element], color=edge_color)\n",
    "    for element in ['medians']:\n",
    "        plt.setp(bp[element], color='k',linewidth=2,ls='dashed')\n",
    "\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set(facecolor=fill_color,alpha=alpha)#'w'       \n",
    "        \n",
    "    return bp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#data1 = data.loc[data['rand_mech_response']!=9,:]\n",
    "#data1.shape\n",
    "fig, ax = plt.subplots(figsize=(3,5))\n",
    "\n",
    "y = \"ASR_Intn_T\"\n",
    "#x = \"rand_mech_response\"\n",
    "x = \"rand_mech_yesorunsure\"\n",
    "rows = data[x] == 0\n",
    "bp2 = box_plot(data.loc[rows,y], blue_rgb, blue_rgb,0,True)\n",
    "rows = data[x] == 1\n",
    "bp1 = box_plot(data.loc[rows,y], red_rgb, red_rgb,1,True)\n",
    "plt.xticks(range(2),['\"Non-social\"','\"Social\"/\\n \"Unsure\"'])\n",
    "t, p = stats.ttest_ind(data[data[x]==1][y], data[data[x]==0][y], nan_policy='omit')\n",
    "plt.ylabel('ASR_Intn_T')\n",
    "ax.annotate(f't = {t:.2f}\\n(p = {p:.2g})', xy=(0.05, 0.85), xycoords='axes fraction')\n",
    "plt.title('RANDOM MECH',fontweight='bold')\n",
    "fig.savefig('../results/RANDMECHresp_vs_ASRIntnT.png')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a new variable denoting subjects who responded either \"yes\" or \"unsure\"\n",
    "data[\"rand_mech_yesorunsure\"] = data[\"rand_mech_response\"] > 0\n",
    "\n",
    "y = \"ASR_Intn_T\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,10))\n",
    "\n",
    "sns.set_palette([\"tab:blue\", \"tab:red\"])\n",
    "ax = sns.boxplot(x=\"rand_mech_yesorunsure\", y=y, data=data)\n",
    "ax.set_xlabel(\"RANDMECH response\")\n",
    "ax.set_xticklabels([\"\\\"Non-social\\\"\", \"\\\"Social\\\" or \\n\\\"Unsure\\\"\"])\n",
    "\n",
    "t, p = stats.ttest_ind(data[data[\"rand_mech_yesorunsure\"]==1][y], data[data[\"rand_mech_yesorunsure\"]==0][y], nan_policy='omit')\n",
    "ax.annotate(f't = {t:.2f} (p = {p:.2g})', xy=(0.05, 0.9), xycoords='axes fraction')\n",
    "\n",
    "#fig.savefig('../results/RANDMECHresp_vs_ASRIntnT.png')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Look at RT on RANDMECH:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = data.join(all_trial_data[all_trial_data[\"movie\"]==\"Random mechanical.AVI\"][\"rt\"])\n",
    "data = data.rename(columns={\"rt\": \"rand_mech_rt\"})\n",
    "data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g = explore_correlation(x=\"rand_mech_rt\", y=\"ASR_Intn_T\", data=data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Restrict correlation to only subjects that responded \"yes\" or \"unsure\"\n",
    "\n",
    "g = explore_correlation(x=\"rand_mech_rt\", y=\"ASR_Intn_T\", data=data[data[\"rand_mech_yesorunsure\"]==1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# extra code"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "'''# model 1: factors: traits, responses, their interaction\n",
    "coef_nodes_rand_lr_model1 = []\n",
    "pval_nodes_rand_lr_model1 = []\n",
    "\n",
    "# model 2: factor: responses\n",
    "coef_nodes_rand_lr_model2 = []  \n",
    "pval_nodes_rand_lr_model2  = []'''\n",
    "\n",
    "# model 3: factor: responses, traits (no interactions)\n",
    "coef_nodes_fish_lr_model3 = []  \n",
    "pval_nodes_fish_lr_model3  = []\n",
    "\n",
    "print_term = True\n",
    "for n in nodes_traits[1]: # FISHING \n",
    "    if n% 50 ==0:\n",
    "        print('node',n)\n",
    "\n",
    "    fMRI_data = pd.DataFrame({'Subject':sub_id_all,'slopeReg_node':coef_slope_rand[:,n], 'responses':responses[:,4]})\n",
    "    fMRI_data.set_index(\"Subject\", inplace=True)\n",
    "    data = fMRI_data.join(behav_data, how='inner') # join betas and trait info\n",
    "    data.reset_index(inplace=True)\n",
    "    data = data.loc[:,['Subject','slopeReg_node','responses','ASR_Intn_T']]\n",
    "    \n",
    "    d = data.loc[(data['responses']==0)|(data['responses']==1),:]\n",
    "    ind = (~np.isnan(d['slopeReg_node'])) & (~np.isnan(d['ASR_Intn_T'])) & (~np.isnan(d['responses']))\n",
    "    d = d.loc[ind,:]\n",
    "    \n",
    "    '''model1 = Lm(\"slopeReg_node ~  responses\", data=d)\n",
    "    model1.fit(summary = False, verbose = False)\n",
    "    \n",
    "    model2 = Lm(\"slopeReg_node ~  responses + ASR_Intn_T\", data=d)\n",
    "    model2.fit(summary = False, verbose = False)'''\n",
    "\n",
    "    model3 = Lm(\"slopeReg_node ~  responses + ASR_Intn_T + responses*ASR_Intn_T\", data=d)\n",
    "    model3.fit(summary = False, verbose = False)\n",
    "    #model.fit(factors={\"response\":[\"Social\",\"Unsure\"]},summary = False, verbose = False) # Unsure > Social\n",
    "    \n",
    "\n",
    "    if print_term == True:\n",
    "        print_term = False\n",
    "        print('node_ind',n)\n",
    "        '''print(model1.fit())#factors={\"response\":[\"Social\",\"Unsure\"]}))\n",
    "        print(model2.fit())'''\n",
    "        print(model3.fit())\n",
    "\n",
    "    '''coef_nodes_rand_lr_model1.append([n] + [model1.coefs['Estimate'][1]] )\n",
    "    pval_nodes_rand_lr_model1.append([n] + [model1.coefs['P-val'][1]]    )\n",
    "    \n",
    "    coef_nodes_rand_lr_model2.append([n] + [model2.coefs['Estimate'][i] for i in np.arange(1,3)])\n",
    "    pval_nodes_rand_lr_model2.append([n] + [model2.coefs['P-val'][i] for i in np.arange(1,3)])'''\n",
    "    \n",
    "    #intercept,coef_resp,coef_trait,interaxn_resp_trait = [model3.coefs['Estimate'][i] for i in range(4)]\n",
    "    coef_nodes_fish_lr_model3.append([n] + [model3.coefs['Estimate'][i] for i in np.arange(1,4)])\n",
    "    pval_nodes_fish_lr_model3.append([n] + [model3.coefs['P-val'][i] for i in np.arange(1,4)])\n",
    "    \n",
    "coef_nodes_fish_lr_model3,pval_nodes_fish_lr_model3 = [np.array(i) for i in [coef_nodes_fish_lr_model3,pval_nodes_fish_lr_model3]]\n",
    "'''coef_nodes_rand_lr_model1,pval_nodes_rand_lr_model1,coef_nodes_rand_lr_model2,pval_nodes_rand_lr_model2,\\\n",
    "coef_nodes_rand_lr_model3,pval_nodes_rand_lr_model3 = [np.array(i) for i in [coef_nodes_rand_lr_model1,pval_nodes_rand_lr_model1,coef_nodes_rand_lr_model2,pval_nodes_rand_lr_model2,\\\n",
    "coef_nodes_rand_lr_model3,pval_nodes_rand_lr_model3]]'''\n",
    "\n",
    "#pval_nodes_fdr_rand_lr_model2 = []\n",
    "pval_nodes_fdr_fish_lr_model3 = []\n",
    "\n",
    "for ind in range(3):\n",
    "    pval_nodes_fdr_fish_lr_model3.append(lsu(pval_nodes_fish_lr_model3[:,ind+1],q=.05))\n",
    "\n",
    "\n",
    "sig_interaction_node_inds_fish =  [int(i) for i in np.where(pval_nodes_fdr_fish_lr_model3[2])[0]]\n",
    "print(sig_interaction_node_inds_fish)\n",
    "fish_sig_interaction_nodes = np.array([nodes_traits[0][sig_interaction_node_inds_fish],coef_nodes_fish_lr_model3[sig_interaction_node_inds_fish,3]]).T\n",
    "fish_sig_interaction_nodes"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30fd9c97283ec1278eec212a8f8afab06ad903f38228c32cacb469eba8e56f4f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('py37': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}