{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import general packages, check folders\n",
    "#%reset\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "#import imagesc as imagesc #pip install imagesc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# TO DO - REMOVE THE UNNECESSARY LIBRARY IMPORTS\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "working_dir = '/Users/f0053cz/Dropbox (Dartmouth College)/postdoc_Dartmouth/HCP/fMRIScipts/code'\n",
    "#working_dir = os.getcwd()\n",
    "print('current directory:\\n',working_dir)\n",
    "path = Path(working_dir)\n",
    "parent_folder = path.parent\n",
    "#print('parent folder:', parent_folder)\n",
    "data_file_loc = os.path.join(parent_folder,'data') # to store data we extract later in this notebook"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting default fontsizes for plots\n",
    "\n",
    "s=20 # CHANGE FONTSIZE HERE\n",
    "plt.rc('font', size=s) #controls default text size\n",
    "plt.rc('axes', titlesize=s) #fontsize of the title\n",
    "plt.rc('axes', labelsize=s) #fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=s) #fontsize of the x tick labels\n",
    "plt.rc('ytick', labelsize=s) #fontsize of the y tick labels\n",
    "plt.rc('legend', fontsize=s) #fontsize of the legend\n",
    "#import matplotlib as mpl\n",
    "#mpl.rcParams['font.weight']= 'normal'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#suff= ' '\n",
    "suff = '_corrected'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load behavioral data - coded 1 for \"social\", 0 for \"nonsocial\" and 9 for \"unsure\", nan for missed response\n",
    "# even if using the Mental/Random labels, need this to sub-select subs who have responded on all trials\n",
    "responses = np.load(os.path.join(data_file_loc,f'responses{suff}.npy'))\n",
    "responses.shape # subs *movies"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vid_joined = [\"COAXING-B\", \"BILLIARD-A\", \"DRIFTING-A\", \"Fishing\", \"Random mechanical\",\"Scaring\", \"SEDUCING-B\", \"STAR-A\", \"SURPRISING-B\", \"TENNIS-A\"]\n",
    "vid_joined"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Nr of complete subs:',len(np.where(np.array([len(np.where(~np.isnan(responses[s,:]))[0]) for s in range(responses.shape[0])])==10)[0]))\n",
    "print('total subs:', responses.shape[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "[timepts_indiv_movie,vid_start_rel_tr] = np.load(os.path.join(data_file_loc,'Video_TRs.npy'),allow_pickle=True)\n",
    "vid_start_rel_tr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run-level regressors vs. traits (option (5) on Miro)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import run-level regs\n",
    "flName = os.path.join(data_file_loc,f'coef_slopereg_all{suff}.npy')\n",
    "run_level_coefs = np.load(flName)\n",
    "#run_level_coefs.shape\n",
    "\n",
    "run_level_coefs_mean = np.nanmean(run_level_coefs, axis=2)\n",
    "run_level_coefs_mean.shape # USE THIS, BECAUSE THIS WAS USED IN THE MAIN GLM ANALYSIS!"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pymer4.models import Lm\n",
    "from multipy.fdr import lsu\n",
    "from datetime import datetime\n",
    "\n",
    "print(data_file_loc)\n",
    "nodes_coaxbill_rand_all = np.load(os.path.join(data_file_loc,'nodes_coaxbill_rand_all.npy')) # sig nodes hihglighted in the first S>NS GLM\n",
    "# for contours"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_file_loc = '/Users/f0053cz/Dropbox (Dartmouth College)/postdoc_Dartmouth/HCP/fMRIScipts/data'\n",
    "sub_id_all = np.load(os.path.join(data_file_loc,f'sub_ID_all{suff}.npy'))\n",
    "sub_id_all = [str(i) for i in sub_id_all]\n",
    "sub_id_all = np.array(sub_id_all)\n",
    "len(sub_id_all)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vidnames = [\"COAXING-B\", \"BILLIARD-A\", \"DRIFTING-A\", \"Fishing\", \"Random mechanical\",\"Scaring\", \"SEDUCING-B\", \"STAR-A\", \"SURPRISING-B\", \"TENNIS-A\"]\n",
    "\n",
    "# creating a 3D array of beta coeffs across movies from individual movie files\n",
    "all_coefs = np.zeros((responses.shape[0],268,10))\n",
    "\n",
    "for m in range(10):\n",
    "    fileName =  os.path.join(data_file_loc,'coefs_run_norm','slope_reg',f'coef_slopereg_runnorm_{vidnames[m]}{suff}.npy')\n",
    "    all_coefs[:,:,m] = np.load(fileName)\n",
    "    #print(dat.shape)\n",
    "\n",
    "all_coefs[:10,0,:2]\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# first of all, best to remove subjects with < 10 responses for power in general\n",
    "count_resp = np.zeros((responses.shape[0],))\n",
    "for i in range(responses.shape[0]):\n",
    "    count_resp[i] = len(np.where(~np.isnan(responses[i,:]))[0])\n",
    "subs_10resp = np.where(count_resp == 10)[0]\n",
    "len(subs_10resp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "res_behav_data = pd.read_csv('/Users/f0053cz/Documents/HCP_trait_diffs_DONOTSHARE/trait_analyses/data/RESTRICTED_esfinn_11_21_2021_19_19_35.csv')\n",
    "res_behav_data.set_index(\"Subject\", inplace=True)\n",
    "res_behav_data.index = res_behav_data.index.map(str)\n",
    "print(res_behav_data.shape)\n",
    "#res_behav_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# (5) effect of \"Social\" - \"Non-social\" beta and trait scores (without considering movies)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model9_txt = 'coefs_diff ~ ASR_Intn_T'\n",
    "nsubs_node = []\n",
    "# LM - run-level regs\n",
    "model9_res = []\n",
    "rval_pval_spearman_coef_diff_ASR_Intn_T = []\n",
    "start_time =  time.time()\n",
    "for n in range(268):\n",
    "    if n%10 == 0:\n",
    "        print(f'node {n+1},time={(time.time()-start_time)/60:.2f} mins')\n",
    "    \n",
    "    df = pd.DataFrame({'Subject':sub_id_all[subs_10resp], 'coefs_diff': run_level_coefs_mean[subs_10resp,n], 'subID':subs_10resp})\n",
    "    df.set_index(\"Subject\", inplace=True)\n",
    "\n",
    "    df_both = df.join(res_behav_data.loc[:,['ASR_Intn_T']], how='inner') # join betas and trait info\n",
    "    inds = ~np.isnan(df_both['coefs_diff']) & ~np.isnan(df_both['ASR_Intn_T']) # find rows where neither x or y is NaN\n",
    "    nsubs_node.append(len(np.where(inds)[0]))\n",
    "    df_both = df_both.loc[inds,:]\n",
    "    \n",
    "    model9 = Lm(model9_txt, data=df_both) # \n",
    "    model9.fit(summary = False, verbose = False)\n",
    "    model9_res.append([model9.coefs['Estimate'],model9.coefs['P-val'],model9.AIC])\n",
    "\n",
    "    rs,ps = stats.spearmanr(df_both['coefs_diff'],df_both['ASR_Intn_T'])\n",
    "    rval_pval_spearman_coef_diff_ASR_Intn_T.append([rs,ps])\n",
    "    if n == 0:\n",
    "        print('model:',model9.fit(summary = True, verbose = False))\n",
    "\n",
    "rval_pval_spearman_coef_diff_ASR_Intn_T = np.array(rval_pval_spearman_coef_diff_ASR_Intn_T)\n",
    "print('Done on/at:',datetime.now()) # cell run at)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n=31\n",
    "model9_res[n][0], '1', model9_res[n][1], '2', model9_res[n][2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model9_res[n][0][1], '1', model9_res[n][1][1], '2', model9_res[n][2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(model9_txt, model9.formula)\n",
    "# coef interaction-like term\n",
    "print(model9_txt)\n",
    "coef_p_model9 = [[model9_res[n][0][1], model9_res[n][1][1]] for n in range(268)] # ASR reg coefft\n",
    "coef_p_model9= np.array(coef_p_model9)\n",
    "print(coef_p_model9[:5,:])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Traits term's dependence on ASR_Intn_T:\")\n",
    "print('nodes with p < .05 :', np.where(coef_p_model9[:,1]<.05)[0])\n",
    "#coef_p_model9[coef_p_model9[:,1]<.05,1]\n",
    "\n",
    "coef_p_model9_fdr = lsu(coef_p_model9[:,1],q=.05)#fdr_correction(pval_slope_rand,.05)\n",
    "print('nodes with q<.05:', np.where(coef_p_model9_fdr)[0])\n",
    "\n",
    "#glm_nodes_inds = np.where(nodes_coaxbill_rand_all)[0]\n",
    "#print(f'There are {len(glm_nodes_inds)} GLM nodes.')\n",
    "\n",
    "#coef_p_model9_fdr_glmnodes = lsu(coef_p_model9[nodes_coaxbill_rand_all,1],q=.05)#fdr_correction(pval_slope_rand,.05)\n",
    "#print('glm nodes with q<.05 for traits:', glm_nodes_inds[coef_p_model9_fdr_glmnodes])\n",
    "\n",
    "min(coef_p_model9[:,0]),max(coef_p_model9[:,0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from nilearn.surface import vol_to_surf\n",
    "from nilearn.plotting import plot_glass_brain, plot_surf_roi,plot_stat_map,plot_img,plot_surf_contours\n",
    "import nibabel as nib\n",
    "from nilearn import datasets\n",
    "bg_img = datasets.load_mni152_template()\n",
    "fig_save_loc = os.path.join('/Users/f0053cz/Dropbox (Dartmouth College)/postdoc_Dartmouth/HCP/paper_prep/figures/fig2_2_traits/fmri_results/ALL')\n",
    "\n",
    "from nilearn.datasets import fetch_surf_fsaverage\n",
    "fsaverage = fetch_surf_fsaverage()\n",
    "\n",
    "from nilearn import datasets\n",
    "bg_img = datasets.load_mni152_template()\n",
    "\n",
    "from nltools.data import Brain_Data\n",
    "from nltools.mask import expand_mask, roi_to_brain\n",
    "\n",
    "\n",
    "mask = Brain_Data('https://neurovault.org/media/images/8423/shen_2mm_268_parcellation.nii.gz')\n",
    "mask_x = expand_mask(mask)\n",
    "\n",
    "def color_rois(values):\n",
    "    \"\"\"\n",
    "    This function assumes you are passing a vector \"values\" with the same length as the number of nodes in the atlas.\n",
    "    \"\"\"\n",
    "    shen268 = nib.load(os.path.join(data_file_loc,\"shen_2mm_268_parcellation.nii.gz\"))\n",
    "    shen268_data = shen268.get_fdata()\n",
    "    img = np.zeros(shen268_data.shape)\n",
    "    #print(shen268_data.shape)\n",
    "    for roi in range(len(values)):\n",
    "        itemindex = np.where(shen268_data==roi+1) # find voxels in this node (add 1 to account for zero-indexing)\n",
    "        #print(len(itemindex[0]))\n",
    "        img[itemindex] = values[roi] # color them by the desired value \n",
    "    affine = shen268.affine\n",
    "    img_nii = nib.Nifti1Image(img, affine)\n",
    "    return img_nii\n",
    "\n",
    "def surf_plot1(fig,ax,nodes,params, thresh):\n",
    "    title_txt = params['title']\n",
    "    txt  = params['txt']\n",
    "    vmin = params['vmin']\n",
    "    vmax = params['vmax']\n",
    "\n",
    "    #LH\n",
    "    ax_surf = ax[0,0]\n",
    "    texture = vol_to_surf(color_rois(nodes), fsaverage.pial_left,interpolation='nearest',radius =1, n_samples=1)\n",
    "    surf_plot1=plot_surf_roi(fsaverage.infl_left, texture, hemi='left',cmap = cmap, colorbar=False, symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                                bg_map=fsaverage.sulc_left,axes = ax_surf, threshold =  thresh)#)#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "    texture_contour = vol_to_surf(color_rois(nodes_coaxbill_rand_all), fsaverage.pial_left,interpolation='nearest',radius =1, n_samples=1)\n",
    "    plot_surf_contours(fsaverage.infl_left, texture_contour, axes = ax_surf,figure=surf_plot1, legend=True,levels = [1], colors=['k'])\n",
    "\n",
    "    ax_surf = ax[1,0]\n",
    "    surf_plot2=plot_surf_roi(fsaverage.infl_left, texture, hemi='left',cmap = cmap, colorbar=False, symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                                bg_map=fsaverage.sulc_left, view = 'medial',axes = ax_surf, threshold =  thresh)#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "    plot_surf_contours(fsaverage.infl_left, texture_contour, axes = ax_surf,figure=surf_plot2, legend=True,levels = [1], colors=['k'])\n",
    "\n",
    "    #RH\n",
    "    ax_surf = ax[0,1]\n",
    "    texture = vol_to_surf(color_rois(nodes), fsaverage.pial_right,interpolation='nearest',radius =1, n_samples=1)\n",
    "    surf_plot3=plot_surf_roi(fsaverage.infl_right, texture, hemi='right',cmap = cmap, colorbar=True,symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                                bg_map=fsaverage.sulc_right,axes = ax_surf, threshold =  thresh)#)#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "    texture_contour = vol_to_surf(color_rois(nodes_coaxbill_rand_all), fsaverage.pial_right,interpolation='nearest',radius =1, n_samples=1)\n",
    "    plot_surf_contours(fsaverage.infl_right, texture_contour, axes = ax_surf,figure=surf_plot3, legend=True,levels = [1], colors=['k'])\n",
    "    surf_plot3.axes[4].text(10,.5*vmax,s=txt,fontsize=20, fontdict = {'verticalalignment':'top','horizontalalignment':'left','rotation':0})\n",
    "    box = surf_plot3.axes[4].get_position()\n",
    "    surf_plot3.axes[4].set_position([box.x0*.93, box.y0-.3, box.width, box.height*2])  # move a bit the bar to the right, need to divide by number of columns (to move relative to last figure only, not to overall row, else will get too far away)\n",
    "    \n",
    "\n",
    "    ax_surf = ax[1,1]\n",
    "    surf_plot4=plot_surf_roi(fsaverage.infl_right, texture, hemi='right',cmap = cmap, colorbar=False,symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                                bg_map=fsaverage.sulc_right, view ='medial',axes = ax_surf, threshold =  thresh)#)#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "    plot_surf_contours(fsaverage.infl_right, texture_contour, axes = ax_surf,figure=surf_plot4, legend=True, levels = [1], colors=['k'])#, labels=['Sig. (q<.05) across\\n(a),(c),(d)'])\n",
    "\n",
    "    ax[0,0].dist = 7 # change viewing distance to \"zoom in\" to surface plots\n",
    "    ax[0,1].dist = 7\n",
    "    ax[1,0].dist = 7\n",
    "    ax[1,1].dist = 7\n",
    "\n",
    "    #fig.colorbar(surf_plot3.axes[2])\n",
    "    plt.subplots_adjust(left=0,\n",
    "                        bottom=0, \n",
    "                        right=.8, \n",
    "                        top=1, \n",
    "                        wspace=0.0, \n",
    "                        hspace=-.1)    \n",
    "fig_save_loc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(np.where(coef_p_model9[:,1]<.05)[0]), len(np.where((coef_p_model9[:,1]<.05) & (nodes_coaxbill_rand_all))[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "min(coef_p_model9[:,0]), max(coef_p_model9[:,0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig_save_loc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots\n",
    "vmin,vmax = -.003,.003\n",
    "cmap =  'RdBu_r' #'RdBu_r', 'PiYG'\n",
    "txt = '     'r\"$\\overline{\\beta}(traits)$\" # to be corrected - remove overline (NOT \"MEAN\" BETA)\n",
    "title_txt = 'traits term beta (p<.05)'\n",
    " \n",
    "thresh = 1e-10\n",
    "nodes = np.zeros((268,))\n",
    "nodes[(coef_p_model9[:,1]<.05)] = coef_p_model9[(coef_p_model9[:,1]<.05),0]\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params,thresh = 1e-10)\n",
    "plt.savefig(os.path.join(fig_save_loc,f'soc_vs_nonsoc/resp_trait_corr_unc_all_nodes_surf.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img, threshold=thresh,\n",
    "colorbar= False)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "plt.savefig(os.path.join(fig_save_loc,f'soc_vs_nonsoc/resp_trait_corr_unc_all_nodes_axial.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots\n",
    "vmin,vmax = -.003,.003\n",
    "cmap =  'RdBu_r' #'RdBu_r', 'PiYG'\n",
    "txt = '     'r\"$\\overline{\\beta}(traits)$\" # to be corrected - remove overline (NOT \"MEAN\" BETA)\n",
    "title_txt = 'traits term beta (p<.05)'\n",
    " \n",
    "thresh = 1e-10\n",
    "nodes = np.zeros((268,))\n",
    "nodes[(coef_p_model9[:,1]<.05) &  (nodes_coaxbill_rand_all)] = coef_p_model9[(coef_p_model9[:,1]<.05) & (nodes_coaxbill_rand_all),0]\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params,thresh = 1e-10)\n",
    "plt.savefig(os.path.join(fig_save_loc,f'soc_vs_nonsoc/resp_trait_corr_unc_GLM nodes_surf.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img, threshold=thresh,\n",
    "colorbar= False)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "plt.savefig(os.path.join(fig_save_loc,f'soc_vs_nonsoc/resp_trait_corr_unc_GLM nodes_axial.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CORRELATION between run-wise diff and traits"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(np.where(rval_pval_spearman_coef_diff_ASR_Intn_T[:,1]<.05))\n",
    "print(np.where(lsu(rval_pval_spearman_coef_diff_ASR_Intn_T[:,1])))\n",
    "print(np.where(lsu(rval_pval_spearman_coef_diff_ASR_Intn_T[nodes_coaxbill_rand_all,1])))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "qcorr = np.zeros((268,))\n",
    "qcorr[nodes_coaxbill_rand_all] = lsu(rval_pval_spearman_coef_diff_ASR_Intn_T[nodes_coaxbill_rand_all,1])\n",
    "np.where(qcorr)\n",
    "\n",
    "min(rval_pval_spearman_coef_diff_ASR_Intn_T[:,0]), max(rval_pval_spearman_coef_diff_ASR_Intn_T[:,0])\n",
    "rval_pval_spearman_coef_diff_ASR_Intn_T[:,0]\n",
    "\n",
    "\n",
    "# nodes showing sig (unc p <.05) correlation between \"Social\"-\"Non-social\" and trait score\n",
    "vmin,vmax = -.08,.08\n",
    "cmap =  'RdBu_r' #'RdBu_r', 'PiYG'\n",
    "#txt = r\"$\\overline{\\beta}(''S''-''NS'')$\"\n",
    "txt = \"rSp_traits\" \n",
    "\n",
    "title_txt = 'traits term Spearman_r (p<.05)' \n",
    "thresh = 1e-10\n",
    "\n",
    "nodes = np.zeros((268,))\n",
    "nodes[rval_pval_spearman_coef_diff_ASR_Intn_T[:,1]<.05] = rval_pval_spearman_coef_diff_ASR_Intn_T[rval_pval_spearman_coef_diff_ASR_Intn_T[:,1]<.05,0]\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params,thresh = 1e-10)\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_surf_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img, threshold=thresh,\n",
    "colorbar= False)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "\n",
    "\n",
    "print(model9_txt)\n",
    "coef_p_model9 = [[model9_res[n][0][1], model9_res[n][1][1]] for n in range(268)] # ASR reg coefft\n",
    "coef_p_model9= np.array(coef_p_model9)\n",
    "print(coef_p_model9[:5,:])\n",
    "\n",
    "print('sig terms:', len(np.where(coef_p_model9[:,1]<.05)[0]))\n",
    "#coef_p_model9[coef_p_model9[:,1]<.05,1]\n",
    "coef_p_model9_fdr = lsu(coef_p_model9[:,1],q=.05)#fdr_correction(pval_slope_rand,.05)\n",
    "len(np.where(coef_p_model9_fdr)[0])\n",
    "\n",
    "min(coef_p_model9[:,0]),max(coef_p_model9[:,0])\n",
    "\n",
    "# surface plots\n",
    "vmin,vmax = -.003,.003\n",
    "cmap =  'RdBu_r' #'RdBu_r', 'PiYG'\n",
    "txt = r\"$\\overline{\\beta}(traits)$\"\n",
    "\n",
    "title_txt = 'traits term beta (p<.05)'\n",
    "thresh = 1e-10\n",
    "\n",
    "nodes = np.zeros((268,))\n",
    "nodes[coef_p_model9[:,1]<.05] = coef_p_model9[coef_p_model9[:,1]<.05,0]\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params,thresh = 1e-10)\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img, threshold=thresh,\n",
    "colorbar= False)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LME  response label vs. response label + traits"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#install lme functions\n",
    "from pymer4.models import Lmer\n",
    "import time\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model1_txt = 'coefs ~  response +(1|subID) + (1|movie)'\n",
    "model2_txt = 'coefs ~  response*ASR_Intn_T + (1|movie)'\n",
    "model3_txt = 'coefs ~  response + ASR_Intn_T + (1|movie)'\n",
    "model4_txt =  'coefs ~ response + (1|movie)'\n",
    "model5_txt = 'coefs ~  response'\n",
    "model6_txt = 'coefs ~  response + ASR_Intn_T'\n",
    "model7_txt = 'coefs ~  response * ASR_Intn_T'\n",
    "model8_txt = 'coefs ~  ASR_Intn_T'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random mech"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# LM - RESPTYPE VS RESPTYPE+TRAIT BASED\n",
    "load_all = 0 # 1: load saved coefs, 0: run the LME\n",
    "\n",
    "start_time =  time.time()\n",
    "model5_res_rand = []\n",
    "model6_res_rand = []\n",
    "model7_res_rand= []\n",
    "model8_res_rand = []\n",
    "\n",
    "rand_movie_ind = 4\n",
    "\n",
    "for n in range(268):\n",
    "    if n%10 == 0:\n",
    "        print(f'node {n+1},time={(time.time()-start_time)/60:.2f} mins')\n",
    "    \n",
    "    df = pd.DataFrame(columns = ['Subject','coefs','subID'])\n",
    "    \n",
    "\n",
    "    df_temp = pd.DataFrame({'Subject':sub_id_all, 'coefs': all_coefs[:,n, rand_movie_ind], 'response':responses[:, rand_movie_ind],\\\n",
    "        'subID':np.arange(sub_id_all.shape[0]) })\n",
    "\n",
    "    df = df.append(df_temp,ignore_index=True)\n",
    "    #df = df.loc[(df['response'] != 9) & (~np.isnan(df['response'])),:] # yes v no\n",
    "    df = df.loc[(~np.isnan(df['response'])),:] \n",
    "    \n",
    "    df.set_index(\"Subject\", inplace=True)\n",
    "    df_both = df.join(res_behav_data.loc[:,['ASR_Intn_T']], how='inner') # join betas and trait info\n",
    "    inds = ~np.isnan(df_both['coefs']) & ~np.isnan(df_both['ASR_Intn_T']) # find rows where neither x or y is NaN\n",
    "    df_both = df_both.loc[inds,:]\n",
    "\n",
    "    nresps_per_sub = df_both.groupby(['subID','response']).count().unstack(level=1).iloc[:,:2]\n",
    "    nresps_per_sub.columns = nresps_per_sub.columns.droplevel()\n",
    "\n",
    "    #rows_to_delete = np.zeros((subID.shape[0],))\n",
    "    #for i in biased_sub_IDs:\n",
    "    #    rows_to_delete[subID == i] = 1\n",
    "\n",
    "    #df_both['rows_to_delete'] = rows_to_delete\n",
    "    df_both_nobiasedsubs = df_both\n",
    "    #df_both_nobiasedsubs = df_both.loc[df_both['rows_to_delete']==0,:]\n",
    "    #df_both_nobiasedsubs['response'] = df_both_nobiasedsubs['response'].map({0.0: \"Non-social\", 1.0:  \"Social\"}) \n",
    "    df_both_nobiasedsubs['response'] = df_both_nobiasedsubs['response'].map({0.0: \"Non-social\", 1.0:  \"XAny_social\", 9.0:  \"XAny_social\"}) # yes or unsure v no\n",
    "     \n",
    "    # base LME that depends only on response, taking into account subject and movie variance\n",
    "\n",
    "    model5 = Lm(model5_txt, data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    #model1 = Lmer('coefs ~  response +(1|subID) + (1|movie)', data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    #model5.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "    #model5.fit(factors={\"response\":[\"Non-social\",\"Any_social\"]},ordered=True,summary = False, verbose = False)\n",
    "    model5.fit(summary = False, verbose = False)\n",
    "    model5_res_rand.append([model5.coefs['Estimate'],model5.coefs['P-val'],model5.AIC])\n",
    "\n",
    "    # to determine noes with a significant percept-trait interaction\n",
    "    model6 = Lm(model6_txt, data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    #model2 = Lmer('coefs ~  response*ASR_Intn_T + (1|movie)', data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    #model6.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "    #model6.fit(factors={\"response\":[\"Non-social\",\"Any_social\"]},ordered=True,summary = False, verbose = False)\n",
    "    model6.fit(summary = False, verbose = False)\n",
    "    model6_res_rand.append([model6.coefs['Estimate'],model6.coefs['P-val'],model6.AIC])\n",
    "\n",
    "    # to determine if the trait term has a sig beta over what response explains\n",
    "    model7 = Lm(model7_txt, data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    #model3 = Lmer('coefs ~  response + ASR_Intn_T + (1|movie)', data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    #model7.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "    #model7.fit(factors={\"response\":[\"Non-social\",\"Any_social\"]},ordered=True,summary = False, verbose = False)\n",
    "    model7.fit(summary = False, verbose = False)\n",
    "    model7_res_rand.append([model7.coefs['Estimate'],model7.coefs['P-val'],model7.AIC])\n",
    "\n",
    "    # base LME that depends only on response, taking into account movie variance - for comparison with the above model\n",
    "    model8 = Lm(model8_txt, data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    #model4 = Lmer('coefs ~  response + (1|movie)', data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    #model8.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "    #model8.fit(factors={\"response\":[\"Non-social\",\"Any_social\"]},ordered=True,summary = False, verbose = False)\n",
    "    model8.fit(summary = False, verbose = False)\n",
    "    model8_res_rand.append([model8.coefs['Estimate'],model8.coefs['P-val'],model8.AIC])\n",
    "\n",
    "    if n == 0:\n",
    "        #print('model:',model5.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False))\n",
    "        #print('model:',model5.fit(factors={\"response\":[\"Non-social\",\"Social\"]}))\n",
    "        print('model:',model5.fit(factors={\"response\":[\"Non-social\",\"Any_social\"]},summary = False, verbose = False))\n",
    "        print('model:',model5.fit(factors={\"response\":[\"Non-social\",\"Any_social\"]}))\n",
    "\n",
    "print('Done on/at:',datetime.now()) # cell run at)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# All movies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# LMER - RESPTYPE VS RESPTYPE+TRAIT BASED\n",
    "load_all = 0 # 1: load saved coefs, 0: run the LME\n",
    "\n",
    "\n",
    "#if load_all == 1:\n",
    "#     df_all_coefs = pd.read_csv(os.path.join(data_file_loc,'coefs_run_norm','slope_reg','LME_S_NS_revision1','lmecoefs_all_S_NS_S_NSwithtraits.csv'))\n",
    "#[coef_ALL_stim,pval_ALL_stim] = np.load(os.path.join(data_file_loc,'coefs_run_norm','slope_reg','LME_S_NS_revision1','lmecoefs_all_S_NS_stimType.npy'), allow_pickle=True)\n",
    "#else:\n",
    "start_time =  time.time()\n",
    "model1_res = []\n",
    "model2_res = []\n",
    "model3_res = []\n",
    "model4_res = []\n",
    "for n in range(268):\n",
    "    if n%10 == 0:\n",
    "        print(f'node {n+1},time={(time.time()-start_time)/60:.2f} mins')\n",
    "    \n",
    "    df = pd.DataFrame(columns = ['Subject','coefs','subID','movie'])\n",
    "    for m in range(10):\n",
    "        df_temp = pd.DataFrame({'Subject':sub_id_all[subs_10resp], 'coefs': all_coefs[subs_10resp,n,m], 'response':responses[subs_10resp,m],\\\n",
    "            'subID':subs_10resp,\\\n",
    "                'movie':np.repeat(m,len(subs_10resp))})\n",
    "        df = df.append(df_temp,ignore_index=True)\n",
    "        df = df.loc[df['response'] != 9] # yes v no\n",
    "    \n",
    "    df.set_index(\"Subject\", inplace=True)\n",
    "    df_both = df.join(res_behav_data.loc[:,['ASR_Intn_T']], how='inner') # join betas and trait info\n",
    "    inds = ~np.isnan(df_both['coefs']) & ~np.isnan(df_both['ASR_Intn_T']) # find rows where neither x or y is NaN\n",
    "    df_both = df_both.loc[inds,:]\n",
    "\n",
    "    nresps_per_sub = df_both.groupby(['subID','response']).count().unstack(level=1).iloc[:,:2]\n",
    "    nresps_per_sub.columns = nresps_per_sub.columns.droplevel()\n",
    "\n",
    "    biased_sub_IDs1 = list(nresps_per_sub[nresps_per_sub[0].isna()].index)\n",
    "    biased_sub_IDs1 # No \"Non-social response\"\n",
    "\n",
    "    biased_sub_IDs2 = list(nresps_per_sub[nresps_per_sub[1].isna()].index)\n",
    "    biased_sub_IDs2 #  No \"Social\" response\n",
    "\n",
    "    biased_sub_IDs = biased_sub_IDs1 + biased_sub_IDs2\n",
    "\n",
    "    subID = df_both['subID'].values\n",
    "    rows_to_delete = np.zeros((subID.shape[0],))\n",
    "    for i in biased_sub_IDs:\n",
    "        rows_to_delete[subID == i] = 1\n",
    "\n",
    "    df_both['rows_to_delete'] = rows_to_delete\n",
    "    df_both_nobiasedsubs = df_both.loc[df_both['rows_to_delete']==0,:]\n",
    "    df_both_nobiasedsubs['response'] = df_both_nobiasedsubs['response'].map({0.0: \"Non-social\", 1.0:  \"Social\"})\n",
    "    \n",
    "    # base LME that depends only on response, taking into account subject and movie variance\n",
    "    model1 = Lmer(model1_txt, data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    #model1 = Lmer('coefs ~  response +(1|subID) + (1|movie)', data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    model1.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "    model1_res.append([model1.coefs['Estimate'],model1.coefs['P-val'],model1.AIC])\n",
    "\n",
    "    # to determine noes with a significant percept-trait interaction\n",
    "    model2 = Lmer(model2_txt, data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    #model2 = Lmer('coefs ~  response*ASR_Intn_T + (1|movie)', data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    model2.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "    model2_res.append([model2.coefs['Estimate'],model2.coefs['P-val'],model2.AIC])\n",
    "\n",
    "    # to determine if the trait term has a sig beta over what response explains\n",
    "    model3 = Lmer(model3_txt, data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    #model3 = Lmer('coefs ~  response + ASR_Intn_T + (1|movie)', data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    model3.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "    model3_res.append([model3.coefs['Estimate'],model3.coefs['P-val'],model3.AIC])\n",
    "\n",
    "    # base LME that depends only on response, taking into account movie variance - for comparison with the above model\n",
    "    model4 = Lmer(model4_txt, data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    #model4 = Lmer('coefs ~  response + (1|movie)', data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    model4.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "    model4_res.append([model4.coefs['Estimate'],model4.coefs['P-val'],model4.AIC])\n",
    "\n",
    "    #if n == 0:\n",
    "    #    print('model:',model1.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False))\n",
    "    #    print('model:',model2.fit(factors={\"response\":[\"Non-social\",\"Social\"]}))\n",
    "\n",
    "\n",
    "print('Done on/at:',datetime.now()) # cell run at)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# LM - RESP VS RESPTYPE+TRAIT BASED\n",
    "\n",
    "'''load_all = 0 # 1: load saved coefs, 0: run the LME\n",
    "if load_all == 1:\n",
    "    df_all_coefs = pd.read_csv(os.path.join(data_file_loc,'coefs_run_norm','slope_reg','LME_S_NS_revision1','lmecoefs_all_S_NS_S_NSwithtraits.csv'))\n",
    "    #[coef_ALL_stim,pval_ALL_stim] = np.load(os.path.join(data_file_loc,'coefs_run_norm','slope_reg','LME_S_NS_revision1','lmecoefs_all_S_NS_stimType.npy'), allow_pickle=True)\n",
    "else:'''\n",
    "\n",
    "model5_res = []\n",
    "model6_res = []\n",
    "model7_res = []\n",
    "model8_res = []\n",
    "start_time =  time.time()\n",
    "for n in range(268):\n",
    "    if n%10 == 0:\n",
    "        print(f'node {n+1},time={(time.time()-start_time)/60:.2f} mins')\n",
    "    \n",
    "    df = pd.DataFrame(columns = ['Subject','coefs','subID','movie'])\n",
    "    for m in range(10):\n",
    "        df_temp = pd.DataFrame({'Subject':sub_id_all[subs_10resp], 'coefs': all_coefs[subs_10resp,n,m], 'response':responses[subs_10resp,m],\\\n",
    "            'subID':subs_10resp,\\\n",
    "                'movie':np.repeat(m,len(subs_10resp))})\n",
    "        df = df.append(df_temp,ignore_index=True)\n",
    "        df = df.loc[df['response'] != 9] # yes v no\n",
    "    \n",
    "    df.set_index(\"Subject\", inplace=True)\n",
    "    df_both = df.join(res_behav_data.loc[:,['ASR_Intn_T']], how='inner') # join betas and trait info\n",
    "    inds = ~np.isnan(df_both['coefs']) & ~np.isnan(df_both['ASR_Intn_T']) # find rows where neither x or y is NaN\n",
    "    df_both = df_both.loc[inds,:]\n",
    "\n",
    "    nresps_per_sub = df_both.groupby(['subID','response']).count().unstack(level=1).iloc[:,:2]\n",
    "    nresps_per_sub.columns = nresps_per_sub.columns.droplevel()\n",
    "\n",
    "    biased_sub_IDs1 = list(nresps_per_sub[nresps_per_sub[0].isna()].index)\n",
    "    biased_sub_IDs1 # No \"Non-social response\"\n",
    "\n",
    "    biased_sub_IDs2 = list(nresps_per_sub[nresps_per_sub[1].isna()].index)\n",
    "    biased_sub_IDs2 #  No \"Social\" response\n",
    "\n",
    "    biased_sub_IDs = biased_sub_IDs1 + biased_sub_IDs2\n",
    "\n",
    "    subID = df_both['subID'].values\n",
    "    rows_to_delete = np.zeros((subID.shape[0],))\n",
    "    for i in biased_sub_IDs:\n",
    "        rows_to_delete[subID == i] = 1\n",
    "\n",
    "    df_both['rows_to_delete'] = rows_to_delete\n",
    "    df_both_nobiasedsubs = df_both.loc[df_both['rows_to_delete']==0,:]\n",
    "    df_both_nobiasedsubs['response'] = df_both_nobiasedsubs['response'].map({0.0: \"Non-social\", 1.0:  \"Social\"})\n",
    "\n",
    "    model5 = Lm(model5_txt, data=df_both_nobiasedsubs) # \n",
    "    model5.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "    model5_res.append([model5.coefs['Estimate'],model5.coefs['P-val'],model5.AIC])\n",
    "    \n",
    "    model6 = Lm(model6_txt, data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    model6.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "    model6_res.append([model6.coefs['Estimate'],model6.coefs['P-val'],model6.AIC])\n",
    "\n",
    "    model7 = Lm(model7_txt, data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    model7.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "    model7_res.append([model7.coefs['Estimate'],model7.coefs['P-val'],model7.AIC])\n",
    "\n",
    "    model8 = Lm(model8_txt, data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    model8.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "    model8_res.append([model8.coefs['Estimate'],model8.coefs['P-val'],model8.AIC])\n",
    "\n",
    "    #if n == 0:\n",
    "    #    print('model:',model1.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False))\n",
    "    #    print('model:',model2.fit(factors={\"response\":[\"Non-social\",\"Social\"]}))\n",
    "\n",
    "print('Done on/at:',datetime.now()) # cell run at)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Unsure response trials"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# LM - Unsure trials\n",
    "\n",
    "model8_res_unsure = []\n",
    "start_time =  time.time()\n",
    "for n in range(268):\n",
    "    if n%10 == 0:\n",
    "        print(f'node {n+1},time={(time.time()-start_time)/60:.2f} mins')\n",
    "    \n",
    "    df = pd.DataFrame(columns = ['Subject','coefs','subID','movie'])\n",
    "    for m in range(10):\n",
    "        df_temp = pd.DataFrame({'Subject':sub_id_all[subs_10resp], 'coefs': all_coefs[subs_10resp,n,m], 'response':responses[subs_10resp,m],\\\n",
    "            'subID':subs_10resp,\\\n",
    "                'movie':np.repeat(m,len(subs_10resp))})\n",
    "        df = df.append(df_temp,ignore_index=True)\n",
    "        df = df.loc[df['response'] == 9] # only \"Unsure\"\n",
    "    \n",
    "    df.set_index(\"Subject\", inplace=True)\n",
    "    df_both = df.join(res_behav_data.loc[:,['ASR_Intn_T']], how='inner') # join betas and trait info\n",
    "    inds = ~np.isnan(df_both['coefs']) & ~np.isnan(df_both['ASR_Intn_T']) # find rows where neither x or y is NaN\n",
    "    df_both = df_both.loc[inds,:]\n",
    "\n",
    "\n",
    "    subID = df_both['subID'].values\n",
    "    rows_to_delete = np.zeros((subID.shape[0],))\n",
    "    for i in biased_sub_IDs:\n",
    "        rows_to_delete[subID == i] = 1\n",
    "\n",
    "    df_both_nobiasedsubs = df_both\n",
    "    #df_both_nobiasedsubs['response'] = df_both_nobiasedsubs['response'].map({0.0: \"Non-social\", 1.0:  \"Social\"})\n",
    "\n",
    "    model8 = Lm(model8_txt, data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    model8.fit(summary = False, verbose = False)\n",
    "    model8_res_unsure.append([model8.coefs['Estimate'],model8.coefs['P-val'],model8.AIC])\n",
    "\n",
    "    #if n == 0:\n",
    "    #    print('model:',model1.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False))\n",
    "    #    print('model:',model2.fit(factors={\"response\":[\"Non-social\",\"Social\"]}))\n",
    "\n",
    "print('Done on/at:',datetime.now()) # cell run at)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model8_txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model8_txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model10_txt =  'coefs ~ stimType * ASR_Intn_T'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# LM - Unsure trials\n",
    "\n",
    "model10_res_unsure = []\n",
    "start_time =  time.time()\n",
    "for n in range(268):\n",
    "    if n%10 == 0:\n",
    "        print(f'node {n+1},time={(time.time()-start_time)/60:.2f} mins')\n",
    "    \n",
    "    df = pd.DataFrame(columns = ['Subject','coefs','subID','movie'])\n",
    "    for m in range(10):\n",
    "        df_temp = pd.DataFrame({'Subject':sub_id_all[subs_10resp], 'coefs': all_coefs[subs_10resp,n,m], 'response':responses[subs_10resp,m],\\\n",
    "            'subID':subs_10resp,\\\n",
    "                'movie':np.repeat(m,len(subs_10resp))})\n",
    "        df = df.append(df_temp,ignore_index=True)\n",
    "        df = df.loc[df['response'] == 9] # only \"Unsure\"\n",
    "    \n",
    "    df.set_index(\"Subject\", inplace=True)\n",
    "    df_both = df.join(res_behav_data.loc[:,['ASR_Intn_T']], how='inner') # join betas and trait info\n",
    "    inds = ~np.isnan(df_both['coefs']) & ~np.isnan(df_both['ASR_Intn_T']) # find rows where neither x or y is NaN\n",
    "    df_both = df_both.loc[inds,:]\n",
    "\n",
    "\n",
    "    subID = df_both['subID'].values\n",
    "    rows_to_delete = np.zeros((subID.shape[0],))\n",
    "    for i in biased_sub_IDs:\n",
    "        rows_to_delete[subID == i] = 1\n",
    "\n",
    "    df_both_nobiasedsubs = df_both\n",
    "    df_both_nobiasedsubs['stimType'] = ['Mental' if i < 5 else \"ARandom\" for i in df_both_nobiasedsubs['movie'] ] \n",
    "    #df_both_nobiasedsubs['response'] = df_both_nobiasedsubs['response'].map({0.0: \"Non-social\", 1.0:  \"Social\"})\n",
    "\n",
    "    model10 = Lm(model10_txt, data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "    model10.fit(summary = False, verbose = False)\n",
    "    model10_res_unsure.append([model10.coefs['Estimate'],model10.coefs['P-val'],model10.AIC])\n",
    "\n",
    "    #if n == 0:\n",
    "    #    print('model:',model1.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False))\n",
    "    #    print('model:',model2.fit(factors={\"response\":[\"Non-social\",\"Social\"]}))\n",
    "\n",
    "print('Done on/at:',datetime.now()) # cell run at)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot results on brain"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Model 1:', model1.formula, '\\nModel 2:', model2.formula, '\\nModel 3:', model3.formula, '\\nModel 4:', model4.formula, \n",
    "'\\nModel 5:', model5.formula, '\\nModel 6:', model6.formula, '\\nModel 7:', model7.formula, '\\nModel 8:', model8.formula)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# (1) AIC model 3 v. model 4 (LME models with and without the traits term)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('model3:',model3_txt, '\\nmodel4:', model4_txt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "AIC_diff =  np.array([model3_res[n][2] -  model4_res[n][2] for n in range(268)])\n",
    "plt.hist(AIC_diff)\n",
    "np.where(AIC_diff < -2)[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "shen268_lbl = pd.read_csv(os.path.join(data_file_loc,\"shen_dictionary.csv\"))\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "shen268_lbl.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n=49\n",
    "eval(shen268_lbl[str(n+1)][0])['name'], eval(shen268_lbl[str(n+1)][0])['coords']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "min(AIC_diff),max(AIC_diff)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots\n",
    "vmin,vmax = -23,23\n",
    "cmap =  'PiYG' #'RdBu_r', 'PiYG'\n",
    "txt = ' AIC Traitsmodel-\\nNoTraitsModel'\n",
    "#txt = r' $\\beta_{TraitScore}FDR.$'\n",
    "#txt = r' $\\overline{\\beta}(\\\"\"\")-$' + '\\n' + r'$\\overline{\\beta}_{Non-social}$'+ '\\n'\n",
    "#txt = '' #'AIC response-\\nbased LME - \\nstim-based LME' #'AIC S/NS LME - M/R LME'#r\"$\\overline{\\beta}{(diff)}$\"\n",
    "\n",
    "title_txt = 'Internalizing score reg coefft (p<.05)'\n",
    "\n",
    "nodes = np.zeros((268,))\n",
    "nodes = AIC_diff\n",
    "#nodes[coef_p_model3_intn_fdr] = coef_p_model3_intn[coef_p_model3_intn_fdr,0]\n",
    "\n",
    "thresh = 2 #1e-10\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params,thresh = thresh)\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_surf_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img, threshold= thresh,\n",
    "colorbar= False)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_axial_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (1a) trait term coefft - model 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model3_txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# coef trait term\n",
    "coef_p_model3_traits = [[model3_res[n][0][2], model3_res[n][1][2]] for n in range(268)]\n",
    "coef_p_model3_traits = np.array(coef_p_model3_traits)\n",
    "print(coef_p_model3_traits[:5,:])\n",
    "\n",
    "Traits_sig_ROIs = np.where(coef_p_model3_traits[:,1]<.05)[0]\n",
    "Traits_sig_ROIs\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "coef_p_model3_traits_fdr = lsu(coef_p_model3_traits[:,1],q=.05)#fdr_correction(pval_slope_rand,.05)\n",
    "np.where(coef_p_model3_traits_fdr)[0], len(np.where(coef_p_model3_traits_fdr)[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vmin,vmax = min(coef_p_model3_traits[:,0]),max(coef_p_model3_traits[:,0])\n",
    "vmin,vmax"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots\n",
    "vmin,vmax = -.005,.005\n",
    "cmap =  'RdBu_r' #'RdBu_r', 'PiYG'\n",
    "txt = r' $\\beta_{TraitScore}Unc.$'\n",
    "#txt = r' $\\beta_{TraitScore}FDR.$'\n",
    "#txt = r' $\\overline{\\beta}(\\\"\"\")-$' + '\\n' + r'$\\overline{\\beta}_{Non-social}$'+ '\\n'\n",
    "#txt = '' #'AIC response-\\nbased LME - \\nstim-based LME' #'AIC S/NS LME - M/R LME'#r\"$\\overline{\\beta}{(diff)}$\"\n",
    "\n",
    "title_txt = 'Internalizing score reg coefft (p<.05)'\n",
    " \n",
    "thresh = 1e-10\n",
    "\n",
    "nodes = np.zeros((268,))\n",
    "nodes[coef_p_model3_traits[:,1]<.05] = coef_p_model3_traits[coef_p_model3_traits[:,1]<.05,0]\n",
    "\n",
    "thresh = 1e-10\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params,thresh = 1e-10)\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_surf_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img, threshold= thresh,\n",
    "colorbar= False)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_axial_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# model 3 vs. 4 - comparing response beta terms between a model with and without trait terms - does adding a trait term for nodes showing trait sensitivity increase beta?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model3_txt, model4_txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model3_res[49][0], model4_res[49][0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "beta_resp_model3 = np.array([model3_res[n][0][1] for n in range(268)])\n",
    "beta_resp_model4 = np.array([model4_res[n][0][1] for n in range(268)])\n",
    "\n",
    "plt.hist(beta_resp_model3, color='blue', alpha = .3)\n",
    "plt.hist(beta_resp_model4, color='green', alpha = .3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.hist(beta_resp_model3[beta_resp_model3 >beta_resp_model4]-beta_resp_model4[beta_resp_model3 >beta_resp_model4], color='blue')\n",
    "plt.hist(beta_resp_model3[beta_resp_model3 < beta_resp_model4] - beta_resp_model4[beta_resp_model3 < beta_resp_model4], color='green')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "beta_diff34 = beta_resp_model3-beta_resp_model4\n",
    "plt.hist(beta_diff34, color='grey')\n",
    "plt.hist(beta_diff34[coef_p_model3_traits_fdr], color='red')\n",
    "stats.ttest_1samp(beta_diff34,0), np.nanmean(beta_diff34)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "beta_diff34_abs =  np.abs(beta_resp_model3) - np.abs(beta_resp_model4)\n",
    "plt.hist(beta_diff34_abs, color='grey')\n",
    "plt.hist(beta_diff34_abs[coef_p_model3_traits_fdr], color='red')\n",
    "stats.ttest_1samp(beta_diff34_abs,0), np.nanmean(beta_diff34_abs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('No traits model. min and max model 4:', min(beta_resp_model4[coef_p_model3_traits_fdr]),max(beta_resp_model4[coef_p_model3_traits_fdr]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots\n",
    "vmin,vmax = -.4,.4\n",
    "cmap =  'RdBu_r' #'RdBu_r', 'PiYG'\n",
    "txt = 'responseBeta\\n(NoTraitsModel)'\n",
    "#txt = r' $\\overline{\\beta}(\\\"\"\")-$' + '\\n' + r'$\\overline{\\beta}_{Non-social}$'+ '\\n'\n",
    "#txt = '' #'AIC response-\\nbased LME - \\nstim-based LME' #'AIC S/NS LME - M/R LME'#r\"$\\overline{\\beta}{(diff)}$\"\n",
    " \n",
    "thresh = 1e-10\n",
    "\n",
    "nodes = np.zeros((268,))\n",
    "nodes[coef_p_model3_traits_fdr] = beta_resp_model4[coef_p_model3_traits_fdr]\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params,thresh = 1e-10)\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_surf_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img, threshold=thresh,\n",
    "colorbar= False)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_axial_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('with traits model. min and max model 3:', min(beta_resp_model3[coef_p_model3_traits_fdr]), max(beta_resp_model3[coef_p_model3_traits_fdr]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots\n",
    "vmin,vmax = -.4,.4\n",
    "cmap =  'RdBu_r' #'RdBu_r', 'PiYG'\n",
    "txt = 'responseBeta\\n(Traitsmodel)'\n",
    "#txt = r' $\\overline{\\beta}(\\\"\"\")-$' + '\\n' + r'$\\overline{\\beta}_{Non-social}$'+ '\\n'\n",
    "#txt = '' #'AIC response-\\nbased LME - \\nstim-based LME' #'AIC S/NS LME - M/R LME'#r\"$\\overline{\\beta}{(diff)}$\"\n",
    " \n",
    "thresh = 1e-10\n",
    "\n",
    "nodes = np.zeros((268,))\n",
    "nodes[coef_p_model3_traits_fdr] = beta_resp_model3[coef_p_model3_traits_fdr]\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params,thresh = 1e-10)\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_surf_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img, threshold=thresh,\n",
    "colorbar= False)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_axial_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# (6) \"Unsure\" response analyses"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model8_txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# coef trait term\n",
    "coef_p_model8_traits_unsure = [[model8_res_unsure[n][0][1], model8_res_unsure[n][1][1]] for n in range(268)]\n",
    "coef_p_model8_traits_unsure = np.array(coef_p_model8_traits_unsure)\n",
    "print(coef_p_model8_traits_unsure[:5,:])\n",
    "\n",
    "Traits_sig_ROIs = np.where(coef_p_model8_traits_unsure[:,1]<.05)[0]\n",
    "Traits_sig_ROIs\n",
    "\n",
    "coef_p_model8_traits_unsure_fdr = lsu(coef_p_model8_traits_unsure[:,1],q=.05)#fdr_correction(pval_slope_rand,.05)\n",
    "np.where(coef_p_model8_traits_unsure_fdr)[0], len(np.where(coef_p_model8_traits_unsure[:,1]<.05)[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "min(coef_p_model8_traits_unsure[:,0]), max(coef_p_model8_traits_unsure[:,0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.where(coef_p_model8_traits_unsure_fdr[nodes_coaxbill_rand_all])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots\n",
    "vmin,vmax = -.01,.01\n",
    "cmap =  'RdBu_r' #'RdBu_r', 'PiYG'\n",
    "txt = 'Est_traits_Unsure'\n",
    "#txt = r' $\\overline{\\beta}(\\\"\"\")-$' + '\\n' + r'$\\overline{\\beta}_{Non-social}$'+ '\\n'\n",
    "#txt = '' #'AIC response-\\nbased LME - \\nstim-based LME' #'AIC S/NS LME - M/R LME'#r\"$\\overline{\\beta}{(diff)}$\"\n",
    " \n",
    "thresh = 1e-10\n",
    "\n",
    "nodes = np.zeros((268,))\n",
    "nodes[coef_p_model8_traits_unsure[:,1]<.05] = coef_p_model8_traits_unsure[coef_p_model8_traits_unsure[:,1]<.05,0]\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params,thresh = 1e-10)\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img, threshold=thresh,\n",
    "colorbar= False)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# (b) stimType*traits"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# coef trait term\n",
    "coef_p_model10_traits_unsure = [[model10_res_unsure[n][0][3], model10_res_unsure[n][1][3]] for n in range(268)]\n",
    "coef_p_model10_traits_unsure = np.array(coef_p_model10_traits_unsure)\n",
    "print(coef_p_model10_traits_unsure[:5,:])\n",
    "\n",
    "Traits_sig_ROIs = np.where(coef_p_model10_traits_unsure[:,1]<.05)[0]\n",
    "Traits_sig_ROIs\n",
    "\n",
    "coef_p_model10_traits_unsure_fdr = lsu(coef_p_model10_traits_unsure[:,1],q=.05)#fdr_correction(pval_slope_rand,.05)\n",
    "np.where(coef_p_model10_traits_unsure_fdr)[0], len(np.where(coef_p_model10_traits_unsure[:,1]<.05)[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model10.design_matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.where(lsu(coef_p_model10_traits_unsure[nodes_coaxbill_rand_all,1],q=.05))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "min(coef_p_model10_traits_unsure[:,0]), max(coef_p_model10_traits_unsure[:,0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.where(coef_p_model10_traits_unsure_fdr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots\n",
    "vmin,vmax = -.02,.02\n",
    "cmap =  'RdBu_r' #'RdBu_r', 'PiYG'\n",
    "txt = 'Est_Interaction term_Unsure'\n",
    "#txt = r' $\\overline{\\beta}(\\\"\"\")-$' + '\\n' + r'$\\overline{\\beta}_{Non-social}$'+ '\\n'\n",
    "#txt = '' #'AIC response-\\nbased LME - \\nstim-based LME' #'AIC S/NS LME - M/R LME'#r\"$\\overline{\\beta}{(diff)}$\"\n",
    " \n",
    "thresh = 1e-10\n",
    "\n",
    "nodes = np.zeros((268,))\n",
    "nodes[coef_p_model10_traits_unsure[:,1]<.05] = coef_p_model10_traits_unsure[coef_p_model10_traits_unsure[:,1]<.05,0]\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params,thresh = 1e-10)\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img, threshold=thresh,\n",
    "colorbar= False)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.where(coef_p_model10_traits_unsure[:,1]<.05)[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n = 0\n",
    "\n",
    "df = pd.DataFrame(columns = ['Subject','coefs','subID','movie'])\n",
    "for m in range(10):\n",
    "    df_temp = pd.DataFrame({'Subject':sub_id_all[subs_10resp], 'coefs': all_coefs[subs_10resp,n,m], 'response':responses[subs_10resp,m],\\\n",
    "        'subID':subs_10resp, 'movie':np.repeat(m,len(subs_10resp))})\n",
    "    df = df.append(df_temp,ignore_index=True)\n",
    "    df = df.loc[df['response'] == 9] # only \"Unsure\"\n",
    "\n",
    "df.set_index(\"Subject\", inplace=True)\n",
    "df_both = df.join(res_behav_data.loc[:,['ASR_Intn_T']], how='inner') # join betas and trait info\n",
    "inds = ~np.isnan(df_both['coefs']) & ~np.isnan(df_both['ASR_Intn_T']) # find rows where neither x or y is NaN\n",
    "df_both = df_both.loc[inds,:]\n",
    "\n",
    "\n",
    "subID = df_both['subID'].values\n",
    "rows_to_delete = np.zeros((subID.shape[0],))\n",
    "for i in biased_sub_IDs:\n",
    "    rows_to_delete[subID == i] = 1\n",
    "\n",
    "df_both_nobiasedsubs = df_both\n",
    "df_both_nobiasedsubs['stimType'] = ['Mental' if i < 5 else \"Random\" for i in df_both_nobiasedsubs['movie'] ] "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mean_per_sub = df_both_nobiasedsubs.groupby(['subID','stimType']).mean().unstack(level=1)\n",
    "mean_per_sub.columns =  ['_'.join(col) for col in mean_per_sub.columns.values] #mean_per_sub.columns.droplevel()\n",
    "mean_per_sub"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.regplot(x = 'ASR_Intn_T_Mental',     y = 'coefs_Mental', data = mean_per_sub, color = 'k', label = '\"Mental\"', ax=ax, marker = '.')\n",
    "sns.regplot(x = 'ASR_Intn_T_Random',     y = 'coefs_Random', data = mean_per_sub, color = [.6,.6,.6], label = '\"Random\"', ax=ax, marker = '.')\n",
    "\n",
    "rs1, ps1 = stats.spearmanr(mean_per_sub['ASR_Intn_T_Mental'], mean_per_sub['coefs_Mental'], nan_policy='omit')\n",
    "rs2, ps2 = stats.spearmanr(mean_per_sub['ASR_Intn_T_Random'], mean_per_sub['coefs_Random'], nan_policy='omit')\n",
    "print(f'\"Mental\":{rs1:.4f},(p={ps1:.4f})')\n",
    "print(f'\"Random\":{rs2:.4f},(p={ps2:.4f})')\n",
    "#plt.annotate(r\"$ r_{S}= -.03$\"f' (p='r\"$.63)$\", xy=(.3,.1), xycoords='axes fraction',fontsize=20, color = 'k') # 0.1, .003\n",
    "#plt.annotate(r\"$ r_{S}=  .19$\"f' (p='r\"$.017)$\", xy=(.3,.01), xycoords='axes fraction',fontsize=20, color = [.7,.7,.7]) # 0.1, .003\n",
    "plt.xlabel('Internalizing Score (T)')\n",
    "plt.ylabel('Mean beta Estimate')\n",
    "plt.legend(bbox_to_anchor = [1.01,1])\n",
    "plt.ylim(-3,3)\n",
    "plt.xlim(29,100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EDIT FOR UNSURE RESPONSE TRIALS\n",
    "# surface plots\n",
    "vmin,vmax = -.4,.4\n",
    "cmap =  'RdBu_r' #'RdBu_r', 'PiYG'\n",
    "txt = 'responseBeta\\n(Traitsmodel)'\n",
    "#txt = r' $\\overline{\\beta}(\\\"\"\")-$' + '\\n' + r'$\\overline{\\beta}_{Non-social}$'+ '\\n'\n",
    "#txt = '' #'AIC response-\\nbased LME - \\nstim-based LME' #'AIC S/NS LME - M/R LME'#r\"$\\overline{\\beta}{(diff)}$\"\n",
    " \n",
    "thresh = 1e-10\n",
    "\n",
    "nodes = np.zeros((268,))\n",
    "nodes[coef_p_model3_traits_fdr] = beta_resp_model3[coef_p_model3_traits_fdr]\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params,thresh = 1e-10)\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_surf_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img, threshold=thresh,\n",
    "colorbar= False)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_axial_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('min mag. diff:', min( np.abs(beta_resp_model3[coef_p_model3_traits_fdr] - beta_resp_model4[coef_p_model3_traits_fdr])))\n",
    "print('max mag. diff:', max( np.abs(beta_resp_model3[coef_p_model3_traits_fdr] - beta_resp_model4[coef_p_model3_traits_fdr])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "100*(beta_resp_model3[coef_p_model3_traits_fdr] - beta_resp_model4[coef_p_model3_traits_fdr])/(beta_resp_model4[coef_p_model3_traits_fdr])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "coef_pval_traitsig_nodes = np.array([[model4_res[n][0][1],model4_res[n][1][1]] for n in np.where(coef_p_model3_traits_fdr)[0]])\n",
    "coef_pval_traitsig_nodes, coef_pval_traitsig_nodes.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(np.where(coef_pval_traitsig_nodes[:,1]<.05)[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.scatter(coef_pval_traitsig_nodes[:,0],coef_pval_traitsig_nodes[:,1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots\n",
    "vmin,vmax = -.01,.01\n",
    "cmap =  'RdBu_r' #'RdBu_r', 'PiYG'\n",
    "txt = 'responseBeta\\n(Traits-NoTraits)'\n",
    "#txt = r' $\\overline{\\beta}(\\\"\"\")-$' + '\\n' + r'$\\overline{\\beta}_{Non-social}$'+ '\\n'\n",
    "#txt = '' #'AIC response-\\nbased LME - \\nstim-based LME' #'AIC S/NS LME - M/R LME'#r\"$\\overline{\\beta}{(diff)}$\"\n",
    "\n",
    "title_txt = 'beta diff (with traits vs. without in the sig nodes)'\n",
    " \n",
    "thresh = 1e-10\n",
    "\n",
    "nodes = np.zeros((268,))\n",
    "nodes[coef_p_model3_traits_fdr] = beta_resp_model3[coef_p_model3_traits_fdr] - beta_resp_model4[coef_p_model3_traits_fdr]\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params,thresh = 1e-10)\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_surf_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img, threshold=thresh,\n",
    "colorbar= False)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_axial_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- blue: magnitude of response increases in model 3 !\n",
    "e.g."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "beta_resp_model3[coef_p_model3_intn_fdr][0], beta_resp_model4[coef_p_model3_intn_fdr][0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "min(beta_resp_model3 - beta_resp_model4),max(beta_resp_model3 - beta_resp_model4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots\n",
    "vmin,vmax = -.01,.01\n",
    "cmap =  'RdBu_r' #'RdBu_r', 'PiYG'\n",
    "txt = 'responseBeta\\n(Traits-NoTraits)'\n",
    "#txt = r' $\\overline{\\beta}(\\\"\"\")-$' + '\\n' + r'$\\overline{\\beta}_{Non-social}$'+ '\\n'\n",
    "#txt = '' #'AIC response-\\nbased LME - \\nstim-based LME' #'AIC S/NS LME - M/R LME'#r\"$\\overline{\\beta}{(diff)}$\"\n",
    "\n",
    "title_txt = 'beta diff (with traits vs. without in the sig nodes)'\n",
    " \n",
    "thresh = 1e-10\n",
    "\n",
    "nodes = np.zeros((268,))\n",
    "nodes = beta_resp_model3 - beta_resp_model4\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params,thresh = 1e-10)\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_surf_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img, threshold=thresh,\n",
    "colorbar= False)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_axial_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# (2) response * trait interaction - model 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# coef interaction term\n",
    "print(model2_txt)\n",
    "coef_p_model2 = [[model2_res[n][0][3], model2_res[n][1][3]] for n in range(268)] # ASR_response_interaction_term\n",
    "coef_p_model2= np.array(coef_p_model2)\n",
    "print(coef_p_model2[:5,:])\n",
    "print('sig terms:', )\n",
    "\n",
    "coef_p_model2_fdr = lsu(coef_p_model2[:,1],q=.05)#fdr_correction(pval_slope_rand,.05)\n",
    "np.where(coef_p_model2_fdr)[0]\n",
    "# min(coef_p_model2[coef_p_model2[:,1]<.05,0]), max(coef_p_model2[coef_p_model2[:,1]<.05,0])\n",
    "\n",
    "# surface plots\n",
    "vmin,vmax = -.0055,.0055\n",
    "cmap =  'RdBu_r' #'RdBu_r', 'PiYG'\n",
    "txt = r' $\\beta_{InteractionTerm}$'\n",
    "#txt = r' $\\overline{\\beta}(\\\"\"\")-$' + '\\n' + r'$\\overline{\\beta}_{Non-social}$'+ '\\n'\n",
    "#txt = '' #'AIC response-\\nbased LME - \\nstim-based LME' #'AIC S/NS LME - M/R LME'#r\"$\\overline{\\beta}{(diff)}$\"\n",
    "\n",
    "title_txt = 'Interaction term beta (p<.05)'\n",
    " \n",
    "thresh = 1e-10\n",
    "\n",
    "nodes = np.zeros((268,))\n",
    "nodes[coef_p_model2[:,1]<.05] = coef_p_model2[coef_p_model2[:,1]<.05,0]\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params,thresh = 1e-10)\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_surf_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img, \n",
    "colorbar= False)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_axial_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# (3) Linear reg - effect of adding traits term"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('model5_txt:',model5_txt, '\\nmodel6_txt:',model6_txt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "AIC_LM_diff_addingAIC = np.array([model6_res[n][2] - model5_res[n][2] for n in range(268)])\n",
    "plt.hist(AIC_LM_diff_addingAIC)\n",
    "AIC_LM_diff_addingAIC.mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('model5_txt:',model5_txt, '\\nmodel6_txt:',model6_txt)\n",
    "AIC_LM_diff_addingAIC_RAND = np.array([model6_res_rand[n][2] - model5_res_rand[n][2] for n in range(268)])\n",
    "plt.hist(AIC_LM_diff_addingAIC_RAND)\n",
    "AIC_LM_diff_addingAIC_RAND.mean()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nodes_that_improve =  np.where((AIC_LM_diff_addingAIC<-2))[0]\n",
    "len(nodes_that_improve)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nodes_that_improve_rand =  np.where((AIC_LM_diff_addingAIC_RAND<-2))[0]\n",
    "len(nodes_that_improve_rand)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "min(AIC_LM_diff_addingAIC), max(AIC_LM_diff_addingAIC)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model5_txt,model6_txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# all movies\n",
    "\n",
    "n = 49 # the MT-like node\n",
    "df = pd.DataFrame(columns = ['Subject','coefs','subID','movie'])\n",
    "for m in range(10):\n",
    "    df_temp = pd.DataFrame({'Subject':sub_id_all[subs_10resp], 'coefs': all_coefs[subs_10resp,n,m], 'response':responses[subs_10resp,m],\\\n",
    "        'subID':subs_10resp,\\\n",
    "            'movie':np.repeat(m,len(subs_10resp))})\n",
    "    df = df.append(df_temp,ignore_index=True)\n",
    "    df = df.loc[df['response'] != 9] # yes v no\n",
    "\n",
    "df.set_index(\"Subject\", inplace=True)\n",
    "df_both = df.join(res_behav_data.loc[:,['ASR_Intn_T']], how='inner') # join betas and trait info\n",
    "inds = ~np.isnan(df_both['coefs']) & ~np.isnan(df_both['ASR_Intn_T']) # find rows where neither x or y is NaN\n",
    "df_both = df_both.loc[inds,:]\n",
    "\n",
    "nresps_per_sub = df_both.groupby(['subID','response']).count().unstack(level=1).iloc[:,:2]\n",
    "nresps_per_sub.columns = nresps_per_sub.columns.droplevel()\n",
    "\n",
    "biased_sub_IDs1 = list(nresps_per_sub[nresps_per_sub[0].isna()].index)\n",
    "biased_sub_IDs1 # No \"Non-social response\"\n",
    "\n",
    "biased_sub_IDs2 = list(nresps_per_sub[nresps_per_sub[1].isna()].index)\n",
    "biased_sub_IDs2 #  No \"Social\" response\n",
    "\n",
    "biased_sub_IDs = biased_sub_IDs1 + biased_sub_IDs2\n",
    "\n",
    "subID = df_both['subID'].values\n",
    "rows_to_delete = np.zeros((subID.shape[0],))\n",
    "for i in biased_sub_IDs:\n",
    "    rows_to_delete[subID == i] = 1\n",
    "\n",
    "df_both['rows_to_delete'] = rows_to_delete\n",
    "df_both_nobiasedsubs = df_both.loc[df_both['rows_to_delete']==0,:]\n",
    "df_both_nobiasedsubs['response'] = df_both_nobiasedsubs['response'].map({0.0: \"Non-social\", 1.0:  \"Social\"})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rand_movie_ind"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mean_per_sub = df_both_nobiasedsubs.groupby(['subID','response']).mean().unstack(level=1)\n",
    "mean_per_sub"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mean_per_sub.columns =  ['_'.join(col) for col in mean_per_sub.columns.values] #mean_per_sub.columns.droplevel()\n",
    "mean_per_sub"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import seaborn as sns\n",
    "\n",
    "#red_rgb = [103,0,31] # edges of RdBu\n",
    "#blue_rgb = [5,48,97] # edges of RdBu\n",
    "red_rgb =[188,61,62] # from Emily\n",
    "blue_rgb = [54,122,177] # from Emily\n",
    "red_rgb = np.array(red_rgb)/255\n",
    "blue_rgb = np.array(blue_rgb)/255\n",
    "alpha = .2 # transparency inside boxplots, for datapts etc."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def explore_correlation(x, y, data):\n",
    "    \"\"\"\n",
    "    Calculates and plots correlation between x and y variables in dataframe `data`, plus distribution of x and y \n",
    "    \"\"\"\n",
    "    sns.set_style(\"white\")\n",
    "    \n",
    "    inds = ~np.isnan(data[x]) & ~np.isnan(data[y]) # find rows where neither x or y is NaN\n",
    "\n",
    "    g = sns.jointplot(x=x, y=y, data=data, kind='reg', color='gray')\n",
    "\n",
    "    # Calculate and print correlations\n",
    "    rp, pp = stats.pearsonr(data[x][inds], data[y][inds])\n",
    "    rs, ps = stats.spearmanr(data[x][inds], data[y][inds])\n",
    "    #g.ax_joint.annotate(f'r_s = {rs:.2f}\\n(p={ps:.1e})', xy=(.05,.8), xycoords='axes fraction')\n",
    "    print(f'Spearman r={rs}, p = {ps}')\n",
    "    \n",
    "    return g"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mean_per_sub['abs_coefs_Non-social'] = np.abs(mean_per_sub['coefs_Non-social'])\n",
    "mean_per_sub['abs_coefs_Social'] = np.abs(mean_per_sub['coefs_Social'])\n",
    "mean_per_sub"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "explore_correlation(x = 'ASR_Intn_T_Non-social', y = 'abs_coefs_Non-social', data = mean_per_sub)\n",
    "explore_correlation(x = 'ASR_Intn_T_Social', y = 'abs_coefs_Social', data = mean_per_sub)\n",
    "\n",
    "#explore_correlation(x = 'ASR_Intn_T_Non-social', y = 'coefs_Non-social', data = mean_per_sub)\n",
    "#explore_correlation(x = 'ASR_Intn_T_Social', y = 'coefs_Social', data = mean_per_sub)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def independent_corr(xy, ab, n, n2 = None, twotailed=True, conf_level=0.95, method='fisher'):\n",
    "    \"\"\"\n",
    "    Calculates the statistic significance between two independent correlation coefficients\n",
    "    @param xy: correlation coefficient between x and y\n",
    "    @param xz: correlation coefficient between a and b\n",
    "    @param n: number of elements in xy\n",
    "    @param n2: number of elements in ab (if distinct from n)\n",
    "    @param twotailed: whether to calculate a one or two tailed test, only works for 'fisher' method\n",
    "    @param conf_level: confidence level, only works for 'zou' method\n",
    "    @param method: defines the method uses, 'fisher' or 'zou'\n",
    "    @return: z and p-val\n",
    "    \"\"\"\n",
    "\n",
    "    if method == 'fisher':\n",
    "        xy_z = 0.5 * np.log((1 + xy)/(1 - xy))\n",
    "        ab_z = 0.5 * np.log((1 + ab)/(1 - ab))\n",
    "        if n2 is None:\n",
    "            n2 = n\n",
    "\n",
    "        se_diff_r = np.sqrt(1/(n - 3) + 1/(n2 - 3))\n",
    "        diff = xy_z - ab_z\n",
    "        z = abs(diff / se_diff_r)\n",
    "        p = (1 - norm.cdf(z))\n",
    "        if twotailed:\n",
    "            p *= 2\n",
    "\n",
    "        return z, p\n",
    "    elif method == 'zou':\n",
    "        L1 = rz_ci(xy, n, conf_level=conf_level)[0]\n",
    "        U1 = rz_ci(xy, n, conf_level=conf_level)[1]\n",
    "        L2 = rz_ci(ab, n2, conf_level=conf_level)[0]\n",
    "        U2 = rz_ci(ab, n2, conf_level=conf_level)[1]\n",
    "        lower = xy - ab - pow((pow((xy - L1), 2) + pow((U2 - ab), 2)), 0.5)\n",
    "        upper = xy - ab + pow((pow((U1 - xy), 2) + pow((ab - L2), 2)), 0.5)\n",
    "        return lower, upper\n",
    "    else:\n",
    "        raise Exception('Wrong method!')\n",
    "\n",
    "#print(dependent_corr(.40, .50, .10, 103, method='steiger'))\n",
    "#print(independent_corr(0.5 , 0.6, 103, 103, method='fisher'))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The following function was taken from here: https://github.com/psinger/CorrelationStats/blob/master/corrstats.py\n",
    "\n",
    "from scipy.stats import t, norm\n",
    "from math import atanh, pow\n",
    "from numpy import tanh\n",
    "\n",
    "def rz_ci(r, n, conf_level = 0.95):\n",
    "    zr_se = pow(1/(n - 3), .5)\n",
    "    moe = norm.ppf(1 - (1 - conf_level)/float(2)) * zr_se\n",
    "    zu = atanh(r) + moe\n",
    "    zl = atanh(r) - moe\n",
    "    return tanh((zl, zu))\n",
    "\n",
    "def rho_rxy_rxz(rxy, rxz, ryz):\n",
    "    num = (ryz-1/2.*rxy*rxz)*(1-pow(rxy,2)-pow(rxz,2)-pow(ryz,2))+pow(ryz,3)\n",
    "    den = (1 - pow(rxy,2)) * (1 - pow(rxz,2))\n",
    "    return num/float(den)\n",
    "\n",
    "def dependent_corr(xy, xz, yz, n, twotailed=True, conf_level=0.95, method='steiger'):\n",
    "    \"\"\"\n",
    "    Calculates the statistic significance between two dependent correlation coefficients\n",
    "    @param xy: correlation coefficient between x and y\n",
    "    @param xz: correlation coefficient between x and z\n",
    "    @param yz: correlation coefficient between y and z\n",
    "    @param n: number of elements in x, y and z\n",
    "    @param twotailed: whether to calculate a one or two tailed test, only works for 'steiger' method\n",
    "    @param conf_level: confidence level, only works for 'zou' method\n",
    "    @param method: defines the method uses, 'steiger' or 'zou'\n",
    "    @return: t and p-val\n",
    "    \"\"\"\n",
    "    if method == 'steiger':\n",
    "        d = xy - xz\n",
    "        determin = 1 - xy * xy - xz * xz - yz * yz + 2 * xy * xz * yz\n",
    "        av = (xy + xz)/2\n",
    "        cube = (1 - yz) * (1 - yz) * (1 - yz)\n",
    "\n",
    "        t2 = d * np.sqrt((n - 1) * (1 + yz)/(((2 * (n - 1)/(n - 3)) * determin + av * av * cube)))\n",
    "        p = 1 - t.cdf(abs(t2), n - 3)\n",
    "\n",
    "        if twotailed:\n",
    "            p *= 2\n",
    "\n",
    "        return t2, p\n",
    "    elif method == 'zou':\n",
    "        L1 = rz_ci(xy, n, conf_level=conf_level)[0]\n",
    "        U1 = rz_ci(xy, n, conf_level=conf_level)[1]\n",
    "        L2 = rz_ci(xz, n, conf_level=conf_level)[0]\n",
    "        U2 = rz_ci(xz, n, conf_level=conf_level)[1]\n",
    "        rho_r12_r13 = rho_rxy_rxz(xy, xz, yz)\n",
    "        lower = xy - xz - pow((pow((xy - L1), 2) + pow((U2 - xz), 2) - 2 * rho_r12_r13 * (xy - L1) * (U2 - xz)), 0.5)\n",
    "        upper = xy - xz + pow((pow((U1 - xy), 2) + pow((xz - L2), 2) - 2 * rho_r12_r13 * (U1 - xy) * (xz - L2)), 0.5)\n",
    "        return lower, upper\n",
    "    else:\n",
    "        raise Exception('Wrong method!')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "r,p = stats.spearmanr(mean_per_sub['ASR_Intn_T_Social'], mean_per_sub['coefs_Social'])\n",
    "print('Social:',r,p)\n",
    "r,p = stats.spearmanr(mean_per_sub['ASR_Intn_T_Non-social'], mean_per_sub['coefs_Non-social'])\n",
    "print('Non-social:',r,p)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "xy = stats.spearmanr(mean_per_sub['ASR_Intn_T_Social'], mean_per_sub['coefs_Social'])[0]\n",
    "xz = stats.spearmanr(mean_per_sub['ASR_Intn_T_Social'], mean_per_sub['coefs_Non-social'])[0]\n",
    "yz = stats.spearmanr(mean_per_sub['coefs_Social'], mean_per_sub['coefs_Non-social'])[0]\n",
    "\n",
    "inds = ~np.isnan(mean_per_sub['ASR_Intn_T_Social']) & ~np.isnan(mean_per_sub['coefs_Social']) & ~np.isnan(mean_per_sub['coefs_Non-social'])\n",
    "print(inds.sum())\n",
    "\n",
    "dependent_corr(xy, xz, yz, n, twotailed=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.regplot(x = 'ASR_Intn_T_Social',     y = 'coefs_Social', data = mean_per_sub, color = red_rgb, label = '\"Social\"', ax=ax, marker = '.')\n",
    "sns.regplot(x = 'ASR_Intn_T_Non-social', y = 'coefs_Non-social', data = mean_per_sub, color = blue_rgb, label = '\"Non-social\"', ax=ax, marker = '.')\n",
    "plt.annotate(r\"$ r_{S}=-.07$\"f' (p='r\"$.051)$\", xy=(.3,.1), xycoords='axes fraction',fontsize=20, color = red_rgb) # 0.1, .003\n",
    "plt.annotate(r\"$ r_{S}=-.09$\"f' (p='r\"$.009)$\", xy=(.3,.01), xycoords='axes fraction',fontsize=20, color = blue_rgb) # 0.1, .003\n",
    "plt.xlabel('Internalizing Score (T)')\n",
    "plt.ylabel('Mean LME Estimate')\n",
    "plt.legend(bbox_to_anchor = [1.01,1])\n",
    "plt.ylim(-3,3)\n",
    "plt.xlim(29,100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ONLY RAND"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "min(AIC_LM_diff_addingAIC_RAND),max(AIC_LM_diff_addingAIC_RAND)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots\n",
    "vmin,vmax = -9,9\n",
    "cmap = 'PiYG' #'RdBu_r'\n",
    "txt = 'AIC diff on\\nadding traits term- RAND'\n",
    "#txt = r' $\\overline{\\beta}(\\\"\"\")-$' + '\\n' + r'$\\overline{\\beta}_{Non-social}$'+ '\\n'\n",
    "title_txt = ''\n",
    " \n",
    "nodes = np.zeros((268,))\n",
    "nodes = AIC_LM_diff_addingAIC_RAND\n",
    "thresh = 2\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params, thresh)\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_surf_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "    \n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img,colorbar= False,threshold = thresh)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_axial_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model5_txt, model6_txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "coefs_rand_resp = np.array([model5_res_rand[n][0][1] for n in range(268)])\n",
    "pval_rand_resp = np.array([model5_res_rand[n][1][1] for n in range(268)])\n",
    "\n",
    "min(coefs_rand_resp[pval_rand_resp<.05]), max(coefs_rand_resp[pval_rand_resp<.05])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots\n",
    "vmin,vmax = -.3, .3\n",
    "cmap = 'RdBu_r' # 'PiYG'\n",
    "txt = 'estimate_response in the LM:\\ncoefs ~ response (RAND)'\n",
    "#txt = r' $\\overline{\\beta}(\\\"\"\")-$' + '\\n' + r'$\\overline{\\beta}_{Non-social}$'+ '\\n'\n",
    "title_txt = ''\n",
    " \n",
    "nodes = np.zeros((268,))\n",
    "nodes[pval_rand_resp<.05] = coefs_rand_resp[pval_rand_resp<.05]\n",
    "thresh = 1e-6\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params, thresh)\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_surf_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "    \n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img,colorbar= False,threshold = thresh)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_axial_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "coefs_rand_resp = np.array([model6_res_rand[n][0][1] for n in range(268)])\n",
    "pval_rand_resp = np.array([model6_res_rand[n][1][1] for n in range(268)])\n",
    "pval_rand_resp_fdr = lsu(pval_rand_resp,q=.05)\n",
    "print(len(np.where(pval_rand_resp<.05)[0]), len(np.where(pval_rand_resp_fdr)[0]))\n",
    "\n",
    "min(coefs_rand_resp[pval_rand_resp<.05]), max(coefs_rand_resp[pval_rand_resp<.05])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots\n",
    "vmin,vmax = -.3, .3\n",
    "cmap = 'RdBu_r' # 'PiYG'\n",
    "txt = 'estimate_response in the LM:\\ncoefs ~ response + ASR (RAND)'\n",
    "#txt = r' $\\overline{\\beta}(\\\"\"\")-$' + '\\n' + r'$\\overline{\\beta}_{Non-social}$'+ '\\n'\n",
    "title_txt = ''\n",
    " \n",
    "nodes = np.zeros((268,))\n",
    "nodes[pval_rand_resp<.05] = coefs_rand_resp[pval_rand_resp<.05]\n",
    "thresh = 1e-6\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params, thresh)\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_surf_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "    \n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img,colorbar= False,threshold = thresh)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_axial_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model7_res_rand[0][0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "coefs_rand_interaction = np.array([model7_res_rand[n][0][3] for n in range(268)])\n",
    "pval_rand_interaction = np.array([model7_res_rand[n][1][3] for n in range(268)])\n",
    "pval_rand_interaction_fdr = lsu(pval_rand_interaction,q=.05)\n",
    "\n",
    "print(len(np.where(pval_rand_interaction<.05)[0]), len(np.where(pval_rand_interaction_fdr)[0]))\n",
    "\n",
    "min(coefs_rand_interaction[pval_rand_interaction<.05]), max(coefs_rand_interaction[pval_rand_interaction<.05])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.where(lsu(pval_rand_interaction[nodes_coaxbill_rand_all],q=.05))[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots\n",
    "vmin,vmax = -.03, .03\n",
    "cmap = 'RdBu_r' # 'PiYG'\n",
    "txt = 'estimate_response in the LM:\\ncoefs ~ response * ASR (RAND)'\n",
    "#txt = r' $\\overline{\\beta}(\\\"\"\")-$' + '\\n' + r'$\\overline{\\beta}_{Non-social}$'+ '\\n'\n",
    "title_txt = ''\n",
    " \n",
    "nodes = np.zeros((268,))\n",
    "nodes[pval_rand_interaction<.05] = coefs_rand_interaction[pval_rand_interaction<.05]\n",
    "thresh = 1e-6\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params, thresh)\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_surf_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "    \n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img,colorbar= False,threshold = thresh)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_axial_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots\n",
    "'''vmin,vmax = -.3, .3\n",
    "cmap = 'RdBu_r' # 'PiYG'\n",
    "txt = 'estimate_response in the LM:\\ncoefs ~ response + ASR (RAND)'\n",
    "#txt = r' $\\overline{\\beta}(\\\"\"\")-$' + '\\n' + r'$\\overline{\\beta}_{Non-social}$'+ '\\n'\n",
    "title_txt = ''\n",
    " \n",
    "nodes = np.zeros((268,))\n",
    "nodes[pval_rand_resp<.05] = coefs_rand_resp[pval_rand_resp<.05]\n",
    "thresh = 1e-6\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params, thresh)\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_surf_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "    \n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img,colorbar= False,threshold = thresh)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_axial_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'''coefs_rand_resp5 = np.array([model5_res_rand[n][0][1] for n in range(268)])\n",
    "pval_rand_resp5 = np.array([model5_res_rand[n][1][1] for n in range(268)])\n",
    "pval_rand_resp5_fdr = lsu(pval_rand_resp5,q=.05)\n",
    "pval_rand_resp5_fdr_glm = lsu(pval_rand_resp5[nodes_coaxbill_rand_all],q=.05)\n",
    "\n",
    "coefs_rand_resp6 = np.array([model6_res_rand[n][0][1] for n in range(268)])\n",
    "pval_rand_resp6 = np.array([model6_res_rand[n][1][1] for n in range(268)])\n",
    "pval_rand_resp6_fdr = lsu(pval_rand_resp6,q=.05)\n",
    "pval_rand_resp6_fdr_glm = lsu(pval_rand_resp6[nodes_coaxbill_rand_all],q=.05)\n",
    "\n",
    "plt.hist(coefs_rand_resp5[pval_rand_resp6<.05] - coefs_rand_resp6[pval_rand_resp6<.05]) # beta with ASR - without ASR'''\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "max(coefs_rand_interaction[pval_rand_interaction<.05])\n",
    "np.where(coefs_rand_interaction==max(coefs_rand_interaction))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.where(pval_rand_interaction == min(pval_rand_interaction))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lsu(pval_rand_interaction,.05)[89]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.where(np.where(nodes_coaxbill_rand_all)[0]==89)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# random mech\n",
    "n = 89 # 49 is the MT-like node\n",
    "df = pd.DataFrame(columns = ['Subject','coefs','subID'])\n",
    "\n",
    "df_temp = pd.DataFrame({'Subject':sub_id_all, 'coefs': all_coefs[:,n,rand_movie_ind], 'response':responses[:,rand_movie_ind],\\\n",
    "    'subID':np.arange(sub_id_all.shape[0]) })\n",
    "df = df.append(df_temp,ignore_index=True)\n",
    "#df = df.loc[(df['response'] != 9) & ~np.isnan(df['response']),:] # yes v no\n",
    "df = df.loc[~np.isnan(df['response']),:] # yes v no\n",
    "\n",
    "\n",
    "df.set_index(\"Subject\", inplace=True)\n",
    "df_both_RAND = df.join(res_behav_data.loc[:,['ASR_Intn_T']], how='inner') # join betas and trait info\n",
    "inds = ~np.isnan(df_both_RAND['coefs']) & ~np.isnan(df_both_RAND['ASR_Intn_T']) # find rows where neither x or y is NaN\n",
    "df_both_RAND = df_both_RAND.loc[inds,:]\n",
    "df_both_RAND['response'] = df_both_RAND['response'].map({0.0: \"Non-social\", 1.0:  \"Any_social\", 9.0:  \"Any_social\"})\n",
    "df_both_RAND.head(),df_both_RAND.shape\n",
    "\n",
    "df_both_RAND_soc = df_both_RAND.loc[df_both_RAND['response']==\"Any_social\",:]\n",
    "df_both_RAND_nonsoc = df_both_RAND.loc[df_both_RAND['response']==\"Non-social\",:]\n",
    "\n",
    "print('\"Any_social\"')\n",
    "explore_correlation(x = 'ASR_Intn_T', y = 'coefs', data = df_both_RAND_soc)\n",
    "print('\"Non-social\"')\n",
    "explore_correlation(x = 'ASR_Intn_T', y = 'coefs', data = df_both_RAND_nonsoc)\n",
    "\n",
    "x = 'ASR_Intn_T'\n",
    "y= 'coefs'\n",
    "#rp, pp = stats.pearsonr(df_both_RAND_soc[x],    df_both_RAND_soc[y])\n",
    "#rp, pp = stats.pearsonr(df_both_RAND_nonsoc[x], df_both_RAND_nonsoc[y])\n",
    "rs1, ps1 = stats.spearmanr(df_both_RAND_soc[x],    df_both_RAND_soc[y])\n",
    "rs2, ps2 = stats.spearmanr(df_both_RAND_nonsoc[x], df_both_RAND_nonsoc[y])\n",
    "\n",
    "print(rs1, rs2)\n",
    "\n",
    "z, p = independent_corr(rs1 , rs2, df_both_RAND_soc.shape[0], df_both_RAND_nonsoc.shape[0], method='fisher')\n",
    "print('z=',z, ',p=', p ) # not sig different"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.regplot(x = 'ASR_Intn_T',     y = 'coefs', data = df_both_RAND_soc, color = red_rgb, label = '\"Social\" or \"Unsure\"', ax=ax, marker = '.')\n",
    "sns.regplot(x = 'ASR_Intn_T', y = 'coefs', data = df_both_RAND_nonsoc, color = blue_rgb, label = '\"Non-social\"', ax=ax, marker = '.')\n",
    "rs1, ps1 = stats.spearmanr(df_both_RAND_soc[x],    df_both_RAND_soc[y])\n",
    "rs2, ps2 = stats.spearmanr(df_both_RAND_nonsoc[x], df_both_RAND_nonsoc[y])\n",
    "print(f'\"Social\":{rs1:.4f},(p={ps1:.4f})')\n",
    "print(f'\"Non-social\":{rs2:.4f},(p={ps2:.4f})')\n",
    "plt.annotate(r\"$ r_{S}=  .12$\"f' (p='r\"$.03)$\", xy=(.3,.1), xycoords='axes fraction',fontsize=20, color = red_rgb) # 0.1, .003\n",
    "plt.annotate(r\"$ r_{S}= -.06$\"f' (p='r\"$.13)$\", xy=(.3,.01), xycoords='axes fraction',fontsize=20, color = blue_rgb) # 0.1, .003\n",
    "plt.xlabel('Internalizing Score (T)')\n",
    "plt.ylabel('LME Estimate')\n",
    "plt.legend(bbox_to_anchor = [1.01,1])\n",
    "plt.ylim(-3,3)\n",
    "plt.xlim(29,100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ALL MOVIES"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots\n",
    "vmin,vmax = -33,33\n",
    "cmap = 'PiYG' #'RdBu_r'\n",
    "txt = 'AIC diff on\\nadding traits term'\n",
    "#txt = r' $\\overline{\\beta}(\\\"\"\")-$' + '\\n' + r'$\\overline{\\beta}_{Non-social}$'+ '\\n'\n",
    "title_txt = ''\n",
    " \n",
    "nodes = np.zeros((268,))\n",
    "nodes = AIC_LM_diff_addingAIC\n",
    "thresh = 2\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params, thresh)\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_surf_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "    \n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img,colorbar= False,threshold = thresh)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_axial_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Looking at nodes which show trait dependence"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model8_txt, model8.formula"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "coefs_traits =  np.array([[model8_res[n][0][1],model8_res[n][1][1]] for n in range(268)])\n",
    "coefs_traits[:5,:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "coefs_traits_fdr = lsu(coefs_traits[:,1],q=.05)#fdr_correction(pval_slope_rand,.05)\n",
    "np.where(coefs_traits_fdr)[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(np.where(coefs_traits[:,1] < .05)[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "min(coefs_traits[:,0]), max(coefs_traits[:,0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots\n",
    "vmin,vmax = -.005,.005\n",
    "cmap = 'RdBu_r' #'RdBu_r', 'PiYG'\n",
    "#txt = r' $\\overline{\\beta}_{traits}Unc$'\n",
    "txt = r' $\\overline{\\beta}_{traits}FDR$'\n",
    "title_txt = ''\n",
    " \n",
    "nodes = np.zeros((268,))\n",
    "#nodes[coefs_traits[:,1]<.05] = coefs_traits[coefs_traits[:,1]<.05,0]\n",
    "nodes[coefs_traits_fdr] = coefs_traits[coefs_traits_fdr,0]\n",
    "thresh = 1e-10\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params, thresh)\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_surf_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "    \n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img,colorbar= False,threshold = thresh)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_axial_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model8.formula"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# extra code"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'''nresps_per_sub = df_both.groupby(['subID','response']).count().unstack(level=1).iloc[:,:2]\n",
    "nresps_per_sub.columns = nresps_per_sub.columns.droplevel()\n",
    "\n",
    "biased_sub_IDs1 = list(nresps_per_sub[nresps_per_sub[\"Non-social\"].isna()].index)\n",
    "biased_sub_IDs1 # No \"Non-social response\"\n",
    "\n",
    "biased_sub_IDs2 = list(nresps_per_sub[nresps_per_sub[\"Social\"].isna()].index)\n",
    "biased_sub_IDs2 #  No \"Social\" response\n",
    "\n",
    "biased_sub_IDs = biased_sub_IDs1 + biased_sub_IDs2\n",
    "\n",
    "subID = df_both['subID'].values\n",
    "rows_to_delete = np.zeros((subID.shape[0]))\n",
    "for i in biased_sub_IDs:\n",
    "    rows_to_delete[subID == i] = 1\n",
    "\n",
    "df_both['rows_to_delete'] = rows_to_delete\n",
    "df_both_nobiasedsubs = df_both.loc[df_both['rows_to_delete']==0,:]\n",
    "print(df_both_nobiasedsubs.shape, df_both.shape)\n",
    "\n",
    "model1 = Lmer('coefs ~  response +(1|subID) + (1|movie)', data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "model1.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "\n",
    "model2 = Lmer('coefs ~  response + ASR_Intn_T + (1|subID) + (1|movie)', data=df_both) # ff: mean response, rf:subjID\n",
    "model2.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "\n",
    "'''\n",
    "\n",
    "'''data = pd.DataFrame({})#columns = ['Subject','coef','response','movie'])\n",
    "n=0\n",
    "nresp = [len(np.where(~np.isnan(responses[i,:]))[0]) for i in range(responses.shape[0])]\n",
    "for m in range(10):\n",
    "    #fMRI_data = pd.DataFrame({'coefs': all_coefs[subs_10resp,n,m],'response':responses[subs_10resp,m], 'subID':sub_id_all[subs_10resp], 'movie':np.repeat(m,len(subs_10resp))})\n",
    "    fMRI_data = pd.DataFrame({'Subject':sub_id_all,'slopeReg_node': all_coefs_run[:,n,m], 'response': responses[:,m],\n",
    "    'nresp':nresp, 'movie': np.repeat(m,1049)})\n",
    "    #fMRI_data = fMRI_data.loc[fMRI_data['nresp']==10,:]\n",
    "    fMRI_data.set_index(\"Subject\", inplace=True)\n",
    "    data_temp = fMRI_data.join(behav_data.loc[:,['ASR_Intn_T','Age_in_Yrs','Gender']], how='inner') # join betas and trait info\n",
    "    data = data.append(data_temp)#,ignore_index=True)\n",
    "data.reset_index(inplace=True)\n",
    "\n",
    "inds = ~np.isnan(data['slopeReg_node']) # find rows with missing fMRI data\n",
    "data = data.loc[inds,:]\n",
    "data.shape'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'''coef_ALL_resp, coef_ALL_resp_traits, coef_ALL_resp_traits_nosubID , coef_ALL_resp_traits_nosubID_notraits= [np.empty((268,)) for _ in range(4)]\n",
    "coef_ALL_resp[:], coef_ALL_resp_traits[:],coef_ALL_resp_traits_nosubID[:],coef_ALL_resp_traits_nosubID_notraits[:] = [np.nan]*4\n",
    "\n",
    "pval_ALL_resp, pval_ALL_resp_traits,pval_ALL_resp_traits_nosubID,pval_ALL_resp_traits_nosubID_notraits = [np.empty((268,)) for _ in range(4)]\n",
    "pval_ALL_resp[:], pval_ALL_resp_traits[:], pval_ALL_resp_traits_nosubID[:],pval_ALL_resp_traits_nosubID_notraits[:]  = [np.nan]*4\n",
    "\n",
    "AIC_ALL_resp, AIC_ALL_resp_traits, AIC_ALL_resp_traits_nosubID, AIC_ALL_resp_traits_nosubID_notraits = [np.empty((268,)) for _ in range(4)]\n",
    "AIC_ALL_resp[:], AIC_ALL_resp_traits[:],  AIC_ALL_resp_traits_nosubID[:], AIC_ALL_resp_traits_nosubID_notraits[:] = [np.nan]*4'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# RESPTYPE VS RESPTYPE+TRAIT BASED\n",
    "load_all = 0 # 1: load saved coefs, 0: run the LME\n",
    "model1_res = []\n",
    "model2_res = []\n",
    "model3_res = []\n",
    "model4_res = []\n",
    "\n",
    "if load_all == 1:\n",
    "     df_all_coefs = pd.read_csv(os.path.join(data_file_loc,'coefs_run_norm','slope_reg','LME_S_NS_revision1','lmecoefs_all_S_NS_S_NSwithtraits.csv'))\n",
    "     #[coef_ALL_stim,pval_ALL_stim] = np.load(os.path.join(data_file_loc,'coefs_run_norm','slope_reg','LME_S_NS_revision1','lmecoefs_all_S_NS_stimType.npy'), allow_pickle=True)\n",
    "else:\n",
    "    start_time =  time.time()\n",
    "    for n in range(268):\n",
    "        if n%10 == 0:\n",
    "            print(f'node {n+1},time={(time.time()-start_time)/60:.2f} mins')\n",
    "        \n",
    "        df = pd.DataFrame(columns = ['Subject','coefs','subID','movie'])\n",
    "        for m in range(10):\n",
    "            df_temp = pd.DataFrame({'Subject':sub_id_all[subs_10resp], 'coefs': all_coefs[subs_10resp,n,m], 'response':responses[subs_10resp,m],\\\n",
    "                'subID':subs_10resp,\\\n",
    "                 'movie':np.repeat(m,len(subs_10resp))})\n",
    "            df = df.append(df_temp,ignore_index=True)\n",
    "            df = df.loc[df['response'] != 9] # yes v no\n",
    "        \n",
    "        df.set_index(\"Subject\", inplace=True)\n",
    "        df_both = df.join(res_behav_data.loc[:,['ASR_Intn_T']], how='inner') # join betas and trait info\n",
    "        inds = ~np.isnan(df_both['coefs']) & ~np.isnan(df_both['ASR_Intn_T']) # find rows where neither x or y is NaN\n",
    "        df_both = df_both.loc[inds,:]\n",
    "\n",
    "        nresps_per_sub = df_both.groupby(['subID','response']).count().unstack(level=1).iloc[:,:2]\n",
    "        nresps_per_sub.columns = nresps_per_sub.columns.droplevel()\n",
    "\n",
    "        biased_sub_IDs1 = list(nresps_per_sub[nresps_per_sub[0].isna()].index)\n",
    "        biased_sub_IDs1 # No \"Non-social response\"\n",
    "\n",
    "        biased_sub_IDs2 = list(nresps_per_sub[nresps_per_sub[1].isna()].index)\n",
    "        biased_sub_IDs2 #  No \"Social\" response\n",
    "\n",
    "        biased_sub_IDs = biased_sub_IDs1 + biased_sub_IDs2\n",
    "\n",
    "        subID = df_both['subID'].values\n",
    "        rows_to_delete = np.zeros((subID.shape[0],))\n",
    "        for i in biased_sub_IDs:\n",
    "            rows_to_delete[subID == i] = 1\n",
    "\n",
    "        df_both['rows_to_delete'] = rows_to_delete\n",
    "        df_both_nobiasedsubs = df_both.loc[df_both['rows_to_delete']==0,:]\n",
    "        #print(df_both_nobiasedsubs.shape, df_both.shape)\n",
    "\n",
    "        #data_both = df.join(res_behav_data.loc[:,['ASR_Intn_T','Age_in_Yrs','Gender']], how='inner') # join betas and trait info\n",
    "\n",
    "        #df_both['response'] = df_both['response'].map({1.0: \"Non-social\", 0.0:  \"Social\"})\n",
    "        df_both_nobiasedsubs['response'] = df_both_nobiasedsubs['response'].map({1.0: \"Non-social\", 0.0:  \"Social\"})\n",
    "        \n",
    "\n",
    "        model1 = Lmer('coefs ~  response +(1|subID) + (1|movie)', data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "        model1.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "        model1_res.append([model1.coefs['Estimate'],model1.coefs['P-val'],model1.AIC])\n",
    "\n",
    "        model2 = Lmer('coefs ~  response*ASR_Intn_T + (1|movie)', data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "        model2.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "        model2_res.append([model2.coefs['Estimate'],model2.coefs['P-val'],model2.AIC])\n",
    "\n",
    "        model3 = Lmer('coefs ~  response + ASR_Intn_T + (1|movie)', data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "        model3.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "        model3_res.append([model3.coefs['Estimate'],model3.coefs['P-val'],model3.AIC])\n",
    "\n",
    "        model4 = Lmer('coefs ~  response + (1|movie)', data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "        model4.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "        model4_res.append([model4.coefs['Estimate'],model4.coefs['P-val'],model4.AIC])\n",
    "\n",
    "        model5 = Lmer('coefs ~  response + ASR_Intn_T', data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "        model5.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "        model5_res.append([model4.coefs['Estimate'],model4.coefs['P-val'],model4.AIC])\n",
    "\n",
    "        model6 = Lmer('coefs ~  response + ASR_Intn_T', data=df_both_nobiasedsubs) # ff: mean response, rf:subjID\n",
    "        model5.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False)\n",
    "        model5_res.append([model4.coefs['Estimate'],model4.coefs['P-val'],model4.AIC])\n",
    "\n",
    "        #if n == 0:\n",
    "        #    print('model:',model1.fit(factors={\"response\":[\"Non-social\",\"Social\"]},summary = False, verbose = False))\n",
    "        #    print('model:',model2.fit(factors={\"response\":[\"Non-social\",\"Social\"]}))\n",
    "\n",
    "        '''coef_ALL_resp[n] = model1.coefs['Estimate'][1]\n",
    "        pval_ALL_resp[n]= model1.coefs['P-val'][1]\n",
    "        AIC_ALL_resp[n]= model1.AIC\n",
    "\n",
    "        coef_ALL_resp_traits[n] = model2.coefs['Estimate'][1]\n",
    "        pval_ALL_resp_traits[n]= model2.coefs['P-val'][1]\n",
    "        AIC_ALL_resp_traits[n] = model2.AIC\n",
    "\n",
    "        coef_ALL_resp_traits_nosubID[n] = model3.coefs['Estimate'][1]\n",
    "        pval_ALL_resp_traits_nosubID[n]= model3.coefs['P-val'][1]\n",
    "        AIC_ALL_resp_traits_nosubID[n] = model3.AIC\n",
    "        \n",
    "        coef_ALL_resp_traits_nosubID_notraits[n] = model4.coefs['Estimate'][1]\n",
    "        pval_ALL_resp_traits_nosubID_notraits[n]= model4.coefs['P-val'][1]\n",
    "        AIC_ALL_resp_traits_nosubID_notraits[n] = model4.AIC'''\n",
    "        \n",
    "    '''df_all_coefs = pd.DataFrame({'Node': np.arange(268), 'coef_ALL_resp': coef_ALL_resp, 'pval_ALL_resp': pval_ALL_resp, 'AIC_ALL_resp': AIC_ALL_resp,\\\n",
    "        'coef_ALL_resp_traits': coef_ALL_resp_traits,   'pval_ALL_resp_traits': pval_ALL_resp_traits, 'AIC_ALL_resp_traits': AIC_ALL_resp_traits, \\\n",
    "        'coef_ALL_resp_traits_nosubID': coef_ALL_resp_traits_nosubID, 'pval_ALL_resp_traits_nosubID': pval_ALL_resp_traits_nosubID, \n",
    "        'AIC_ALL_resp_traits_nosubID': AIC_ALL_resp_traits_nosubID,\n",
    "        'coef_ALL_resp_traits_nosubID_notraits': coef_ALL_resp_traits_nosubID_notraits, 'pval_ALL_resp_traits_nosubID_notraits': pval_ALL_resp_traits_nosubID_notraits, \n",
    "        'AIC_ALL_resp_traits_nosubID_notraits': AIC_ALL_resp_traits_nosubID_notraits})'''\n",
    "    #df_all_coefs.to_csv(os.path.join(data_file_loc,'coefs_run_norm','slope_reg','LME_S_NS_revision1','lmecoefs_all_S_NS_S_NSwithtraits.csv'))\n",
    "    \n",
    "    print('Done on/at:',datetime.now()) # cell run at)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('py37': conda)"
  },
  "interpreter": {
   "hash": "30fd9c97283ec1278eec212a8f8afab06ad903f38228c32cacb469eba8e56f4f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}