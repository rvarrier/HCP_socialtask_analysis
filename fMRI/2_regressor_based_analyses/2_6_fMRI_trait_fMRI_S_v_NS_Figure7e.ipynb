{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "- This script compares how well the neural responses to social content correlates with internalizing symptom scores, i.e., the trait-behavior-fMRI relationship\n",
    "- Renaming notebook for clarity (former name: 2_3_3_fMRI_SocNonsoc_v_SocNonsocwTraits_AIC_nooutput.ipynb)\n",
    "\n",
    "Rekha Varrier, July-August 2022"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import general packages, check folders\n",
    "#%reset\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import imagesc as imagesc #pip install imagesc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "working_dir = '/Users/f0053cz/Dropbox (Dartmouth College)/postdoc_Dartmouth/HCP/fMRIScipts/code'\n",
    "#working_dir = os.getcwd()\n",
    "print('current directory:\\n',working_dir)\n",
    "path = Path(working_dir)\n",
    "parent_folder = path.parent\n",
    "data_file_loc = os.path.join(parent_folder,'data') # to store data we extract later in this notebook"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting default fontsizes for plots\n",
    "\n",
    "s=20 # CHANGE FONTSIZE HERE\n",
    "plt.rc('font', size=s) #controls default text size\n",
    "plt.rc('axes', titlesize=s) #fontsize of the title\n",
    "plt.rc('axes', labelsize=s) #fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=s) #fontsize of the x tick labels\n",
    "plt.rc('ytick', labelsize=s) #fontsize of the y tick labels\n",
    "plt.rc('legend', fontsize=s) #fontsize of the legend"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#suff= ' '\n",
    "suff = '_corrected'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load behavioral data - coded 1 for \"social\", 0 for \"nonsocial\" and 9 for \"unsure\", nan for missed response\n",
    "# even if using the Mental/Random labels, need this to sub-select subs who have responded on all trials\n",
    "responses = np.load(os.path.join(data_file_loc,f'responses{suff}.npy'))\n",
    "responses.shape # subs *movies"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Number of complete subjects:',len(np.where(np.array([len(np.where(~np.isnan(responses[s,:]))[0]) for s in range(responses.shape[0])])==10)[0]))\n",
    "print('Total subjects:', responses.shape[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# timepts_indiv_movie = file with TRs within run to be selected for each movie (including a few fixation TRs at the start and end),\n",
    "# vid_start_rel_tr = the TR at which the movie begins within each timecourse snippet\n",
    "# details in 1_1_create_regressors.ipynb\n",
    "[timepts_indiv_movie,vid_start_rel_tr] = np.load(os.path.join(data_file_loc,'Video_TRs.npy'),allow_pickle=True)\n",
    "vid_start_rel_tr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run-level regressors vs. traits "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import run-level regression coefficients (saved in 2_2_MRI_LM_allmovies_generateregcoeffts.ipynb)\n",
    "flName = os.path.join(data_file_loc,f'coef_slopereg_all{suff}.npy')\n",
    "run_level_coefs = np.load(flName) # dimensions: subject *  brain parcels * runs\n",
    "\n",
    "run_level_coefs_mean = np.nanmean(run_level_coefs, axis=2) # 1 coefft per run, average across runs\n",
    "run_level_coefs_mean.shape "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# packages for linear regression and multiple comparison\n",
    "from pymer4.models import\n",
    "from multipy.fdr import lsu\n",
    "from datetime import datetime\n",
    "\n",
    "# social processing regions across the various GLM analyses - highlighted in the first S>NS GLM as black contours. Using it for contours here too\n",
    "nodes_coaxbill_rand_all = np.load(os.path.join(data_file_loc,'nodes_coaxbill_rand_all.npy')) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_file_loc = '/Users/f0053cz/Dropbox (Dartmouth College)/postdoc_Dartmouth/HCP/fMRIScipts/data'\n",
    "sub_id_all = np.load(os.path.join(data_file_loc,f'sub_ID_all{suff}.npy')) # subject IDs assigned by HCP for comparison with trait scores\n",
    "sub_id_all = [str(i) for i in sub_id_all]\n",
    "sub_id_all = np.array(sub_id_all)\n",
    "len(sub_id_all)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# names of all the animations in the presented order (they were never randomized)\n",
    "vidnames = [\"COAXING-B\", \"BILLIARD-A\", \"DRIFTING-A\", \"Fishing\", \"Random mechanical\",\"Scaring\", \"SEDUCING-B\", \"STAR-A\", \"SURPRISING-B\", \"TENNIS-A\"]\n",
    "\n",
    "# creating a 3D array of beta coeffs across movies from individual movie files\n",
    "all_coefs = np.zeros((responses.shape[0],268,10)) # subject * nodes * movies (i.e., stimuli)\n",
    "\n",
    "for m in range(10): # 10 movies\n",
    "    fileName =  os.path.join(data_file_loc,'coefs_run_norm','slope_reg',f'coef_slopereg_runnorm_{vidnames[m]}{suff}.npy')\n",
    "    all_coefs[:,:,m] = np.load(fileName)\n",
    "\n",
    "all_coefs[:10,0,:2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# best to remove subjects with < 10 responses (i.e., any missing responses) for power in general\n",
    "count_resp = np.zeros((responses.shape[0],))\n",
    "for i in range(responses.shape[0]):\n",
    "    count_resp[i] = len(np.where(~np.isnan(responses[i,:]))[0])\n",
    "subs_10resp = np.where(count_resp == 10)[0]\n",
    "len(subs_10resp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "res_behav_data = pd.read_csv('/Users/f0053cz/Documents/HCP_trait_diffs_DONOTSHARE/trait_analyses/data/RESTRICTED_esfinn_11_21_2021_19_19_35.csv')\n",
    "res_behav_data.set_index(\"Subject\", inplace=True)\n",
    "res_behav_data.index = res_behav_data.index.map(str)\n",
    "print(res_behav_data.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Effect of \"Social\" - \"Non-social\" beta and trait scores (without considering movies)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Fitting each run-level regression coefficient (which already summarizes S-NS) with the internalizing trait score (ASR_Intn_T) for each brain region across people"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "model9_txt = 'coefs_diff ~ ASR_Intn_T'\n",
    "nsubs_node = []\n",
    "\n",
    "# LM - run-level regs\n",
    "model9_res = []\n",
    "rval_pval_spearman_coef_diff_ASR_Intn_T = []\n",
    "start_time =  time.time()\n",
    "\n",
    "for n in range(268): # all brain regions/nodes/parcesl\n",
    "    if n%10 == 0: # print status\n",
    "        print(f'node {n+1},time={(time.time()-start_time)/60:.2f} mins')\n",
    "    \n",
    "    df = pd.DataFrame({'Subject':sub_id_all[subs_10resp], 'coefs_diff': run_level_coefs_mean[subs_10resp,n], 'subID':subs_10resp})\n",
    "    df.set_index(\"Subject\", inplace=True) # save fMRI run-level data as a dataframe\n",
    "\n",
    "    df_both = df.join(res_behav_data.loc[:,['ASR_Intn_T']], how='inner') # join the run-level regression coefft (i.e., beta S -NS)\n",
    "    #  and trait info\n",
    "    inds = ~np.isnan(df_both['coefs_diff']) & ~np.isnan(df_both['ASR_Intn_T']) # find rows where neither x or y is NaN\n",
    "    nsubs_node.append(len(np.where(inds)[0])) # store the non-NaN subs for each node in this list (sanity check for later if needed)\n",
    "    df_both = df_both.loc[inds,:] # df without NaNs\n",
    "    \n",
    "     # linear regressionm setting up and fititng model\n",
    "    model9 = Lm(model9_txt, data=df_both)\n",
    "    model9.fit(summary = False, verbose = False)\n",
    "    model9_res.append([model9.coefs['Estimate'],model9.coefs['P-val'],model9.AIC]) \n",
    "    # store results of the model - i.e., the Estimate for traits, its p-value and AIC, which is useful to compare against other models\n",
    "\n",
    "    # parallelly, also doing a correlation between the two. should give somewhat similar results as the above, but less precise.\n",
    "    rs,ps = stats.spearmanr(df_both['coefs_diff'],df_both['ASR_Intn_T']) \n",
    "    rval_pval_spearman_coef_diff_ASR_Intn_T.append([rs,ps])\n",
    "    if n == 0:\n",
    "        print('model:',model9.fit(summary = True, verbose = False))\n",
    "\n",
    "rval_pval_spearman_coef_diff_ASR_Intn_T = np.array(rval_pval_spearman_coef_diff_ASR_Intn_T)\n",
    "print('Done on/at:',datetime.now()) # cell run at)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# extract the estimate and p-value corresponding to the trait term\n",
    "# The coefficient for the trait term (ASR_Intn_T) is an interaction-like term, since it summarizes how much this trait covaries with a \n",
    "# difference term for brain activity between social and non-social\n",
    "print(model9_txt)\n",
    "coef_p_model9 = [[model9_res[n][0][1], model9_res[n][1][1]] for n in range(268)] # ASR reg coefft\n",
    "coef_p_model9= np.array(coef_p_model9)\n",
    "print(coef_p_model9[:5,:])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Traits term's dependence on ASR_Intn_T:\")\n",
    "print('nodes with p < .05 :', np.where(coef_p_model9[:,1]<.05)[0])\n",
    "\n",
    "coef_p_model9_fdr = lsu(coef_p_model9[:,1],q=.05)#fdr_correction(pval_slope_rand,.05)\n",
    "print('nodes with q<.05:', np.where(coef_p_model9_fdr)[0])\n",
    "\n",
    "min(coef_p_model9[:,0]),max(coef_p_model9[:,0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot results on the brain"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Some of the packages and funcitons have also been used in 2_3_1.. and 2_3_2..., so same idea here too\n",
    "    "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from nilearn.surface import vol_to_surf\n",
    "from nilearn.plotting import plot_glass_brain, plot_surf_roi,plot_stat_map,plot_img,plot_surf_contours\n",
    "import nibabel as nib\n",
    "from nilearn import datasets\n",
    "bg_img = datasets.load_mni152_template()\n",
    "fig_save_loc = os.path.join('/Users/f0053cz/Dropbox (Dartmouth College)/postdoc_Dartmouth/HCP/paper_prep/figures/fig2_2_traits/fmri_results/ALL')\n",
    "\n",
    "from nilearn.datasets import fetch_surf_fsaverage\n",
    "fsaverage = fetch_surf_fsaverage()\n",
    "\n",
    "from nilearn import datasets\n",
    "bg_img = datasets.load_mni152_template()\n",
    "\n",
    "from nltools.data import Brain_Data\n",
    "from nltools.mask import expand_mask, roi_to_brain\n",
    "\n",
    "\n",
    "mask = Brain_Data('https://neurovault.org/media/images/8423/shen_2mm_268_parcellation.nii.gz')\n",
    "mask_x = expand_mask(mask)\n",
    "\n",
    "def color_rois(values):\n",
    "    \"\"\"\n",
    "    This function assumes you are passing a vector \"values\" with the same length as the number of nodes in the atlas.\n",
    "    \"\"\"\n",
    "\n",
    "    shen268 = nib.load(os.path.join(data_file_loc,\"shen_2mm_268_parcellation.nii.gz\"))\n",
    "    shen268_data = shen268.get_fdata()\n",
    "    img = np.zeros(shen268_data.shape)\n",
    "    #print(shen268_data.shape)\n",
    "    for roi in range(len(values)):\n",
    "        itemindex = np.where(shen268_data==roi+1) # find voxels in this node (add 1 to account for zero-indexing)\n",
    "        #print(len(itemindex[0]))\n",
    "        img[itemindex] = values[roi] # color them by the desired value \n",
    "    affine = shen268.affine\n",
    "    img_nii = nib.Nifti1Image(img, affine)\n",
    "    return img_nii\n",
    "\n",
    "def surf_plot1(fig,ax,nodes,params, thresh):\n",
    "    title_txt = params['title']\n",
    "    txt  = params['txt']\n",
    "    vmin = params['vmin']\n",
    "    vmax = params['vmax']\n",
    "\n",
    "    # LH (left hemisphere)\n",
    "    ax_surf = ax[0,0] # lateral\n",
    "    texture = vol_to_surf(color_rois(nodes), fsaverage.pial_left,interpolation='nearest',radius =1, n_samples=1)\n",
    "    surf_plot1=plot_surf_roi(fsaverage.infl_left, texture, hemi='left',cmap = cmap, colorbar=False, symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                                bg_map=fsaverage.sulc_left,axes = ax_surf, threshold =  thresh)#)#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "    texture_contour = vol_to_surf(color_rois(nodes_coaxbill_rand_all), fsaverage.pial_left,interpolation='nearest',radius =1, n_samples=1)\n",
    "    plot_surf_contours(fsaverage.infl_left, texture_contour, axes = ax_surf,figure=surf_plot1, legend=True,levels = [1], colors=['k'])\n",
    "\n",
    "    ax_surf = ax[1,0] # medial\n",
    "    surf_plot2=plot_surf_roi(fsaverage.infl_left, texture, hemi='left',cmap = cmap, colorbar=False, symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                                bg_map=fsaverage.sulc_left, view = 'medial',axes = ax_surf, threshold =  thresh)#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "    plot_surf_contours(fsaverage.infl_left, texture_contour, axes = ax_surf,figure=surf_plot2, legend=True,levels = [1], colors=['k'])\n",
    "\n",
    "    # RH (right hemisphere)\n",
    "    ax_surf = ax[0,1] # lateral\n",
    "    texture = vol_to_surf(color_rois(nodes), fsaverage.pial_right,interpolation='nearest',radius =1, n_samples=1)\n",
    "    surf_plot3=plot_surf_roi(fsaverage.infl_right, texture, hemi='right',cmap = cmap, colorbar=True,symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                                bg_map=fsaverage.sulc_right,axes = ax_surf, threshold =  thresh)#)#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "    texture_contour = vol_to_surf(color_rois(nodes_coaxbill_rand_all), fsaverage.pial_right,interpolation='nearest',radius =1, n_samples=1)\n",
    "    plot_surf_contours(fsaverage.infl_right, texture_contour, axes = ax_surf,figure=surf_plot3, legend=True,levels = [1], colors=['k'])\n",
    "    surf_plot3.axes[4].text(10,.5*vmax,s=txt,fontsize=20, fontdict = {'verticalalignment':'top','horizontalalignment':'left','rotation':0})\n",
    "    box = surf_plot3.axes[4].get_position()\n",
    "    surf_plot3.axes[4].set_position([box.x0*.93, box.y0-.3, box.width, box.height*2])  # move a bit the bar to the right, need to divide by number of columns (to move relative to last figure only, not to overall row, else will get too far away)\n",
    "    \n",
    "\n",
    "    ax_surf = ax[1,1] # medial\n",
    "    surf_plot4=plot_surf_roi(fsaverage.infl_right, texture, hemi='right',cmap = cmap, colorbar=False,symmetric_cmap=True, vmin = vmin, vmax = vmax,\n",
    "                                bg_map=fsaverage.sulc_right, view ='medial',axes = ax_surf, threshold =  thresh)#)#,vol_to_surf_kwargs={\"n_samples\": 10, \"radius\": 10, \"interpolation\": \"nearest\",\"kind\":'ball'})\n",
    "    plot_surf_contours(fsaverage.infl_right, texture_contour, axes = ax_surf,figure=surf_plot4, legend=True, levels = [1], colors=['k'])#, labels=['Sig. (q<.05) across\\n(a),(c),(d)'])\n",
    "\n",
    "    ax[0,0].dist = 7 # change viewing distance to \"zoom in\" to surface plots\n",
    "    ax[0,1].dist = 7\n",
    "    ax[1,0].dist = 7\n",
    "    ax[1,1].dist = 7\n",
    "\n",
    "    #fig.colorbar(surf_plot3.axes[2])\n",
    "    plt.subplots_adjust(left=0,\n",
    "                        bottom=0, \n",
    "                        right=.8, \n",
    "                        top=1, \n",
    "                        wspace=0.0, \n",
    "                        hspace=-.1)    \n",
    "fig_save_loc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## All nodes that are significant highlighted, with GLM contours to see which ones are within the social processing regions and which ones are not\n",
    "\n",
    "- Figure 7e in the final manuscript"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots\n",
    "vmin,vmax = -.003,.003\n",
    "cmap =  'RdBu_r' #'RdBu_r', 'PiYG'\n",
    "txt = '     'r\"$\\overline{\\beta}(traits)$\" # to be corrected - remove overline (NOT \"MEAN\" BETA)\n",
    "title_txt = 'traits term beta (p<.05)'\n",
    " \n",
    "thresh = 1e-10\n",
    "nodes = np.zeros((268,))\n",
    "nodes[(coef_p_model9[:,1]<.05)] = coef_p_model9[(coef_p_model9[:,1]<.05),0]\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params,thresh = 1e-10)\n",
    "plt.savefig(os.path.join(fig_save_loc,f'soc_vs_nonsoc/resp_trait_corr_unc_all_nodes_surf.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img, threshold=thresh,\n",
    "colorbar= False)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "plt.savefig(os.path.join(fig_save_loc,f'soc_vs_nonsoc/resp_trait_corr_unc_all_nodes_axial.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Not in paper"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filtering nodes by whether they're also within the intersection social processing nodes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# surface plots, \n",
    "vmin,vmax = -.003,.003\n",
    "cmap =  'RdBu_r' #'RdBu_r', 'PiYG'\n",
    "txt = '     'r\"$\\overline{\\beta}(traits)$\" # to be corrected - remove overline (NOT \"MEAN\" BETA)\n",
    "title_txt = 'traits term beta (p<.05)'\n",
    " \n",
    "thresh = 1e-10\n",
    "nodes = np.zeros((268,))\n",
    "nodes[(coef_p_model9[:,1]<.05) &  (nodes_coaxbill_rand_all)] = coef_p_model9[(coef_p_model9[:,1]<.05) & (nodes_coaxbill_rand_all),0]\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params,thresh = 1e-10)\n",
    "plt.savefig(os.path.join(fig_save_loc,f'soc_vs_nonsoc/resp_trait_corr_unc_GLM nodes_surf.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img, threshold=thresh,\n",
    "colorbar= False)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "plt.savefig(os.path.join(fig_save_loc,f'soc_vs_nonsoc/resp_trait_corr_unc_GLM nodes_axial.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "#plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Correlation (as an alternative to linear regression) between run-wise diff and traits"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- this would be less sensitive to magnitudes, but doesn't have an intercept term like linear regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(np.where(rval_pval_spearman_coef_diff_ASR_Intn_T[:,1]<.05))\n",
    "print(np.where(lsu(rval_pval_spearman_coef_diff_ASR_Intn_T[:,1])))\n",
    "print(np.where(lsu(rval_pval_spearman_coef_diff_ASR_Intn_T[nodes_coaxbill_rand_all,1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plotting results from the correlation "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "qcorr = np.zeros((268,))\n",
    "qcorr[nodes_coaxbill_rand_all] = lsu(rval_pval_spearman_coef_diff_ASR_Intn_T[nodes_coaxbill_rand_all,1])\n",
    "np.where(qcorr)\n",
    "\n",
    "# nodes showing sig (unc p <.05) correlation between \"Social\"-\"Non-social\" and trait score\n",
    "vmin,vmax = -.08,.08\n",
    "cmap =  'RdBu_r' #'RdBu_r', 'PiYG'\n",
    "#txt = r\"$\\overline{\\beta}(''S''-''NS'')$\"\n",
    "txt = \"rSp_traits\" \n",
    "\n",
    "title_txt = 'traits term Spearman_r (p<.05)' \n",
    "thresh = 1e-10\n",
    "\n",
    "nodes = np.zeros((268,))\n",
    "nodes[rval_pval_spearman_coef_diff_ASR_Intn_T[:,1]<.05] = rval_pval_spearman_coef_diff_ASR_Intn_T[rval_pval_spearman_coef_diff_ASR_Intn_T[:,1]<.05,0]\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params,thresh = 1e-10)\n",
    "#plt.savefig(os.path.join(fig_save_loc,f'AIC_surf_thresh{thresh}_resp_resptraits.png'),dpi=300,bbox_inches='tight',facecolor='white', edgecolor='none')\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img, threshold=thresh,\n",
    "colorbar= False)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)\n",
    "\n",
    "\n",
    "\n",
    "print(model9_txt)\n",
    "coef_p_model9 = [[model9_res[n][0][1], model9_res[n][1][1]] for n in range(268)] # ASR reg coefft\n",
    "coef_p_model9= np.array(coef_p_model9)\n",
    "print(coef_p_model9[:5,:])\n",
    "\n",
    "print('sig terms:', len(np.where(coef_p_model9[:,1]<.05)[0]))\n",
    "#coef_p_model9[coef_p_model9[:,1]<.05,1]\n",
    "coef_p_model9_fdr = lsu(coef_p_model9[:,1],q=.05)#fdr_correction(pval_slope_rand,.05)\n",
    "len(np.where(coef_p_model9_fdr)[0])\n",
    "\n",
    "min(coef_p_model9[:,0]),max(coef_p_model9[:,0])\n",
    "\n",
    "# surface plots\n",
    "vmin,vmax = -.003,.003\n",
    "cmap =  'RdBu_r' #'RdBu_r', 'PiYG'\n",
    "txt = r\"$\\overline{\\beta}(traits)$\"\n",
    "\n",
    "title_txt = 'traits term beta (p<.05)'\n",
    "thresh = 1e-10\n",
    "\n",
    "nodes = np.zeros((268,))\n",
    "nodes[coef_p_model9[:,1]<.05] = coef_p_model9[coef_p_model9[:,1]<.05,0]\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols= 2,figsize=(6,4),subplot_kw={'projection': '3d'})\n",
    "params = {'title':title_txt,'txt':txt, 'vmin': vmin, 'vmax':vmax}\n",
    "surf_plot1(fig,ax,nodes,params,thresh = 1e-10)\n",
    "\n",
    "img = roi_to_brain(pd.Series(nodes), mask_x)\n",
    "coords = [-44,-34,-24] # initial exploration\n",
    "ax_plot = plot_img(img.to_nifti(), display_mode = 'z',vmin = vmin, vmax = vmax, cut_coords =coords,cmap = cmap, bg_img = bg_img, threshold=thresh,\n",
    "colorbar= False)\n",
    "ax_plot.add_contours(color_rois(nodes_coaxbill_rand_all),linewidths=1, colors=['k'],linestyles ='-',filled=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('py37': conda)"
  },
  "interpreter": {
   "hash": "30fd9c97283ec1278eec212a8f8afab06ad903f38228c32cacb469eba8e56f4f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}